-e 
================================================================================
üìÑ FICHIER : README.md
================================================================================

-e 

-e 
================================================================================
üìÑ FICHIER : backend/add_safe_cache.py
================================================================================
import re

with open('app/routers/coach.py', 'r') as f:
    content = f.read()

# Trouver generate_workout et ajouter un d√©corateur safe
func_pattern = r'async def generate_workout\([\s\S]*?\):'
match = re.search(func_pattern, content)

if match:
    func_start = match.start()
    
    # Ajouter le d√©corateur safe (ignore current_user)
    decorated_func = '@cached_response_fixed(ttl_hours=6, ignore_args=["current_user"])\n' + match.group(0)
    
    new_content = content[:func_start] + decorated_func + content[func_start + len(match.group(0)):]
    
    with open('app/routers/coach.py', 'w') as f:
        f.write(new_content)
    
    print("‚úÖ D√©corateur safe ajout√© √† generate_workout")
else:
    print("‚ö†Ô∏è  Impossible de trouver generate_workout")
-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/__init__.py
================================================================================
-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/core/__init__.py
================================================================================
-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/core/cache.py
================================================================================
"""
Cache intelligent pour les appels Gemini IA.
√âconomise les co√ªts API et am√©liore la r√©activit√©.
"""
import json
import hashlib
from datetime import datetime, timedelta
from typing import Any, Optional
from functools import wraps
import logging

logger = logging.getLogger(__name__)

class IntelligentCache:
    """Cache m√©moire avec expiration et invalidation intelligente."""
    
    def __init__(self, default_ttl_hours: int = 24):
        self._cache = {}
        self.default_ttl = default_ttl_hours
    
    def _generate_key(self, *args, **kwargs) -> str:
        """G√©n√®re une cl√© unique √† partir des param√®tres."""
        data = json.dumps({
            'args': args,
            'kwargs': kwargs
        }, sort_keys=True)
        return hashlib.md5(data.encode()).hexdigest()
    
    def get(self, key: str) -> Optional[Any]:
        """R√©cup√®re un √©l√©ment du cache s'il est valide."""
        if key in self._cache:
            entry = self._cache[key]
            if datetime.now() < entry['expires_at']:
                logger.debug(f"üì¶ Cache hit: {key}")
                return entry['data']
            else:
                del self._cache[key]
                logger.debug(f"üßπ Cache expired: {key}")
        return None
    
    def set(self, key: str, data: Any, ttl_hours: Optional[int] = None):
        """Stocke un √©l√©ment dans le cache."""
        ttl = ttl_hours if ttl_hours is not None else self.default_ttl
        self._cache[key] = {
            'data': data,
            'expires_at': datetime.now() + timedelta(hours=ttl),
            'created_at': datetime.now()
        }
        logger.debug(f"üíæ Cache stored: {key} (TTL: {ttl}h)")
    
    def clear_old_entries(self):
        """Nettoie les entr√©es expir√©es."""
        now = datetime.now()
        expired_keys = [
            k for k, v in self._cache.items() 
            if now >= v['expires_at']
        ]
        for k in expired_keys:
            del self._cache[k]
        if expired_keys:
            logger.info(f"üßπ Cache cleanup: {len(expired_keys)} entr√©es expir√©es")

# Instance globale
ai_cache = IntelligentCache(default_ttl_hours=6)  # 6h pour les plans IA

def cached_response(ttl_hours: int = 6):
    """D√©corateur pour mettre en cache les r√©ponses IA."""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # G√©n√©rer une cl√© unique
            cache_key = f"{func.__name__}:{ai_cache._generate_key(*args, **kwargs)}"
            
            # V√©rifier le cache
            cached = ai_cache.get(cache_key)
            if cached is not None:
                return cached
            
            # Ex√©cuter la fonction
            result = await func(*args, **kwargs)
            
            # Mettre en cache
            if result is not None:
                ai_cache.set(cache_key, result, ttl_hours)
            
            return result
        return wrapper
    return decorator
-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/core/cache_fixed.py
================================================================================
"""
Version corrig√©e du d√©corateur de cache qui ignore les objets non s√©rialisables
"""

import json
import hashlib
from datetime import datetime, timedelta
from typing import Any, Optional, Callable
from functools import wraps
import logging

logger = logging.getLogger(__name__)

class FixedIntelligentCache:
    """Cache m√©moire avec gestion des objets non s√©rialisables."""
    
    def __init__(self, default_ttl_hours: int = 24):
        self._cache = {}
        self.default_ttl = default_ttl_hours
    
    def _safe_serialize(self, obj: Any) -> Any:
        """S√©rialise en toute s√©curit√©, convertissant les objets SQLAlchemy en dict."""
        if hasattr(obj, '__dict__'):
            # Si c'est un mod√®le SQLAlchemy, on prend son ID
            if hasattr(obj, 'id'):
                return f"{obj.__class__.__name__}:{obj.id}"
            # Sinon, on convertit en dict sans les relations
            return {k: self._safe_serialize(v) for k, v in obj.__dict__.items() 
                    if not k.startswith('_')}
        elif isinstance(obj, (list, tuple)):
            return [self._safe_serialize(item) for item in obj]
        elif isinstance(obj, dict):
            return {k: self._safe_serialize(v) for k, v in obj.items()}
        else:
            return obj
    
    def _generate_key(self, *args, **kwargs) -> str:
        """G√©n√®re une cl√© unique en s√©rialisant en toute s√©curit√©."""
        safe_args = self._safe_serialize(args)
        safe_kwargs = self._safe_serialize(kwargs)
        
        data = json.dumps({
            'args': safe_args,
            'kwargs': safe_kwargs
        }, sort_keys=True, default=str)
        return hashlib.md5(data.encode()).hexdigest()
    
    def get(self, key: str) -> Optional[Any]:
        """R√©cup√®re un √©l√©ment du cache s'il est valide."""
        if key in self._cache:
            entry = self._cache[key]
            if datetime.now() < entry['expires_at']:
                logger.debug(f"üì¶ Cache hit: {key}")
                return entry['data']
            else:
                del self._cache[key]
                logger.debug(f"üßπ Cache expired: {key}")
        return None
    
    def set(self, key: str, data: Any, ttl_hours: Optional[int] = None):
        """Stocke un √©l√©ment dans le cache."""
        ttl = ttl_hours if ttl_hours is not None else self.default_ttl
        self._cache[key] = {
            'data': data,
            'expires_at': datetime.now() + timedelta(hours=ttl),
            'created_at': datetime.now()
        }
        logger.debug(f"üíæ Cache stored: {key} (TTL: {ttl}h)")
    
    def clear_old_entries(self):
        """Nettoie les entr√©es expir√©es."""
        now = datetime.now()
        expired_keys = [
            k for k, v in self._cache.items() 
            if now >= v['expires_at']
        ]
        for k in expired_keys:
            del self._cache[k]
        if expired_keys:
            logger.info(f"üßπ Cache cleanup: {len(expired_keys)} entr√©es expir√©es")

# Instance globale
ai_cache_fixed = FixedIntelligentCache(default_ttl_hours=6)

def cached_response_fixed(ttl_hours: int = 6, ignore_args: list = None):
    """
    D√©corateur corrig√© pour mettre en cache les r√©ponses IA.
    ignore_args: liste des noms d'arguments √† ignorer (ex: ['current_user'])
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # Cr√©er une copie des kwargs pour la g√©n√©ration de cl√©
            cache_kwargs = kwargs.copy()
            
            # Ignorer les arguments sp√©cifi√©s
            if ignore_args:
                for arg_name in ignore_args:
                    cache_kwargs.pop(arg_name, None)
            
            # G√©n√©rer une cl√© unique (sans les arguments ignor√©s)
            cache_key = f"{func.__name__}:{ai_cache_fixed._generate_key(*args, **cache_kwargs)}"
            
            # V√©rifier le cache
            cached = ai_cache_fixed.get(cache_key)
            if cached is not None:
                return cached
            
            # Ex√©cuter la fonction
            result = await func(*args, **kwargs)
            
            # Mettre en cache
            if result is not None:
                ai_cache_fixed.set(cache_key, result, ttl_hours)
            
            return result
        return wrapper
    return decorator
-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/core/database.py
================================================================================
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from dotenv import load_dotenv

load_dotenv()

# 1. On r√©cup√®re l'URL
SQLALCHEMY_DATABASE_URL = os.getenv("DATABASE_URL")

# 2. S√©curit√© : si pas d'URL, on met du SQLite temporaire
if not SQLALCHEMY_DATABASE_URL:
    print("‚ö†Ô∏è DATABASE_URL absente. Mode SQLite temporaire.")
    SQLALCHEMY_DATABASE_URL = "sqlite:///./sql_app.db"

# 3. Correctif pour l'URL (postgres -> postgresql)
if SQLALCHEMY_DATABASE_URL.startswith("postgres://"):
    SQLALCHEMY_DATABASE_URL = SQLALCHEMY_DATABASE_URL.replace("postgres://", "postgresql://", 1)

# 4. Cr√©ation du moteur (Version Simplifi√©e pour √©viter les Timeouts)
connect_args = {}
if "sqlite" in SQLALCHEMY_DATABASE_URL:
    connect_args = {"check_same_thread": False}

engine = create_engine(
    SQLALCHEMY_DATABASE_URL,
    connect_args=connect_args
    # On a retir√© pool_pre_ping pour tester la connexion brute
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/core/security.py
================================================================================
from datetime import datetime, timedelta
from typing import Optional
from jose import jwt
from passlib.context import CryptContext
import os
from dotenv import load_dotenv

load_dotenv()

# Configuration
SECRET_KEY = os.getenv("SECRET_KEY", "fallback_secret_key_if_env_missing")
ALGORITHM = os.getenv("ALGORITHM", "HS256")
ACCESS_TOKEN_EXPIRE_MINUTES = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", 30))

pwd_context = CryptContext(
    schemes=["bcrypt"], 
    deprecated="auto",
    bcrypt__ident="2b"
)

def get_password_hash(password: str) -> str:
    """Transforme un mot de passe en clair en hash s√©curis√©."""
    return pwd_context.hash(password)

def verify_password(plain_password: str, hashed_password: str) -> bool:
    """V√©rifie si le mot de passe correspond au hash."""
    return pwd_context.verify(plain_password, hashed_password)

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    """G√©n√®re un Token JWT sign√©."""
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)
        
    to_encode.update({"exp": expire})
    
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/dependencies.py
================================================================================
from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from jose import JWTError, jwt
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.core import security
from app.models import sql_models, schemas

# C'est ici qu'on dit √† FastAPI o√π aller chercher le token si on ne l'a pas
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="auth/token")

async def get_current_user(token: str = Depends(oauth2_scheme), db: Session = Depends(get_db)):
    """
    Cette fonction est un 'Dependency'. 
    Elle sera appel√©e avant chaque route prot√©g√©e.
    1. Elle r√©cup√®re le token.
    2. Elle le d√©code.
    3. Elle v√©rifie si l'utilisateur existe en BDD.
    """
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Impossible de valider les identifiants",
        headers={"WWW-Authenticate": "Bearer"},
    )
    
    try:
        # D√©codage du token
        payload = jwt.decode(token, security.SECRET_KEY, algorithms=[security.ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception
        
    # Recherche de l'utilisateur en BDD
    user = db.query(sql_models.User).filter(sql_models.User.username == username).first()
    if user is None:
        raise credentials_exception
        
    return user-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/domain/__init__.py
================================================================================
-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/domain/bioenergetics.py
================================================================================
import math
from typing import Dict, Any, List

class BioenergeticService:
    """
    Service de calcul physiologique (Bio-Twin v1).
    Estime la d√©pense √©nerg√©tique et les besoins nutritionnels post-effort.
    Ne d√©pend PAS de l'IA, mais de formules m√©taboliques.
    """

    @staticmethod
    def calculate_needs(profile_data: Dict[str, Any], workout_sets: List[Any], duration_min: float, rpe: float) -> Dict[str, Any]:
        """
        Calcule les KPIs physiologiques de la s√©ance.
        """
        # 1. Extraction du profil (valeurs par d√©faut de s√©curit√©)
        weight = float(profile_data.get('weight', 70.0))
        if weight <= 0: weight = 70.0
        
        gender = profile_data.get('gender', 'Homme')
        
        # 2. Estimation de la D√©pense √ânerg√©tique (Kcal)
        # M√©thode A : Pr√©cise si Watts disponibles
        total_work_kj = 0.0
        has_power_data = False
        
        for s in workout_sets:
            if s.metric_type == 'POWER_TIME':
                # Watts * secondes / 1000 = kJ
                # weight = watts, reps = duration(s) dans ce mode (selon schemas.py)
                # Mais attention, le frontend envoie parfois des minutes converties.
                # Dans sql_models/schemas, on a standardis√© : weight=Watts, reps=Secondes (via validateur polymorphique)
                watts = s.weight
                seconds = s.reps 
                total_work_kj += (watts * seconds) / 1000.0
                has_power_data = True
        
        kcal_burn = 0.0
        
        if has_power_data:
            # Rendement m√©canique humain ~20-25% => x4 √† x5 pour passer de kJ m√©canique √† kcal m√©tabolique
            # Formule standard: kJ * 1.1 est une approx basse, kJ / 4.18 * 4 (rendement) est mieux.
            # Simplification robuste : kJ m√©canique * 1.0 = Kcal m√©tabolique (approx tr√®s courante en cyclisme)
            kcal_burn = total_work_kj * 1.0 
            # Si on ajoute le m√©tabolisme de base pendant la dur√©e... Restons sur l'activit√© pure.
        else:
            # M√©thode B : Estimation METs (Metabolic Equivalent of Task)
            # RPE 1-3 (Repos/Recup) : 3 METs
            # RPE 4-6 (Endurance) : 6 METs
            # RPE 7-8 (Seuil) : 9 METs
            # RPE 9-10 (Max) : 12 METs
            mets = 3.0
            if rpe > 8: mets = 11.0
            elif rpe > 6: mets = 9.0
            elif rpe > 4: mets = 6.0
            else: mets = 3.5
            
            # Formule : Kcal = METs * Poids(kg) * Dur√©e(h)
            duration_hours = duration_min / 60.0
            kcal_burn = mets * weight * duration_hours

        # 3. Partition Macro-nutritionnelle (Fili√®res √©nerg√©tiques)
        # Ratio Glucides/Lipides d√©pend de l'intensit√© relative
        # RPE √©lev√© -> Glycolytique -> Besoin Glucides
        carbs_ratio = 0.5 # 50% par d√©faut
        
        if rpe >= 8: carbs_ratio = 0.8  # 80% glucides
        elif rpe >= 6: carbs_ratio = 0.6 # 60% glucides
        elif rpe <= 4: carbs_ratio = 0.3 # 30% glucides (LIPOX max)
        
        kcal_carbs = kcal_burn * carbs_ratio
        carbs_g = kcal_carbs / 4.0 # 4 kcal/g
        
        # 4. Prot√©ines (R√©paration tissulaire)
        # Base : 0.3g / kg de poids de corps apr√®s une s√©ance standard
        # Boost si s√©ance de force (RPE > 7)
        protein_factor = 0.25
        if rpe > 7: protein_factor = 0.35
        
        protein_g = weight * protein_factor
        
        # 5. Hydratation (Estimation sudation standard)
        # ~10ml / min / kg est trop. 
        # Standard : 0.5L √† 1L par heure selon intensit√©.
        sweat_rate_ml_h = 500
        if rpe > 7: sweat_rate_ml_h = 800
        water_ml = (duration_min / 60.0) * sweat_rate_ml_h

        return {
            "kcal_total": int(kcal_burn),
            "carbs_g": int(carbs_g),
            "protein_g": int(protein_g),
            "water_ml": int(water_ml),
            "source": "Wattmeter" if has_power_data else "METs Estimator"
        }-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/domain/calculations.py
================================================================================
import math
from abc import ABC, abstractmethod

# --- STRATEGY PATTERN : MOTEUR 1RM ---

class OneRepMaxStrategy(ABC):
    """Interface abstraite pour les strat√©gies de calcul du 1RM."""
    @abstractmethod
    def calculate(self, weight: float, reps: int) -> float:
        pass

    @property
    @abstractmethod
    def name(self) -> str:
        pass

class EpleyStrategy(OneRepMaxStrategy):
    """Formule d'Epley : W * (1 + r/30)"""
    def calculate(self, weight: float, reps: int) -> float:
        return weight * (1 + reps / 30.0)

    @property
    def name(self) -> str:
        return "Epley"

class BrzyckiStrategy(OneRepMaxStrategy):
    """Formule de Brzycki : W * (36 / (37 - r))"""
    def calculate(self, weight: float, reps: int) -> float:
        if reps >= 37: return 0.0
        return weight * (36.0 / (37.0 - reps))

    @property
    def name(self) -> str:
        return "Brzycki"

class WathanStrategy(OneRepMaxStrategy):
    """Formule de Wathan : Exponentielle"""
    def calculate(self, weight: float, reps: int) -> float:
        denominator = 48.8 + (53.8 * math.exp(-0.075 * reps))
        if denominator == 0: return 0.0
        return (100.0 * weight) / denominator

    @property
    def name(self) -> str:
        return "Wathan"

class OneRepMaxCalculator:
    """Factory : S√©lectionne la bonne strat√©gie selon le nombre de r√©p√©titions."""
    @staticmethod
    def get_strategy(reps: int) -> OneRepMaxStrategy:
        if reps <= 5:
            return EpleyStrategy()
        elif reps <= 10:
            return BrzyckiStrategy()
        else:
            return WathanStrategy()

def calculate_1rm(weight: float, reps: int) -> dict:
    """
    Fonction principale expos√©e au reste de l'app.
    """
    if weight <= 0 or reps <= 0:
        return {"1rm": 0.0, "method": "N/A"}
    
    if reps == 1:
        return {"1rm": weight, "method": "Actual Lift"}
        
    if reps > 30:
        return {"1rm": 0.0, "method": "Out of Range (>30)"}

    strategy = OneRepMaxCalculator.get_strategy(reps)
    one_rm_val = strategy.calculate(weight, reps)
    
    # Arrondi au 0.5kg le plus proche
    final_val = round(one_rm_val * 2) / 2

    return {
        "1rm": final_val,
        "method": strategy.name
    }-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/domain/safety.py
================================================================================
import pandas as pd
from datetime import date, timedelta
import re

def _safe_float(val):
    """Helper pour convertir n'importe quoi en float."""
    if val is None: return 0.0
    try:
        clean = str(val).replace(',', '.').strip()
        match = re.search(r"[-+]?\d*\.\d+|\d+", clean)
        return float(match.group()) if match else 0.0
    except:
        return 0.0

def calculate_acwr(history_logs: list) -> dict:
    """
    Calcule le Ratio Aigu/Chronique (ACWR).
    Entr√©e : Liste de dictionnaires (date, duration, rpe).
    Sortie : Dict avec ratio, status, charges.
    """
    default_res = {
        "ratio": 0.0,
        "status": "Inactif",
        "color": "gray",
        "acute_load": 0,
        "chronic_load": 0,
        "message": "Pas assez de donn√©es."
    }
    
    if not history_logs:
        return default_res

    try:
        # 1. Cr√©ation DataFrame
        df = pd.DataFrame(history_logs)
        
        # Conversion et tri des dates
        df['date_dt'] = pd.to_datetime(df['date'], errors='coerce').dt.floor('D')
        df = df.dropna(subset=['date_dt']).sort_values('date_dt')
        
        if df.empty:
            return default_res

        # 2. Calcul de la charge (Load = Dur√©e * RPE)
        # On s√©curise les valeurs
        df['duration'] = df['duration'].apply(_safe_float)
        df['rpe'] = df['rpe'].apply(_safe_float)
        df['load'] = df['duration'] * df['rpe']
        
        # Agr√©gation par jour (si plusieurs s√©ances le m√™me jour)
        daily_loads = df.groupby('date_dt')['load'].sum()
        
        # 3. Timeline Continue (J-27 √† Aujourd'hui)
        end_date = pd.Timestamp.now().floor('D')
        idx_ref = pd.date_range(end=end_date, periods=28, freq='D')
        
        # On remplit les trous avec 0
        timeline = daily_loads.reindex(idx_ref, fill_value=0)
        
        # 4. Calculs Fen√™tres Glissantes
        acute_avg = timeline.tail(7).mean()   # Fatigue (7j)
        chronic_avg = timeline.mean()         # Forme (28j)
        
        # 5. Ratio
        ratio = 0.0
        if chronic_avg > 0:
            ratio = acute_avg / chronic_avg
        elif acute_avg > 0:
            ratio = 2.0 # Reprise brutale
            
        # 6. Diagnostic
        ratio = round(ratio, 2)
        status, color, msg = "Inactif", "gray", "Reprends progressivement."
        
        if ratio > 0:
            if ratio <= 0.80:
                status, color, msg = "Sous-entra√Ænement", "blue", "Charge faible."
            elif 0.80 < ratio <= 1.30:
                status, color, msg = "Optimal", "green", "Zone de progression."
            elif 1.30 < ratio <= 1.50:
                status, color, msg = "Surcharge", "orange", "Attention fatigue."
            else:
                status, color, msg = "DANGER", "red", "Pic de charge critique (>1.5)."

        return {
            "ratio": ratio,
            "status": status,
            "color": color,
            "acute_load": int(acute_avg),
            "chronic_load": int(chronic_avg),
            "message": msg
        }
        
    except Exception as e:
        print(f"Erreur ACWR: {e}")
        return default_res-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/jobs/daily_coach_memory_update.py
================================================================================
"""
Job quotidien pour mettre √† jour les m√©moires du coach
Ex√©cut√© automatiquement √† 02:00 chaque jour
"""
import logging
import asyncio
from datetime import datetime, timedelta
from sqlalchemy.orm import Session
from sqlalchemy import and_

from app.core.database import SessionLocal
from app.models import sql_models
from app.services.coach_memory.service import CoachMemoryService

logger = logging.getLogger(__name__)

async def daily_coach_memory_update():
    """
    Met √† jour toutes les m√©moires du coach quotidiennement
    """
    logger.info("üöÄ D√©marrage du job quotidien de mise √† jour des m√©moires du coach")
    
    db = SessionLocal()
    try:
        # R√©cup√©rer toutes les m√©moires actives
        coach_memories = db.query(sql_models.CoachMemory).all()
        
        logger.info(f"üìä {len(coach_memories)} m√©moires √† mettre √† jour")
        
        updated_count = 0
        error_count = 0
        
        for memory in coach_memories:
            try:
                # R√©cup√©rer le profil associ√©
                athlete_profile = db.query(sql_models.AthleteProfile).filter(
                    sql_models.AthleteProfile.id == memory.athlete_profile_id
                ).first()
                
                if not athlete_profile:
                    logger.warning(f"Profil non trouv√© pour la m√©moire {memory.id}")
                    continue
                
                # Mettre √† jour le contexte avec des valeurs par d√©faut
                default_checkin = {
                    "sleep_quality": 7,
                    "sleep_duration": 7.5,
                    "perceived_stress": 5,
                    "muscle_soreness": 3,
                    "energy_level": 7
                }
                
                # Mettre √† jour le contexte
                CoachMemoryService.update_daily_context(memory, default_checkin, db)
                
                # Mettre √† jour les m√©tadonn√©es
                metadata = json.loads(memory.metadata) if memory.metadata else {}
                metadata['last_daily_update'] = datetime.utcnow().isoformat()
                metadata['total_updates'] = metadata.get('total_updates', 0) + 1
                memory.metadata = json.dumps(metadata)
                
                updated_count += 1
                
                # Log tous les 10 profils
                if updated_count % 10 == 0:
                    logger.info(f"‚úÖ {updated_count} m√©moires mises √† jour")
                
            except Exception as e:
                error_count += 1
                logger.error(f"‚ùå Erreur mise √† jour m√©moire {memory.id}: {str(e)}")
                continue
        
        db.commit()
        
        logger.info(f"üéâ Job termin√©: {updated_count} mises √† jour, {error_count} erreurs")
        
        # G√©n√©rer un rapport
        report = {
            "timestamp": datetime.now().isoformat(),
            "total_memories": len(coach_memories),
            "updated": updated_count,
            "errors": error_count,
            "success_rate": (updated_count / len(coach_memories) * 100) if coach_memories else 100
        }
        
        logger.info(f"üìà Rapport: {report}")
        
        return report
        
    except Exception as e:
        logger.error(f"üí• Erreur critique dans le job quotidien: {str(e)}")
        db.rollback()
        raise
    finally:
        db.close()

async def update_memory_flags_batch():
    """
    Met √† jour les flags de m√©moire en batch
    """
    logger.info("üöÄ Mise √† jour batch des flags de m√©moire")
    
    db = SessionLocal()
    try:
        # R√©cup√©rer les m√©moires avec contexte r√©cent
        one_day_ago = datetime.utcnow() - timedelta(days=1)
        
        coach_memories = db.query(sql_models.CoachMemory).filter(
            sql_models.CoachMemory.last_updated >= one_day_ago
        ).all()
        
        for memory in coach_memories:
            try:
                context = json.loads(memory.current_context) if memory.current_context else {}
                readiness = context.get('readiness_score', 70)
                
                memory_flags = json.loads(memory.memory_flags) if memory.memory_flags else {}
                
                # Mettre √† jour les flags bas√©s sur le contexte
                memory_flags['needs_deload'] = readiness < 40
                memory_flags['adaptation_window_open'] = readiness > 70
                memory_flags['pr_potential'] = readiness > 80 and context.get('fatigue_state') == 'fresh'
                
                memory.memory_flags = json.dumps(memory_flags)
                
            except Exception as e:
                logger.error(f"‚ùå Erreur mise √† jour flags m√©moire {memory.id}: {str(e)}")
                continue
        
        db.commit()
        logger.info(f"‚úÖ Flags mis √† jour pour {len(coach_memories)} m√©moires")
        
    except Exception as e:
        logger.error(f"üí• Erreur batch flags: {str(e)}")
        db.rollback()
    finally:
        db.close()

async def cleanup_old_data():
    """
    Nettoie les donn√©es anciennes
    """
    logger.info("üßπ Nettoyage des donn√©es anciennes")
    
    db = SessionLocal()
    try:
        # Supprimer les profils incomplets de plus de 30 jours
        thirty_days_ago = datetime.utcnow() - timedelta(days=30)
        
        incomplete_profiles = db.query(sql_models.AthleteProfile).filter(
            and_(
                sql_models.AthleteProfile.is_complete == False,
                sql_models.AthleteProfile.created_at < thirty_days_ago
            )
        ).all()
        
        deleted_count = 0
        for profile in incomplete_profiles:
            try:
                db.delete(profile)
                deleted_count += 1
            except Exception as e:
                logger.error(f"‚ùå Erreur suppression profil {profile.id}: {str(e)}")
        
        db.commit()
        logger.info(f"üóëÔ∏è  {deleted_count} profils incomplets supprim√©s")
        
    except Exception as e:
        logger.error(f"üí• Erreur nettoyage: {str(e)}")
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    # Pour ex√©cution manuelle
    import asyncio
    import json
    
    async def main():
        logger.info("üß™ Ex√©cution manuelle du job quotidien")
        
        # Ex√©cuter les t√¢ches
        report = await daily_coach_memory_update()
        await update_memory_flags_batch()
        await cleanup_old_data()
        
        print(json.dumps(report, indent=2))
    
    asyncio.run(main())
-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/main.py
================================================================================
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from sqlalchemy import text, inspect, create_engine
from datetime import datetime

from app.core.database import engine, Base
# Import des mod√®les
from app.models import sql_models 

# --- IMPORTS DES ROUTEURS ---
from .routers import (
    performance, 
    safety, 
    auth, 
    workouts, 
    coach, 
    user, 
    feed,
    athlete_profiles,
    coach_memories  # ‚úÖ NOUVEL IMPORT CRITIQUE (DEV-CARD #01)
)

# Configuration des logs
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- DATABASE INIT ---
try:
    Base.metadata.create_all(bind=engine)
    logger.info("‚úÖ Tables SQL v√©rifi√©es.")
except Exception as e:
    logger.error(f"ERREUR INIT DB : {e}")

app = FastAPI(
    title="TitanFlow API",
    description="API Backend pour l'application TitanFlow",
    version="2.5.0", # Bump version pour marquer le changement
    docs_url="/docs",
    redoc_url="/redoc"
)

# --- CONFIGURATION CORS ---
origins = ["*"]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"], 
    allow_headers=["*"], 
)

# --- GLOBAL EXCEPTION HANDLER ---
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logger.error(f"üî• CRASH : {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={"detail": f"Erreur serveur : {str(exc)}"},
    )

# --- ROUTEURS ACTIFS ---

# 1. Auth
app.include_router(auth.router)

# 2. PROFILES & MEMORY
app.include_router(
    athlete_profiles.router, 
    prefix="/api/v1/profiles", 
    tags=["Profiles"]
)

# ‚úÖ AJOUT DU ROUTEUR M√âMOIRE (DEV-CARD #02)
# Les pr√©fixes sont d√©j√† d√©finis dans le routeur lui-m√™me (/api/v1/coach-memories)
app.include_router(coach_memories.router)

# 3. Autres features
app.include_router(workouts.router)
app.include_router(performance.router)
app.include_router(safety.router)
app.include_router(coach.router)
app.include_router(feed.router)

# --- ROUTES SYST√àME ---

@app.get("/health", tags=["System"])
async def health_check():
    return {
        "status": "active",
        "version": "2.5.0",
        "database": "connected"
    }

@app.get("/db_status", tags=["System"])
async def database_status():
    """Diagnostic DB"""
    try:
        inspector = inspect(engine)
        tables = inspector.get_table_names()
        
        columns_user = []
        if 'users' in tables:
            columns_user = [c['name'] for c in inspector.get_columns('users')]
            
        return {
            "status": "success",
            "tables": tables,
            "json_profile_ready": 'profile_data' in columns_user,
            "engrams_ready": 'coach_engrams' in tables, # ‚úÖ Check Engrams
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("app.main:app", host="0.0.0.0", port=8000, reload=True)-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/models/__init__.py
================================================================================
-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/models/domain.py
================================================================================
from pydantic import BaseModel, Field, field_validator, model_validator, ConfigDict
from typing import List, Optional, Dict, Any
from app.models.enums import CoachingMandate, SlotStatus, LocationContext, EnergyLevel

# --- SOUS-STRUCTURES ---

class ExternalLoad(BaseModel):
    """
    Charge externe impos√©e (ex: Entra√Ænement Club, Match).
    """
    type: str = Field(..., description="Type d'activit√© (ex: Rugby, Match, Crossfit Class)")
    estimated_rpe: int = Field(..., ge=1, le=10, description="Intensit√© per√ßue (1-10)")
    duration_min: int = Field(..., gt=0, description="Dur√©e en minutes")

    @field_validator('estimated_rpe')
    def validate_rpe(cls, v):
        if not 1 <= v <= 10:
            raise ValueError("Le RPE doit √™tre compris entre 1 et 10")
        return v

class TimeSlot(BaseModel):
    """
    Repr√©sente un cr√©neau unique dans la matrice hebdomadaire.
    """
    day_of_week: str = Field(..., pattern="^(Lundi|Mardi|Mercredi|Jeudi|Vendredi|Samedi|Dimanche)$")
    time_of_day: str = Field(..., pattern="^(Matin|Midi|Soir)$")
    status: SlotStatus = Field(default=SlotStatus.AVAILABLE)
    location: Optional[LocationContext] = None
    energy_level: EnergyLevel = Field(default=EnergyLevel.MEDIUM)
    
    # Charge externe (optionnel, seulement si SlotStatus.EXTERNAL_LOCKED)
    external_load: Optional[ExternalLoad] = None
    
    # [NOUVEAU] Tags pour le moteur de contraintes (ex: "RESTRICTED_LEG_VOLUME", "NO_DEADLIFT")
    tags: List[str] = Field(default_factory=list)

    model_config = ConfigDict(from_attributes=True)

    @model_validator(mode='after')
    def validate_slot_coherence(self):
        """V√©rifie la coh√©rence entre le statut et la charge."""
        if self.status == SlotStatus.EXTERNAL_LOCKED and not self.external_load:
            raise ValueError("Un cr√©neau EXTERNAL_LOCKED doit avoir une 'external_load' d√©finie.")
        return self

# --- PROFIL ATHL√âTIQUE V2 (DOMAINE) ---

class AthleteProfileDomain(BaseModel):
    """
    Repr√©sentation 'Domaine' du profil athl√®te.
    C'est la version stricte utilis√©e par le moteur IA, ind√©pendante de la BDD.
    """
    # Identit√© Sportive
    primary_sport: str
    mandate: CoachingMandate = Field(default=CoachingMandate.SUPPORT_HYBRID)
    
    # Matrice Temporelle (Disponibilit√©s)
    time_matrix: List[TimeSlot] = []

    model_config = ConfigDict(from_attributes=True)

    @model_validator(mode='after')
    def validate_sport_locations(self):
        """
        R√®gle M√©tier : Interdire LocationContext.POOL si le sport principal 
        n'est pas li√© √† la natation (Triathlon, Natation, etc.).
        """
        water_sports = ["Natation", "Triathlon", "Swimrun", "Water-polo"]
        is_water_sport = self.primary_sport in water_sports

        for slot in self.time_matrix:
            if slot.location in [LocationContext.POOL_25M, LocationContext.POOL_50M]:
                if not is_water_sport:
                    raise ValueError(
                        f"Impossible d'assigner une piscine ({slot.location}) "
                        f"pour le sport '{self.primary_sport}'. R√©serv√© aux sports aquatiques."
                    )
        return self-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/models/enums.py
================================================================================
from enum import Enum, IntEnum

class CoachingMandate(str, Enum):
    """
    Niveau d'intervention du Coach IA.
    - FULL_AUTO_PILOT : L'IA g√®re tout (Volume, Intensit√©, S√©lection d'exos).
    - PPG_ONLY : L'IA ne g√®re que la pr√©paration physique (pas le sport sp√©).
    - SUPPORT_HYBRID : L'IA propose, l'athl√®te dispose (mode assistant).
    """
    FULL_AUTO_PILOT = "FULL_AUTO_PILOT"
    PPG_ONLY = "PPG_ONLY"
    SUPPORT_HYBRID = "SUPPORT_HYBRID"

class SlotStatus(str, Enum):
    """
    √âtat d'un cr√©neau horaire dans la matrice temporelle.
    """
    AVAILABLE = "AVAILABLE"           # Cr√©neau libre pour l'entra√Ænement
    UNAVAILABLE = "UNAVAILABLE"       # Pris (Travail, Famille, etc.)
    EXTERNAL_LOCKED = "EXTERNAL_LOCKED" # Pris par une contrainte sportive externe (Match, Club)

class LocationContext(str, Enum):
    """
    Lieu d'entra√Ænement disponible pour un cr√©neau donn√©.
    """
    HOME = "HOME"                     # Maison (poids du corps, √©lastiques)
    HOME_GYM_PRO = "HOME_GYM_PRO"     # Garage gym √©quip√©
    COMMERCIAL_GYM = "COMMERCIAL_GYM" # Salle de sport classique
    OUTDOOR_TRACK = "OUTDOOR_TRACK"   # Piste d'athl√© / Ext√©rieur
    POOL_25M = "POOL_25M"             # Piscine petit bain
    POOL_50M = "POOL_50M"             # Piscine olympique

class EnergyLevel(IntEnum):
    """
    Niveau d'√©nergie allouable sur un cr√©neau (Score).
    Utilis√© pour le calcul de la charge (Load Management).
    """
    HIGH_FOCUS = 3    # Performance maximale
    MEDIUM = 2        # Entra√Ænement standard / D√©veloppement
    LOW_RECOVERY = 1  # R√©cup√©ration active / Technique l√©g√®re

# --- NOUVEAUX ENUMS (ENGRAMMES) ---

class MemoryType(str, Enum):
    """Type de souvenir structurel."""
    INJURY_REPORT = "INJURY_REPORT"         # Blessure signal√©e
    LIFE_CONSTRAINT = "LIFE_CONSTRAINT"     # Contrainte vie (voyage, examen...)
    STRATEGIC_OVERRIDE = "STRATEGIC_OVERRIDE" # Changement de cap manuel
    BIOFEEDBACK_LOG = "BIOFEEDBACK_LOG"     # Retour sensation sp√©cifique

class ImpactLevel(str, Enum):
    """Impact du souvenir sur la g√©n√©ration du plan."""
    INFO = "INFO"           # √Ä titre informatif
    MODERATE = "MODERATE"   # N√©cessite un ajustement mineur
    SEVERE = "SEVERE"       # Bloque ou modifie drastiquement le plan

class MemoryStatus(str, Enum):
    """Cycle de vie du souvenir."""
    ACTIVE = "ACTIVE"       # En cours, pris en compte
    SCHEDULED = "SCHEDULED" # Futur (ex: vacances pr√©vues)
    RESOLVED = "RESOLVED"   # Termin√©, mais gard√© en historique
    ARCHIVED = "ARCHIVED"   # Supprim√© logiquement-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/models/schemas.py
================================================================================
from pydantic import BaseModel, Field, field_validator, model_validator, ConfigDict
from typing import List, Optional, Dict, Any, Union
from datetime import date, datetime
from enum import Enum
import json
import re
import logging
from app.models.enums import MemoryType, ImpactLevel, MemoryStatus

logger = logging.getLogger(__name__)

# --- ENUMS & TYPES ---

class SportType(str, Enum):
    RUGBY = "Rugby"
    FOOTBALL = "Football"
    CROSSFIT = "CrossFit"
    HYBRID = "Hybrid"
    RUNNING = "Running"
    OTHER = "Autre"
    BODYBUILDING = "BODYBUILDING"
    CYCLING = "CYCLING"
    TRIATHLON = "TRIATHLON"
    POWERLIFTING = "POWERLIFTING"
    SWIMMING = "SWIMMING"
    COMBAT_SPORTS = "COMBAT_SPORTS"

class EquipmentType(str, Enum):
    PERFORMANCE_LAB = "PERFORMANCE_LAB"
    COMMERCIAL_GYM = "COMMERCIAL_GYM"
    HOME_GYM_BARBELL = "HOME_GYM_BARBELL"
    HOME_GYM_DUMBBELL = "HOME_GYM_DUMBBELL"
    CALISTHENICS_KIT = "CALISTHENICS_KIT"
    BODYWEIGHT_ZERO = "BODYWEIGHT_ZERO"
    ENDURANCE_SUITE = "ENDURANCE_SUITE"
    STANDARD = "Standard"
    HOME_GYM_FULL = "HOME_GYM_FULL"
    CROSSFIT_BOX = "CROSSFIT_BOX"
    DUMBBELLS = "DUMBBELLS"
    BARBELL = "BARBELL"
    KETTLEBELLS = "KETTLEBELLS"
    PULL_UP_BAR = "PULL_UP_BAR"
    BENCH = "BENCH"
    DIP_STATION = "DIP_STATION"
    BANDS = "BANDS"
    RINGS_TRX = "RINGS_TRX"
    JUMP_ROPE = "JUMP_ROPE"
    WEIGHT_VEST = "WEIGHT_VEST"
    BIKE = "BIKE"
    HOME_TRAINER = "HOME_TRAINER"
    ROWER = "ROWER"
    TREADMILL = "TREADMILL"
    POOL = "POOL"

# --- PERFORMANCE METRICS SUB-SCHEMAS ---

class CyclingMetrics(BaseModel):
    cycling_max_power_15s: Optional[int] = Field(None, description="Puissance Max 15s (Watts)")
    cycling_max_power_3min: Optional[int] = Field(None, description="Puissance Max 3min (Watts)")
    cycling_max_power_20min: Optional[int] = Field(None, description="Puissance Max 20min (Watts)")
    cycling_ftp: Optional[int] = Field(None, description="Functional Threshold Power (Watts)")

class RunningMetrics(BaseModel):
    running_time_5k: Optional[Union[int, str]] = Field(None, description="Temps 5k (Secondes)")
    running_time_10k: Optional[Union[int, str]] = Field(None, description="Temps 10k (Secondes)")
    running_time_21k: Optional[Union[int, str]] = Field(None, description="Temps Semi (Secondes)")
    running_max_sprint_time: Optional[Union[int, str]] = Field(None, description="Sprint Max (Secondes)")

    @field_validator('running_time_5k', 'running_time_10k', 'running_time_21k', 'running_max_sprint_time', mode='before')
    def transform_time_to_seconds(cls, v):
        if v is None: return None
        if isinstance(v, int): return v
        if isinstance(v, float): return int(v)
        if isinstance(v, str):
            v = v.strip()
            if not v: return None
            parts = v.split(':')
            try:
                if len(parts) == 3:
                    return int(parts[0]) * 3600 + int(parts[1]) * 60 + int(float(parts[2]))
                elif len(parts) == 2:
                    return int(parts[0]) * 60 + int(float(parts[1]))
                elif v.isdigit():
                    return int(v)
            except ValueError:
                return v
        return v

class SwimmingMetrics(BaseModel):
    swimming_time_200m: Optional[Union[int, str]] = Field(None, description="Temps 200m (Secondes)")
    swimming_time_400m: Optional[Union[int, str]] = Field(None, description="Temps 400m (Secondes)")

    @field_validator('swimming_time_200m', 'swimming_time_400m', mode='before')
    def transform_swim_time(cls, v):
        if v is None: return None
        if isinstance(v, int): return v
        if isinstance(v, float): return int(v)
        if isinstance(v, str):
            v = v.strip()
            if not v: return None
            parts = v.split(':')
            try:
                if len(parts) == 3:
                    return int(parts[0]) * 3600 + int(parts[1]) * 60 + int(float(parts[2]))
                elif len(parts) == 2:
                    return int(parts[0]) * 60 + int(float(parts[1]))
                elif v.isdigit():
                    return int(v)
            except ValueError:
                return v
        return v

class PerformanceBaselineSchema(CyclingMetrics, RunningMetrics, SwimmingMetrics):
    # Champs suppl√©mentaires pour accepter les donn√©es brutes du mobile
    run_vma_est: Optional[str] = None
    cycling_ftp_est: Optional[str] = None
    swim_css_est: Optional[str] = None
    run_short_dist: Optional[float] = None
    run_short_min: Optional[float] = None
    run_short_sec: Optional[float] = None
    run_long_dist: Optional[float] = None
    run_long_min: Optional[float] = None
    run_long_sec: Optional[float] = None
    bike_short_min: Optional[float] = None
    bike_short_sec: Optional[float] = None
    bike_short_watts: Optional[float] = None
    bike_long_min: Optional[float] = None
    bike_long_sec: Optional[float] = None
    bike_long_watts: Optional[float] = None
    swim_200_min: Optional[float] = None
    swim_200_sec: Optional[float] = None
    swim_400_min: Optional[float] = None
    swim_400_sec: Optional[float] = None
    run_vma: Optional[float] = None
    bike_peak_5s: Optional[float] = None
    run_sprint_max: Optional[float] = None
    squat_1rm: Optional[float] = None
    bench_1rm: Optional[float] = None
    deadlift_1rm: Optional[float] = None
    pull_load: Optional[float] = None
    
    model_config = ConfigDict(extra='allow')

    @field_validator('*', mode='before')
    def clean_none_values(cls, v, info):
        """Nettoie les valeurs None et cha√Ænes vides."""
        if info.field_name not in ['run_vma_est', 'cycling_ftp_est', 'swim_css_est']:
            if v in [None, "", "null", "undefined"]:
                return None
        return v

# --- SUB-SCHEMAS FOR PROFILE ---

class BasicInfo(BaseModel):
    pseudo: Optional[str] = None
    email: Optional[str] = None
    birth_date: Optional[str] = None
    training_age: Optional[int] = 0
    biological_sex: Optional[str] = "MALE"

class PhysicalMetrics(BaseModel):
    height: float = 0
    weight: float = 0
    body_fat: Optional[float] = None
    resting_hr: Optional[int] = None
    sleep_quality_avg: Optional[int] = 5

class SportContext(BaseModel):
    sport: SportType = SportType.OTHER
    position: Optional[str] = None
    level: Optional[str] = "INTERMEDIATE"
    equipment: List[EquipmentType] = [EquipmentType.BODYWEIGHT_ZERO]

    @field_validator('equipment', mode='before')
    def migrate_legacy_equipment(cls, v):
        """Transforme les anciennes valeurs 'Standard' en 'COMMERCIAL_GYM'."""
        if not v:
            return [EquipmentType.BODYWEIGHT_ZERO]
        
        cleaned_list = []
        if isinstance(v, list):
            for item in v:
                if item == "Standard":
                    cleaned_list.append(EquipmentType.COMMERCIAL_GYM)
                else:
                    cleaned_list.append(item)
        return cleaned_list

class TrainingPreferences(BaseModel):
    days_available: List[str] = []
    duration_min: int = 60
    preferred_split: str = "Upper/Lower"

# --- MAIN PROFILE SCHEMAS ---

class AthleteProfileBase(BaseModel):
    basic_info: BasicInfo = Field(default_factory=BasicInfo)
    physical_metrics: PhysicalMetrics = Field(default_factory=PhysicalMetrics)
    sport_context: SportContext = Field(default_factory=SportContext)
    training_preferences: TrainingPreferences = Field(default_factory=TrainingPreferences)
    goals: Dict[str, Any] = {}
    constraints: Dict[str, Any] = {}
    injury_prevention: Dict[str, Any] = {}
    
    performance_baseline: Dict[str, Any] = Field(default_factory=dict)

    @field_validator('performance_baseline', mode='before')
    def parse_performance(cls, v):
        """Nettoie et valide les donn√©es de performance."""
        if v is None:
            return {}
        
        try:
            # Si c'est d√©j√† un dict, le nettoyer
            if isinstance(v, dict):
                # Supprimer les valeurs None et cha√Ænes vides (sauf les r√©sultats format√©s)
                cleaned = {}
                for key, value in v.items():
                    if value in [None, "", "null", "undefined"]:
                        continue
                    # Pour les r√©sultats format√©s, garder m√™me les cha√Ænes vides
                    if key in ['run_vma_est', 'cycling_ftp_est', 'swim_css_est'] and value == "":
                        continue
                    cleaned[key] = value
                return cleaned
            return {}
        except Exception as e:
            logger.error(f"Erreur validation performance_baseline: {e}")
            return {}

class AthleteProfileCreate(AthleteProfileBase):
    pass

class AthleteProfileResponse(AthleteProfileBase):
    id: int
    user_id: int
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None
    
    class Config:
        from_attributes = True

# --- ENGRAM SCHEMAS (NOUVEAU) ---

class CoachEngramBase(BaseModel):
    type: MemoryType
    impact: ImpactLevel = ImpactLevel.INFO
    status: MemoryStatus = MemoryStatus.ACTIVE
    content: str
    tags: List[str] = []
    start_date: Optional[datetime] = None
    end_date: Optional[datetime] = None

class CoachEngramCreate(CoachEngramBase):
    pass

class CoachEngramResponse(CoachEngramBase):
    id: int
    memory_id: int
    author: str
    created_at: Optional[datetime] = None # Mapp√© depuis start_date souvent
    
    class Config:
        from_attributes = True

# --- MEMORY SCHEMAS ---

class CoachMemoryResponse(BaseModel):
    id: int
    readiness_score: int = Field(alias="current_context", default=50)
    current_phase: str = "G√©n√©ral"
    flags: Dict[str, bool] = {}
    insights: Dict[str, Any] = {}
    
    # Pour inclure les engrammes dans la r√©ponse de m√©moire si besoin, 
    # mais pour l'instant on les charge via endpoint d√©di√©.
    
    @field_validator('readiness_score', mode='before')
    def extract_readiness(cls, v):
        if isinstance(v, dict):
            return v.get('readiness_score', 50)
        return v

    class Config:
        from_attributes = True

# --- WORKOUT SCHEMAS ---

class WorkoutSetBase(BaseModel):
    exercise_name: str
    set_order: int
    weight: Union[float, str] = 0.0
    reps: Union[float, str] = 0.0
    rpe: Optional[float] = 0.0
    rest_seconds: int = 0
    metric_type: str = "LOAD_REPS"

    @field_validator('weight', 'reps', mode='before')
    def parse_polymorphic_fields(cls, v):
        if isinstance(v, str):
            v = v.strip().replace(',', '.')
            if ':' in v:
                parts = v.split(':')
                try:
                    seconds = 0.0
                    if len(parts) == 2:
                        seconds = float(parts[0]) * 60 + float(parts[1])
                    elif len(parts) == 3:
                        seconds = float(parts[0]) * 3600 + float(parts[1]) * 60 + float(parts[2])
                    return seconds
                except ValueError:
                    return 0.0
            try:
                return float(v)
            except ValueError:
                return 0.0
        return v

class WorkoutSetCreate(WorkoutSetBase):
    pass

class WorkoutSessionCreate(BaseModel):
    date: date
    duration: float
    rpe: float
    energy_level: int = 5
    notes: Optional[str] = None
    ai_analysis: Optional[str] = None
    sets: List[WorkoutSetCreate] = []

class WorkoutSetResponse(WorkoutSetBase):
    id: int
    weight: float
    reps: float
    class Config:
        from_attributes = True

class WorkoutSessionResponse(WorkoutSessionCreate):
    id: int
    ai_analysis: Optional[str] = None
    sets: List[WorkoutSetResponse] = []
    class Config:
        from_attributes = True

# --- AI & GENERATION ---

class GenerateWorkoutRequest(BaseModel):
    profile_data: Dict[str, Any]
    context: Dict[str, Any]

class AIExercise(BaseModel):
    name: str
    sets: int
    reps: Union[str, int]
    rest: int
    tips: str
    recording_mode: str = "LOAD_REPS"
    @field_validator('reps')
    def force_string_reps(cls, v):
        return str(v)

class AIWorkoutPlan(BaseModel):
    title: str
    coach_comment: str
    warmup: List[str]
    exercises: List[AIExercise]
    cooldown: List[str]

# --- USER & AUTH ---

class UserCreate(BaseModel):
    username: str
    email: Optional[str] = None
    password: str

class UserResponse(BaseModel):
    id: int
    username: str
    email: Optional[str] = None
    profile_data: Optional[Dict[str, Any]] = None 
    
    @field_validator('profile_data', mode='before')
    def parse_profile_data(cls, v):
        if v is None:
            return {}
        if isinstance(v, dict):
            return v
        if isinstance(v, str):
            if not v.strip():
                return {}
            try:
                return json.loads(v)
            except json.JSONDecodeError:
                return {}
        return v

    class Config:
        from_attributes = True

class Token(BaseModel):
    access_token: str
    token_type: str

class TokenData(BaseModel):
    username: Optional[str] = None

# --- FEED ---

class FeedItemType(str, Enum):
    INFO = "INFO"
    ANALYSIS = "ANALYSIS"
    ACTION = "ACTION"
    ALERT = "ALERT"

class FeedItemCreate(BaseModel):
    type: FeedItemType
    title: str
    message: str
    priority: int = 1
    action_payload: Optional[Dict[str, Any]] = None

class FeedItemResponse(FeedItemCreate):
    id: str
    is_read: bool
    is_completed: bool
    created_at: datetime
    
    @field_validator('action_payload', mode='before')
    def parse_payload(cls, v):
        if isinstance(v, str) and v.strip():
            try: return json.loads(v)
            except: return None
        return v
    class Config:
        from_attributes = True

# --- PERFORMANCE & MISC ---

class OneRepMaxRequest(BaseModel):
    weight: float
    reps: int
class OneRepMaxResponse(BaseModel):
    estimated_1rm: float
    method_used: str
class ACWRRequest(BaseModel):
    history: List[Dict[str, Any]]
class ACWRResponse(BaseModel):
    ratio: float
    status: str
    color: str
    message: str
class ProfileAuditRequest(BaseModel):
    profile_data: Dict[str, Any]
class ProfileAuditResponse(BaseModel):
    markdown_report: str
class StrategyResponse(BaseModel):
    periodization_title: str
    phases: List[Any]
class WeeklyPlanResponse(BaseModel):
    schedule: List[Any]
    reasoning: str

class ProfileUpdate(BaseModel):
    profile_data: Dict[str, Any]
    
class ProfileSectionUpdate(BaseModel):
    section_data: Dict[str, Any]

class DailyMetrics(BaseModel):
    date: str
    weight: Optional[float] = None
    sleep_quality: Optional[int] = None
    resting_heart_rate: Optional[int] = None
    hrv: Optional[int] = None
    energy_level: Optional[int] = None
    muscle_soreness: Optional[int] = None
    perceived_stress: Optional[int] = None
    sleep_duration: Optional[float] = None

class GoalProgressUpdate(BaseModel):
    progress_value: int
    progress_note: Optional[str] = None
    achieved: bool = False

class AthleteProfileUpdate(AthleteProfileBase):
    pass-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/models/sql_models.py
================================================================================
from sqlalchemy import Column, Integer, String, Float, Date, ForeignKey, DateTime, Text, Boolean, JSON, Enum as SQLEnum
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
from app.core.database import Base
from app.models.enums import MemoryType, ImpactLevel, MemoryStatus

class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True, index=True)
    email = Column(String, unique=True, index=True, nullable=True)
    hashed_password = Column(String)
    
    # Legacy fields
    profile_data = Column(JSON, default={}) 
    strategy_data = Column(Text, nullable=True)
    weekly_plan_data = Column(Text, nullable=True)
    draft_workout_data = Column(Text, nullable=True)

    workouts = relationship("WorkoutSession", back_populates="owner")
    feed_items = relationship("FeedItem", back_populates="owner", cascade="all, delete-orphan")
    athlete_profile = relationship("AthleteProfile", back_populates="user", uselist=False, cascade="all, delete-orphan")

class AthleteProfile(Base):
    __tablename__ = "athlete_profiles"

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"), unique=True)

    basic_info = Column(JSON, default={})
    physical_metrics = Column(JSON, default={})
    sport_context = Column(JSON, default={})
    performance_baseline = Column(JSON, default={})
    injury_prevention = Column(JSON, default={})
    training_preferences = Column(JSON, default={})
    goals = Column(JSON, default={})
    constraints = Column(JSON, default={})

    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())

    user = relationship("User", back_populates="athlete_profile")
    coach_memory = relationship("CoachMemory", back_populates="athlete_profile", uselist=False, cascade="all, delete-orphan")

    @property
    def completion_percentage(self):
        sections = [
            self.basic_info, self.physical_metrics, self.sport_context,
            self.performance_baseline, self.injury_prevention,
            self.training_preferences, self.goals, self.constraints
        ]
        filled = sum(1 for section in sections if section and section != {})
        total = len(sections)
        return int((filled / total) * 100) if total > 0 else 0

    @property
    def is_complete(self):
        return self.completion_percentage >= 80

class CoachMemory(Base):
    __tablename__ = "coach_memories"

    id = Column(Integer, primary_key=True, index=True)
    athlete_profile_id = Column(Integer, ForeignKey("athlete_profiles.id"), unique=True)

    metadata_info = Column(JSON, default={}) 
    
    current_context = Column(JSON, default={})
    response_patterns = Column(JSON, default={})
    performance_baselines = Column(JSON, default={})
    adaptation_signals = Column(JSON, default={})
    sport_specific_insights = Column(JSON, default={})
    training_history_summary = Column(JSON, default={})
    athlete_preferences = Column(JSON, default={})
    coach_notes = Column(JSON, default={})
    memory_flags = Column(JSON, default={})

    last_updated = Column(DateTime(timezone=True), server_default=func.now())

    athlete_profile = relationship("AthleteProfile", back_populates="coach_memory")
    
    # [NOUVEAU] Relation vers les Engrammes
    engrams = relationship("CoachEngram", back_populates="memory", cascade="all, delete-orphan")

class CoachEngram(Base):
    """
    Unit√© de m√©moire structur√©e (Souvenir/R√®gle) pour le Coach IA.
    """
    __tablename__ = "coach_engrams"

    id = Column(Integer, primary_key=True, index=True)
    memory_id = Column(Integer, ForeignKey("coach_memories.id"), nullable=False)
    
    author = Column(String, default="COACH_AI")
    type = Column(SQLEnum(MemoryType), nullable=False)
    impact = Column(SQLEnum(ImpactLevel), nullable=False, default=ImpactLevel.INFO)
    status = Column(SQLEnum(MemoryStatus), nullable=False, default=MemoryStatus.ACTIVE)
    
    content = Column(Text, nullable=False)
    
    start_date = Column(DateTime(timezone=True), server_default=func.now())
    end_date = Column(DateTime(timezone=True), nullable=True)
    
    tags = Column(JSON, default=[]) # Ex: ["genou", "squat", "douleur"]

    # Relation parente
    memory = relationship("CoachMemory", back_populates="engrams")

class WorkoutSession(Base):
    __tablename__ = "workout_sessions"
    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"))
    date = Column(Date, index=True)
    duration = Column(Float)
    rpe = Column(Float)
    energy_level = Column(Integer, default=5) 
    notes = Column(Text, nullable=True)       
    ai_analysis = Column(Text, nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    owner = relationship("User", back_populates="workouts")
    sets = relationship("WorkoutSet", back_populates="session", cascade="all, delete-orphan")

class WorkoutSet(Base):
    __tablename__ = "workout_sets"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(Integer, ForeignKey("workout_sessions.id"))
    exercise_name = Column(String, index=True)
    set_order = Column(Integer)
    weight = Column(Float, default=0.0)
    reps = Column(Float, default=0.0)
    rpe = Column(Float, default=0.0)
    rest_seconds = Column(Integer, default=0)
    metric_type = Column(String, nullable=False, default="LOAD_REPS") 
    session = relationship("WorkoutSession", back_populates="sets")

class FeedItem(Base):
    __tablename__ = "feed_items"
    id = Column(String, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"))
    type = Column(String, index=True)
    title = Column(String)
    message = Column(String)
    action_payload = Column(Text, nullable=True)
    is_read = Column(Boolean, default=False)
    is_completed = Column(Boolean, default=False)
    priority = Column(Integer, default=1)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    owner = relationship("User", back_populates="feed_items")-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/routers/__init__.py
================================================================================
-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/routers/athlete_profiles.py
================================================================================
"""
Routeur unifi√© pour la gestion des profils athl√®tes
G√®re toutes les routes /api/v1/profiles/*
"""
import json
import logging
import re
from typing import List, Dict, Any, Optional
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from sqlalchemy.exc import IntegrityError
from sqlalchemy.sql import func

from app.core.database import get_db
from app.dependencies import get_current_user
from app.models import sql_models, schemas
from app.services.coach_memory.service import initialize_coach_memory
from app.validators.athlete_profile_validators import validate_athlete_profile

# Configuration du Logger pour le debugging
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

router = APIRouter(
    tags=["Profiles"]  # Tags unifi√©s
)

def transform_mobile_performance_data(raw_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Transforme les donn√©es brutes du mobile en format API compatible.
    """
    if not raw_data:
        return {}
    
    # Nettoyer d'abord les valeurs vides, nulles ou invalides
    cleaned_data = {}
    for key, value in raw_data.items():
        # Filtrer les valeurs vraiment vides
        if value is None:
            continue
        if isinstance(value, str) and value.strip() == "":
            continue
        if value == 0 or value == "0" or value == 0.0:
            continue
        if value == "null" or value == "undefined":
            continue
        
        cleaned_data[key] = value
    
    transformed = {}
    
    # 1. Extraire les valeurs num√©riques des r√©sultats format√©s
    if cleaned_data.get('run_vma_est'):
        try:
            match = re.search(r'(\d+\.?\d*)', str(cleaned_data['run_vma_est']))
            if match:
                vma_value = float(match.group(1))
                transformed['run_vma'] = vma_value
                # Optionnel: calculer le temps 5k √©quivalent
                if vma_value > 0:
                    transformed['running_time_5k'] = int(5000 / (vma_value * 1000/3600))
        except Exception as e:
            logger.debug(f"Erreur extraction run_vma_est: {e}")
    
    if cleaned_data.get('cycling_ftp_est'):
        try:
            match = re.search(r'(\d+\.?\d*)', str(cleaned_data['cycling_ftp_est']))
            if match:
                transformed['cycling_ftp'] = int(float(match.group(1)))
        except Exception as e:
            logger.debug(f"Erreur extraction cycling_ftp_est: {e}")
    
    if cleaned_data.get('swim_css_est'):
        try:
            match = re.search(r'(\d+):(\d+)', str(cleaned_data['swim_css_est']))
            if match:
                minutes = int(match.group(1))
                seconds = int(match.group(2))
                transformed['swimming_time_200m'] = minutes * 60 + seconds
        except Exception as e:
            logger.debug(f"Erreur extraction swim_css_est: {e}")
    
    # 2. Calculer les valeurs d√©riv√©es √† partir des inputs bruts
    # Course √† pied - Calcul VMA/CS
    try:
        required_fields = ['run_short_dist', 'run_short_min', 'run_short_sec', 
                          'run_long_dist', 'run_long_min', 'run_long_sec']
        
        # V√©rifier que tous les champs requis sont pr√©sents et valides
        fields_present = all(k in cleaned_data for k in required_fields)
        fields_valid = all(cleaned_data.get(k) not in [None, "", 0, 0.0] for k in required_fields)
        
        if fields_present and fields_valid:
            d1 = float(cleaned_data['run_short_dist'])
            t1 = float(cleaned_data['run_short_min']) * 60 + float(cleaned_data['run_short_sec'])
            d2 = float(cleaned_data['run_long_dist'])
            t2 = float(cleaned_data['run_long_min']) * 60 + float(cleaned_data['run_long_sec'])
            
            if t2 > t1 and d2 > d1:
                cs_mps = (d2 - d1) / (t2 - t1)
                vma_kmh = cs_mps * 3.6
                if 'run_vma' not in transformed:
                    transformed['run_vma'] = round(vma_kmh, 1)
                # Convertir en temps 5k pour compatibilit√© API
                if vma_kmh > 0 and 'running_time_5k' not in transformed:
                    transformed['running_time_5k'] = int(5000 / (vma_kmh * 1000/3600))
    except Exception as e:
        logger.debug(f"Calcul running non effectu√©: {e}")
    
    # V√©lo - Calcul FTP/CP
    try:
        required_fields = ['bike_short_min', 'bike_short_sec', 'bike_short_watts',
                          'bike_long_min', 'bike_long_sec', 'bike_long_watts']
        
        fields_present = all(k in cleaned_data for k in required_fields)
        fields_valid = all(cleaned_data.get(k) not in [None, "", 0, 0.0] for k in required_fields)
        
        if fields_present and fields_valid:
            t1 = float(cleaned_data['bike_short_min']) * 60 + float(cleaned_data['bike_short_sec'])
            p1 = float(cleaned_data['bike_short_watts'])
            t2 = float(cleaned_data['bike_long_min']) * 60 + float(cleaned_data['bike_long_sec'])
            p2 = float(cleaned_data['bike_long_watts'])
            
            if t2 != t1:
                w1 = p1 * t1
                w2 = p2 * t2
                cp = (w2 - w1) / (t2 - t1)
                if 'cycling_ftp' not in transformed:
                    transformed['cycling_ftp'] = int(cp)
    except Exception as e:
        logger.debug(f"Calcul cycling non effectu√©: {e}")
    
    # 3. Copier les autres champs num√©riques directement
    numeric_fields = ['run_sprint_max', 'bike_peak_5s', 'squat_1rm', 'bench_1rm', 
                     'deadlift_1rm', 'pull_load', 'run_vma', 'cycling_ftp']
    
    for field in numeric_fields:
        if field in cleaned_data:
            try:
                transformed[field] = float(cleaned_data[field])
            except (ValueError, TypeError):
                pass
    
    # 4. Pour compatibilit√© avec le sch√©ma Pydantic
    # Convertir les champs sp√©cifiques vers les noms d'API attendus
    if 'run_vma' in transformed:
        transformed['running_vma'] = transformed.pop('run_vma')
    
    # 5. Garder les donn√©es brutes nettoy√©es pour r√©f√©rence
    if cleaned_data:
        transformed['raw_mobile_data'] = cleaned_data
    
    logger.info(f"üìä Donn√©es performance transform√©es: {transformed}")
    return transformed

# --- ROUTE CRITIQUE POUR LE MOBILE ---

@router.get("/me", response_model=schemas.AthleteProfileResponse)
async def get_my_profile(
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    R√©cup√®re le profil de l'utilisateur connect√©.
    Si aucun profil n'existe, cr√©e un profil vide automatiquement.
    Route appel√©e par le mobile: GET /api/v1/profiles/me
    """
    profile = db.query(sql_models.AthleteProfile).filter(
        sql_models.AthleteProfile.user_id == current_user.id
    ).first()
    
    if not profile:
        logger.info(f"üìù Aucun profil trouv√© pour user {current_user.id}, cr√©ation d'un profil vide")
        
        # Cr√©er un profil vide
        profile = sql_models.AthleteProfile(
            user_id=current_user.id,
            basic_info={"pseudo": current_user.username},
            physical_metrics={},
            sport_context={},
            performance_baseline={},
            injury_prevention={},
            training_preferences={},
            goals={},
            constraints={}
        )
        
        db.add(profile)
        db.commit()
        db.refresh(profile)
        
        logger.info(f"‚úÖ Profil vide cr√©√© pour user {current_user.id}")
    
    return profile

@router.put("/me", response_model=schemas.AthleteProfileResponse)
async def update_my_profile(
    profile_update: schemas.AthleteProfileUpdate,
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    Met √† jour le profil de l'utilisateur connect√©.
    Si le profil n'existe pas, le cr√©e automatiquement.
    Route appel√©e par le mobile: PUT /api/v1/profiles/me
    """
    logger.info(f"‚ö° UPDATE /me demand√© pour user : {current_user.id}")
    
    profile = db.query(sql_models.AthleteProfile).filter(
        sql_models.AthleteProfile.user_id == current_user.id
    ).first()
    
    if not profile:
        logger.info(f"üìù Cr√©ation de profil via PUT /me pour user {current_user.id}")
        
        # Valider les donn√©es du profil
        try:
            validate_athlete_profile(profile_update.model_dump(exclude_unset=True))
        except ValueError as e:
            logger.error(f"Erreur de validation : {str(e)}")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=str(e)
            )
        
        # Cr√©er le profil
        profile = sql_models.AthleteProfile(
            user_id=current_user.id,
            basic_info=profile_update.basic_info or {},
            physical_metrics=profile_update.physical_metrics or {},
            sport_context=profile_update.sport_context or {},
            performance_baseline=profile_update.performance_baseline or {},
            injury_prevention=profile_update.injury_prevention or {},
            training_preferences=profile_update.training_preferences or {},
            goals=profile_update.goals or {},
            constraints=profile_update.constraints or {}
        )
        
        db.add(profile)
        db.commit()
        db.refresh(profile)
        
        logger.info(f"‚úÖ Profil cr√©√© via PUT /me pour user {current_user.id}")
        return profile
    
    # Si profil existe, mise √† jour
    # Conversion Pydantic -> Dict en excluant les valeurs None
    update_dict = profile_update.model_dump(exclude_unset=True)
    
    # Traiter les donn√©es de performance sp√©cialement
    if 'performance_baseline' in update_dict:
        perf_data = update_dict['performance_baseline']
        if perf_data:
            logger.info(f"üìä Donn√©es performance brutes re√ßues: {perf_data}")
            transformed_perf = transform_mobile_performance_data(perf_data)
            logger.info(f"üîÑ Donn√©es performance transform√©es: {transformed_perf}")
            update_dict['performance_baseline'] = transformed_perf
    
    # Liste des champs JSON dans le mod√®le SQL
    json_fields = [
        'basic_info', 'physical_metrics', 'sport_context',
        'performance_baseline', 'injury_prevention', 
        'training_preferences', 'goals', 'constraints'
    ]
    
    try:
        updated_sections = []
        
        for section, data in update_dict.items():
            if section in json_fields and data is not None:
                setattr(profile, section, data)
                updated_sections.append(section)
            elif hasattr(profile, section) and data is not None:
                setattr(profile, section, data)
        
        # Mettre √† jour le timestamp
        profile.updated_at = func.now()
        
        db.commit()
        db.refresh(profile)
        
        logger.info(f"‚úÖ Profil /me mis √† jour. Sections: {updated_sections}")
        return profile
        
    except Exception as e:
        db.rollback()
        logger.error(f"‚ùå Erreur update /me: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur de mise √† jour: {str(e)}"
        )

@router.post("/complete", response_model=schemas.AthleteProfileResponse, status_code=status.HTTP_201_CREATED)
async def create_complete_profile(
    profile_data: Dict[str, Any],
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    Cr√©e un profil athl√®te complet via le wizard
    Route alternative pour cr√©ation via wizard
    """
    logger.info(f"Cr√©ation de profil wizard pour l'utilisateur : {current_user.id}")
    
    # V√©rifier si l'utilisateur a d√©j√† un profil
    existing_profile = db.query(sql_models.AthleteProfile).filter(
        sql_models.AthleteProfile.user_id == current_user.id
    ).first()
    
    if existing_profile:
        logger.warning(f"Profil d√©j√† existant pour user {current_user.id}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Un profil existe d√©j√† pour cet utilisateur. Utilisez PUT /me pour mettre √† jour."
        )
    
    # Valider les donn√©es du profil
    try:
        validate_athlete_profile(profile_data)
    except ValueError as e:
        logger.error(f"Erreur de validation : {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    
    # Traiter les donn√©es de performance
    if 'performance_baseline' in profile_data:
        perf_data = profile_data['performance_baseline']
        if perf_data:
            transformed_perf = transform_mobile_performance_data(perf_data)
            profile_data['performance_baseline'] = transformed_perf
    
    # Cr√©er le profil
    athlete_profile = sql_models.AthleteProfile(
        user_id=current_user.id,
        basic_info=profile_data.get('basic_info', {}),
        physical_metrics=profile_data.get('physical_metrics', {}),
        sport_context=profile_data.get('sport_context', {}),
        performance_baseline=profile_data.get('performance_baseline', {}),
        injury_prevention=profile_data.get('injury_prevention', {}),
        training_preferences=profile_data.get('training_preferences', {}),
        goals=profile_data.get('goals', {}),
        constraints=profile_data.get('constraints', {})
    )
    
    try:
        db.add(athlete_profile)
        db.commit()
        db.refresh(athlete_profile)
        
        # Initialiser la m√©moire du coach
        initialize_coach_memory(athlete_profile, db)
        
        logger.info(f"Profil wizard cr√©√© avec succ√®s pour user {current_user.id}")
        return athlete_profile
        
    except IntegrityError as e:
        db.rollback()
        logger.error(f"Erreur d'int√©grit√© DB : {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Erreur d'int√©grit√© des donn√©es"
        )

# --- AUTRES ROUTES (optionnelles, pour compatibilit√©) ---

@router.get("/{profile_id}", response_model=schemas.AthleteProfileResponse)
async def get_profile(
    profile_id: int,
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    R√©cup√®re un profil athl√®te par ID
    """
    profile = db.query(sql_models.AthleteProfile).filter(
        sql_models.AthleteProfile.id == profile_id,
        sql_models.AthleteProfile.user_id == current_user.id
    ).first()
    
    if not profile:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Profil non trouv√©"
        )
    
    return profile

@router.put("/{profile_id}", response_model=schemas.AthleteProfileResponse)
async def update_profile(
    profile_id: int,
    profile_update: schemas.AthleteProfileUpdate,
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    Met √† jour compl√®tement un profil par ID
    """
    profile = db.query(sql_models.AthleteProfile).filter(
        sql_models.AthleteProfile.id == profile_id,
        sql_models.AthleteProfile.user_id == current_user.id
    ).first()
    
    if not profile:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Profil non trouv√©"
        )
    
    # Conversion Pydantic -> Dict
    update_dict = profile_update.model_dump(exclude_unset=True)
    
    # Traiter les donn√©es de performance
    if 'performance_baseline' in update_dict:
        perf_data = update_dict['performance_baseline']
        if perf_data:
            transformed_perf = transform_mobile_performance_data(perf_data)
            update_dict['performance_baseline'] = transformed_perf
    
    # Mettre √† jour chaque section
    for section, data in update_dict.items():
        if data is not None and hasattr(profile, section):
            setattr(profile, section, data)
    
    # Mettre √† jour le timestamp
    profile.updated_at = func.now()
    
    db.commit()
    db.refresh(profile)
    
    return profile

@router.patch("/{profile_id}/section/{section_name}")
async def update_profile_section(
    profile_id: int,
    section_name: str,
    section_update: schemas.ProfileSectionUpdate,
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    Met √† jour une section sp√©cifique du profil
    """
    profile = db.query(sql_models.AthleteProfile).filter(
        sql_models.AthleteProfile.id == profile_id,
        sql_models.AthleteProfile.user_id == current_user.id
    ).first()
    
    if not profile:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Profil non trouv√©"
        )
    
    # V√©rifier que la section existe
    valid_sections = [
        'basic_info', 'physical_metrics', 'sport_context',
        'performance_baseline', 'injury_prevention',
        'training_preferences', 'goals', 'constraints'
    ]
    
    if section_name not in valid_sections:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Section invalide. Options: {', '.join(valid_sections)}"
        )
    
    # Traiter les donn√©es de performance sp√©cialement
    if section_name == 'performance_baseline':
        perf_data = section_update.section_data
        if perf_data:
            transformed_perf = transform_mobile_performance_data(perf_data)
            setattr(profile, section_name, transformed_perf)
        else:
            setattr(profile, section_name, {})
    else:
        setattr(profile, section_name, section_update.section_data)
    
    # Mettre √† jour le timestamp
    profile.updated_at = func.now()
    
    db.commit()
    
    return {
        "message": "Section mise √† jour avec succ√®s"
    }

@router.get("/{profile_id}/completion")
async def get_profile_completion(
    profile_id: int,
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    R√©cup√®re le statut de compl√©tion du profil
    """
    profile = db.query(sql_models.AthleteProfile).filter(
        sql_models.AthleteProfile.id == profile_id,
        sql_models.AthleteProfile.user_id == current_user.id
    ).first()
    
    if not profile:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Profil non trouv√©"
        )
    
    # Calculer les sections manquantes
    sections = {
        'basic_info': profile.basic_info,
        'physical_metrics': profile.physical_metrics,
        'sport_context': profile.sport_context,
        'performance_baseline': profile.performance_baseline,
        'injury_prevention': profile.injury_prevention,
        'training_preferences': profile.training_preferences,
        'goals': profile.goals,
        'constraints': profile.constraints
    }
    
    missing_sections = []
    for name, value in sections.items():
        if not value or value == {}:
            missing_sections.append(name)
    
    total_sections = 8
    completed_sections = total_sections - len(missing_sections)
    completion_percentage = int((completed_sections / total_sections) * 100)
    
    return {
        "completion_percentage": completion_percentage,
        "is_complete": completion_percentage >= 80,
        "missing_sections": missing_sections,
        "total_sections": total_sections,
        "completed_sections": completed_sections
    }-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/routers/auth.py
================================================================================
from datetime import datetime, timedelta
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.security import OAuth2PasswordRequestForm
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.models import sql_models, schemas
from app.core import security

router = APIRouter(
    prefix="/auth",
    tags=["Authentication"]
)

@router.post("/signup", response_model=schemas.UserResponse, status_code=status.HTTP_201_CREATED)
async def create_user(user: schemas.UserCreate, db: Session = Depends(get_db)):
    """
    Inscription d'un nouvel utilisateur.
    Initialise imm√©diatement le 'sac de sport' (profile_data) pour √©viter les erreurs 500.
    """
    # 1. V√©rifier si le pseudo existe d√©j√†
    db_user = db.query(sql_models.User).filter(sql_models.User.username == user.username).first()
    if db_user:
        raise HTTPException(status_code=400, detail="Ce pseudo est d√©j√† pris.")
    
    # 2. V√©rifier si l'email existe d√©j√† (si fourni)
    if user.email:
        db_email = db.query(sql_models.User).filter(sql_models.User.email == user.email).first()
        if db_email:
            raise HTTPException(status_code=400, detail="Cet email est d√©j√† utilis√©.")
    
    # 3. Hasher le mot de passe
    hashed_pwd = security.get_password_hash(user.password)
    
    # 4. Pr√©parer le Casier (Profile Data JSON)
    # On initialise une structure propre pour que le reste de l'app ne plante pas sur du NULL.
    initial_profile_data = {
        "basic_info": {
            "pseudo": user.username,
            "email": user.email,
            "created_at": datetime.utcnow().isoformat()
        },
        "onboarding_completed": False,
        "physical_metrics": {},
        "goals": {},
        "stats": {
            "level": 1,
            "xp": 0
        }
    }
    
    # 5. Cr√©er l'utilisateur
    new_user = sql_models.User(
        username=user.username,
        email=user.email,
        hashed_password=hashed_pwd,
        profile_data=initial_profile_data # <--- C'est ici que la magie op√®re
    )
    
    try:
        db.add(new_user)
        db.commit()
        db.refresh(new_user)
        return new_user
    except Exception as e:
        db.rollback()
        # On log l'erreur pour le debug serveur, mais on renvoie une erreur propre au client
        print(f"üî• ERREUR CRITIQUE SIGNUP DB : {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, 
            detail="Erreur lors de la cr√©ation du compte. V√©rifiez les donn√©es."
        )

@router.post("/token", response_model=schemas.Token)
async def login_for_access_token(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(get_db)):
    """Login : V√©rifie pseudo/mot de passe et renvoie un Token JWT."""
    user = db.query(sql_models.User).filter(sql_models.User.username == form_data.username).first()
    
    if not user or not security.verify_password(form_data.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Pseudo ou mot de passe incorrect",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    access_token_expires = timedelta(minutes=security.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = security.create_access_token(
        data={"sub": user.username}, expires_delta=access_token_expires
    )
    
    return {"access_token": access_token, "token_type": "bearer"}-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/routers/coach.py
================================================================================
import os
import json
import re
import google.generativeai as genai
from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.dependencies import get_current_user
from app.models import sql_models, schemas
from app.models.schemas import (
    ProfileAuditRequest, ProfileAuditResponse, 
    StrategyResponse, WeeklyPlanResponse,
    GenerateWorkoutRequest, AIWorkoutPlan
)
from dotenv import load_dotenv
from datetime import date

load_dotenv()

router = APIRouter(
    prefix="/coach",
    tags=["AI Coach"]
)

# Configuration unique de l'IA
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# --- UTILITAIRES ---

def clean_ai_json(text: str) -> str:
    """
    Nettoie la r√©ponse de l'IA pour extraire uniquement le bloc JSON valide.
    G√®re les cas o√π l'IA ajoute des balises markdown ```json ... ```.
    """
    try:
        # On cherche le contenu entre ```json et ``` ou juste ``` et ```
        pattern = r"```(?:json)?\s*([\s\S]*?)\s*```"
        match = re.search(pattern, text)
        if match:
            return match.group(1).strip()
        return text.strip()
    except Exception:
        return text

# --- PROMPTS ---

def get_profile_analysis_prompt(profile_data):
    """G√©n√®re le prompt pour l'audit du profil."""
    profile_str = json.dumps(profile_data, ensure_ascii=False, indent=2)
    return f"""
    R√îLE : Tu es le Lead Sport Scientist d'une f√©d√©ration olympique (TitanFlow).
    TACHE : Auditer le profil d'un athl√®te et D√âFINIR LA LIGNE DIRECTRICE.
    
    DONN√âES BRUTES ATHL√àTE (JSON) :
    {profile_str}

    CONSIGNES D'ANALYSE :
    1. V√©rifie la coh√©rence "Niveau vs Performances".
    2. V√©rifie la coh√©rence "Objectif vs Logistique (Dispo)".
    3. Identifie les risques de blessures ou les incoh√©rences majeures.
    
    FORMAT DE SORTIE :
    R√©ponds UNIQUEMENT en Markdown bien format√©.
    Utilise des emojis. Sois direct, bienveillant mais exigeant.
    """

def get_periodization_prompt(profile_data):
    """G√©n√®re le prompt pour la strat√©gie de p√©riodisation (JSON)."""
    today_str = date.today().strftime("%Y-%m-%d")
    profile_str = json.dumps(profile_data, ensure_ascii=False, indent=2)
    cycle_goal = profile_data.get('goal', 'Performance G√©n√©rale')
    target_date_str = profile_data.get('target_date', '2025-12-31')

    return f"""
    R√îLE : Directeur de Performance Sportive (Haut Niveau).
    CONTEXTE : Cr√©er une P√âRIODISATION MACRO (Les Grandes Phases) pour un athl√®te.

    1. DONN√âES ATHL√àTE :
    {profile_str}

    2. PARAM√àTRES DU CYCLE :
    - Objectif : {cycle_goal}
    - Date actuelle : {today_str}
    - Deadline : {target_date_str}

    CONSIGNES DE P√âRIODISATION :
    - Divise la p√©riode en BLOCS (PHASES) de 3 √† 8 semaines.
    - G√©n√®re entre 3 et 6 phases majeures.

    STRUCTURE DE SORTIE (JSON STRICT) :
    {{
        "periodization_title": "Nom scientifique",
        "periodization_logic": "Justification courte.",
        "progression_model": "Ex: RPE Progression.",
        "recommended_frequency": 4, 
        "phases": [
            {{
                "phase_name": "Phase 1 : [Nom]",
                "focus": "Objectif physiologique",
                "intensity_metric": "RPE 7-8", 
                "volume_strategy": "Ex: Volume √âlev√©",
                "start": "YYYY-MM-DD",
                "end": "YYYY-MM-DD"
            }}
        ]
    }}
    """

def get_weekly_planning_prompt(profile_data):
    """G√©n√®re le prompt complexe pour la semaine type."""
    
    user_sport = profile_data.get('sport', 'Musculation')
    avail = profile_data.get('availability', [])
    
    slots_context = []
    for slot in avail:
        if slot.get('isActive', False): # Adaptation au format Flutter (isActive vs Active)
             slots_context.append({
                "Jour": slot.get('day'),
                "Moment": slot.get('moment'),
                "Dispo_Max": f"{slot.get('duration')} min",
                "Type_Cible": slot.get('type')
            })
    
    avail_json = json.dumps(slots_context, ensure_ascii=False, indent=2)

    return f"""
    R√îLE : Entra√Æneur Expert en {user_sport}.
    MISSION : G√©n√©rer la SEMAINE TYPE (Lundi-Dimanche) pour cet athl√®te.

    CONTEXTE ATHL√àTE :
    - Sport : {user_sport}
    - Niveau : {profile_data.get('level')}
    - Objectif : {profile_data.get('goal')}

    === CONTRAINTES STRICTES (MATRICE DE DISPONIBILIT√â) ===
    Tu DOIS respecter ces cr√©neaux √† la lettre. Si un jour n'est pas list√© ci-dessous, c'est REPOS.
    {avail_json}

    R√àGLES D'ALLOCATION :
    1. Pour chaque cr√©neau disponible, assigne une s√©ance pr√©cise.
    2. Respecte le "Type_Cible" impos√© par l'utilisateur :
       - "PPS" = Sport Sp√©cifique (Terrain, Piste, Bassin).
       - "PPG" = Renforcement / Muscu.
       - "Libre" = Choisis le mieux adapt√© pour l'√©quilibre.
    3. Si pas de cr√©neau dispo un jour -> "Type": "Repos", "Focus": "R√©cup√©ration".
    4. "RPE Cible" doit √™tre un ENTIER (ex: 0 pour Repos, 7 pour une s√©ance). Ne jamais mettre null.

    FORMAT DE SORTIE (JSON OBJET) :
    {{
        "schedule": [
            {{ "Jour": "Lundi", "Cr√©neau": "Soir", "Type": "Sp√©cifique (PPS)", "Focus": "...", "RPE Cible": 7 }},
            ... (14 entr√©es pour couvrir la semaine)
        ],
        "reasoning": "Explication courte de la logique de la semaine."
    }}
    """

def get_workout_generation_prompt(profile_data, context):
    """
    G√©n√®re une s√©ance d√©taill√©e avec gestion stricte des MODES D'ENREGISTREMENT.
    """
    sport = profile_data.get('sport', 'Musculation')
    user_level = profile_data.get('level', 'Interm√©diaire')
    
    duration = context.get('duration', 60)
    energy = context.get('energy', 5)
    focus = context.get('focus', 'Full Body')
    equipment = context.get('equipment', 'Standard')

    return f"""
    R√îLE : Coach Sportif d'√âlite (SmartCoach).
    MISSION : Concevoir une s√©ance sur-mesure (JSON).

    ATHL√àTE :
    - Sport : {sport} ({user_level})
    - Blessures : {profile_data.get('injuries', 'Aucune')}
    
    CONTEXTE DU JOUR :
    - Dur√©e Max : {duration} min
    - √ânergie : {energy}/10
    - Focus demand√© : {focus}
    - Mat√©riel : {equipment}

    INSTRUCTIONS TECHNIQUES CRITIQUES :
    1. Adapte le volume (S√©ries/Reps) √† l'√©nergie du jour.
    2. Pour CHAQUE exercice, tu DOIS choisir le 'recording_mode' adapt√© √† la nature de l'effort :
       - "LOAD_REPS" : Pour la musculation classique (Halt√®res, Barres, Machines). Champs : Poids/Reps.
       - "BODYWEIGHT_REPS" : Pour le poids du corps (Pompes, Tractions). Champs : Lest/Reps.
       - "ISOMETRIC_TIME" : Pour le statique (Gainage, Chaise). Champs : Lest/Temps(s).
       - "PACE_DISTANCE" : Pour le Cardio/Running/Natation. Champs : Allure/Distance(m).
       - "POWER_TIME" : Pour le V√©lo/Ergo. Champs : Watts/Temps(s).
    
    3. Le champ 'reps' peut √™tre une string (ex: "10-12" ou "AMRAP") ou un nombre.
    4. Le champ 'rest' est en secondes.

    STRUCTURE DE SORTIE (JSON STRICT) :
    {{
        "title": "Nom de la s√©ance",
        "coach_comment": "Phrase de motivation ou conseil technique.",
        "warmup": ["Exo 1", "Exo 2"],
        "exercises": [
            {{
                "name": "Squat",
                "sets": 4,
                "reps": "8-10",
                "rest": 90,
                "tips": "Dos droit, descendre sous la parall√®le.",
                "recording_mode": "LOAD_REPS"
            }}
        ],
        "cooldown": ["Etirement 1"]
    }}
    """

# --- ROUTES ---

@router.post("/audit", response_model=ProfileAuditResponse)
async def audit_profile(
    payload: ProfileAuditRequest,
    current_user: sql_models.User = Depends(get_current_user)
):
    """Audit du profil athl√®te par l'IA."""
    if not GEMINI_API_KEY:
        raise HTTPException(status_code=500, detail="Cl√© API Gemini manquante.")
    
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-2.0-flash')
        response = model.generate_content(get_profile_analysis_prompt(payload.profile_data))
        
        # Stocker l'audit localement
        from app.core.database import get_db
        from sqlalchemy.orm import Session
        db = next(get_db())
        current_user.profile_data = json.dumps(payload.profile_data)
        db.commit()
        
        return {"markdown_report": response.text}
    except Exception as e:
        print(f"‚ùå Erreur audit: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# --- STRAT√âGIE (Lecture & √âcriture Persistante) ---

@router.get("/strategy", response_model=StrategyResponse)
async def get_strategy(
    current_user: sql_models.User = Depends(get_current_user)
):
    """R√©cup√®re la strat√©gie sauvegard√©e (si elle existe)."""
    if not current_user.strategy_data:
        raise HTTPException(status_code=404, detail="Aucune strat√©gie trouv√©e.")
    try:
        data = json.loads(current_user.strategy_data)
        return data
    except Exception as e:
        print(f"‚ùå Erreur lecture strat√©gie: {e}")
        raise HTTPException(status_code=500, detail="Erreur lecture strat√©gie.")

@router.post("/strategy", response_model=StrategyResponse)
async def generate_strategy(
    payload: ProfileAuditRequest,
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """G√©n√®re ET sauvegarde la strat√©gie."""
    if not GEMINI_API_KEY:
        raise HTTPException(status_code=500, detail="Cl√© API Gemini manquante.")
    
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-2.0-flash', generation_config={"response_mime_type": "application/json"})
        response = model.generate_content(get_periodization_prompt(payload.profile_data))
        
        # Nettoyage et Validation JSON
        clean_text = clean_ai_json(response.text)
        strategy_data = json.loads(clean_text)
        
        # Sauvegarde en BDD
        current_user.strategy_data = json.dumps(strategy_data)
        db.commit()
        db.refresh(current_user)
        
        return strategy_data
    except Exception as e:
        print(f"‚ùå Erreur Strategy Gen: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# --- PLANNING SEMAINE (Lecture & √âcriture Persistante) ---

@router.get("/week", response_model=WeeklyPlanResponse)
async def get_week(
    current_user: sql_models.User = Depends(get_current_user)
):
    """R√©cup√®re la semaine type sauvegard√©e."""
    if not current_user.weekly_plan_data:
         raise HTTPException(status_code=404, detail="Aucune semaine trouv√©e.")
    try:
        data = json.loads(current_user.weekly_plan_data)
        return data
    except Exception as e:
        print(f"‚ùå Erreur lecture semaine: {e}")
        raise HTTPException(status_code=500, detail="Erreur lecture semaine.")

@router.post("/week", response_model=WeeklyPlanResponse)
async def generate_week(
    payload: ProfileAuditRequest,
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """G√©n√®re ET sauvegarde la semaine type."""
    if not GEMINI_API_KEY:
        raise HTTPException(status_code=500, detail="Cl√© API Gemini manquante.")
    
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-2.0-flash', generation_config={"response_mime_type": "application/json"})
        
        prompt = get_weekly_planning_prompt(payload.profile_data)
        response = model.generate_content(prompt)
        
        # Nettoyage et Parsing
        clean_text = clean_ai_json(response.text)
        result = json.loads(clean_text)
        
        if "schedule" not in result and isinstance(result, list):
            result = {"schedule": result, "reasoning": "G√©n√©r√© automatiquement."}
        
        # Sauvegarde en BDD
        current_user.weekly_plan_data = json.dumps(result)
        db.commit()
        db.refresh(current_user)
            
        return result
    except Exception as e:
        print(f"‚ùå Erreur Week Gen: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# --- GESTION DES S√âANCES & BROUILLONS ---

@router.get("/workout/draft", response_model=AIWorkoutPlan)
async def get_draft_workout(
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    R√©cup√®re le brouillon de s√©ance en cours (si existant).
    Utile pour reprendre une session apr√®s un crash.
    """
    if not current_user.draft_workout_data:
        raise HTTPException(status_code=404, detail="Aucun brouillon trouv√©.")
    
    try:
        return json.loads(current_user.draft_workout_data)
    except Exception as e:
        print(f"‚ùå Erreur lecture brouillon: {e}")
        raise HTTPException(status_code=500, detail="Erreur lecture brouillon.")

@router.delete("/workout/draft")
async def discard_draft_workout(
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    Supprime explicitement le brouillon (Abandon).
    """
    try:
        current_user.draft_workout_data = None
        db.commit()
        return {"status": "success", "message": "Brouillon supprim√©."}
    except Exception as e:
        print(f"‚ùå Erreur suppression brouillon: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/workout", response_model=AIWorkoutPlan)
async def generate_workout(
    payload: GenerateWorkoutRequest,
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    G√©n√®re une s√©ance d√©taill√©e ET la sauvegarde en brouillon.
    """
    if not GEMINI_API_KEY:
        raise HTTPException(status_code=500, detail="Cl√© API Gemini manquante.")
    
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-2.0-flash', generation_config={"response_mime_type": "application/json"})
        
        prompt = get_workout_generation_prompt(payload.profile_data, payload.context)
        response = model.generate_content(prompt)
        
        # Nettoyage et Parsing
        clean_text = clean_ai_json(response.text)
        parsed_response = json.loads(clean_text)
        
        # Validation de la structure
        if isinstance(parsed_response, list):
            if parsed_response:
                parsed_response = parsed_response[0]
            else:
                raise ValueError("L'IA a renvoy√© une liste vide.")
        
        # Validation des exercices
        if "exercises" not in parsed_response:
            parsed_response["exercises"] = []
        
        # S'assurer que chaque exercice a un recording_mode
        for exercise in parsed_response["exercises"]:
            if "recording_mode" not in exercise:
                exercise["recording_mode"] = "LOAD_REPS"
        
        # Sauvegarde automatique du brouillon
        current_user.draft_workout_data = json.dumps(parsed_response)
        db.commit()
        db.refresh(current_user)

        return parsed_response
    except json.JSONDecodeError as e:
        print(f"‚ùå Erreur JSON IA: {e}")
        print(f"Texte brut re√ßu: {clean_text[:500]}...")
        raise HTTPException(
            status_code=500, 
            detail="L'IA a renvoy√© une r√©ponse invalide. Veuillez r√©essayer."
        )
    except Exception as e:
        print(f"‚ùå Erreur Workout Gen: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"Erreur lors de la g√©n√©ration: {str(e)}"
        )-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/routers/coach_memories.py
================================================================================
from typing import List, Optional
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from sqlalchemy import select, desc

# --- IMPORTS PROJET (V√©rifie ces chemins selon ton dossier) ---
from database import get_db
import sql_models, schemas

router = APIRouter(
    prefix="/api/v1/coach-memories",
    tags=["Coach Memory v2"]
)

# ==============================================================================
# üì• GET ALL MEMORIES (Engrams)
# ==============================================================================
# ‚úÖ DOUBLE ROUTE : Accepte √† la fois la racine ET /engrams pour √©viter les 404
@router.get("/", response_model=List[schemas.CoachMemoryOut])
@router.get("/engrams", response_model=List[schemas.CoachMemoryOut]) 
async def get_memories(
    db: Session = Depends(get_db),
    limit: int = 50,
    status: Optional[str] = None
):
    """
    R√©cup√®re la liste des souvenirs du Coach (Engrams).
    Filtre optionnel par statut (ACTIVE, ARCHIVED, FORGOTTEN).
    Trie par date de cr√©ation descendante (plus r√©cent en premier).
    """
    query = select(sql_models.CoachMemory)
    
    if status:
        query = query.where(sql_models.CoachMemory.status == status)
    
    # Tri par d√©faut : les plus r√©cents d'abord
    query = query.order_by(desc(sql_models.CoachMemory.created_at))
    query = query.limit(limit)

    result = db.execute(query)
    memories = result.scalars().all()
    
    return memories

# ==============================================================================
# üì§ POST NEW MEMORY
# ==============================================================================
@router.post("/", response_model=schemas.CoachMemoryOut, status_code=status.HTTP_201_CREATED)
async def create_memory(
    memory_in: schemas.CoachMemoryCreate,
    db: Session = Depends(get_db)
):
    """
    Cr√©e un nouvel Engramme dans le Cortex (M√©moire long terme).
    """
    new_memory = sql_models.CoachMemory(
        user_id=memory_in.user_id if hasattr(memory_in, 'user_id') else 1, # Fallback ID si non fourni
        type=memory_in.type,
        impact=memory_in.impact,
        status=memory_in.status,
        content=memory_in.content,
        tags=memory_in.tags,
        start_date=memory_in.start_date,
        end_date=memory_in.end_date
    )
    
    db.add(new_memory)
    try:
        db.commit()
        db.refresh(new_memory)
        return new_memory
    except Exception as e:
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, 
            detail=f"Erreur lors de la sauvegarde du souvenir: {str(e)}"
        )

# ==============================================================================
# üóëÔ∏è DELETE MEMORY
# ==============================================================================
@router.delete("/{memory_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_memory(
    memory_id: int,
    db: Session = Depends(get_db)
):
    query = select(sql_models.CoachMemory).where(sql_models.CoachMemory.id == memory_id)
    result = db.execute(query)
    memory = result.scalar_one_or_none()

    if not memory:
        raise HTTPException(status_code=404, detail="Souvenir introuvable")

    db.delete(memory)
    db.commit()
    return None-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/routers/feed.py
================================================================================
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from typing import List
from app.core.database import get_db
from app.models import sql_models, schemas
from app.dependencies import get_current_user

router = APIRouter(
    prefix="/feed",
    tags=["Neural Feed"]
)

@router.get("/", response_model=List[schemas.FeedItemResponse])
async def get_my_feed(
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    R√©cup√®re le flux d'√©v√©nements de l'utilisateur.
    Filtre : Uniquement les items NON COMPL√âT√âS.
    Tri : Priorit√© (DESC) puis Date de cr√©ation (DESC).
    """
    items = db.query(sql_models.FeedItem)\
        .filter(sql_models.FeedItem.user_id == current_user.id)\
        .filter(sql_models.FeedItem.is_completed == False)\
        .order_by(sql_models.FeedItem.priority.desc(), sql_models.FeedItem.created_at.desc())\
        .all()
    return items

@router.patch("/{item_id}/read")
async def mark_as_read(
    item_id: str,
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """Marque un item comme LU (mais le laisse dans le flux tant que pas compl√©t√©)."""
    item = db.query(sql_models.FeedItem).filter(sql_models.FeedItem.id == item_id, sql_models.FeedItem.user_id == current_user.id).first()
    if not item:
        raise HTTPException(status_code=404, detail="Item introuvable")
    
    item.is_read = True
    db.commit()
    return {"status": "success"}

@router.patch("/{item_id}/complete")
async def mark_as_completed(
    item_id: str,
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """Marque un item comme COMPL√âT√â (Dispara√Æt du flux)."""
    item = db.query(sql_models.FeedItem).filter(sql_models.FeedItem.id == item_id, sql_models.FeedItem.user_id == current_user.id).first()
    if not item:
        raise HTTPException(status_code=404, detail="Item introuvable")
    
    item.is_completed = True
    db.commit()
    return {"status": "success"}-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/routers/performance.py
================================================================================
from fastapi import APIRouter, HTTPException
from app.models.schemas import OneRepMaxRequest, OneRepMaxResponse
from app.domain import calculations

router = APIRouter(
    prefix="/performance",
    tags=["Performance & Metrics"]
)

@router.post("/1rm", response_model=OneRepMaxResponse)
async def compute_one_rep_max(payload: OneRepMaxRequest):
    """
    Calcule le 1RM (One Rep Max) estim√© bas√© sur une performance.
    S√©lectionne automatiquement la meilleure formule (Epley, Brzycki, Wathan).
    """
    try:
        result = calculations.calculate_1rm(payload.weight, payload.reps)
        
        return {
            "estimated_1rm": result["1rm"],
            "method_used": result["method"],
            "input_weight": payload.weight,
            "input_reps": payload.reps
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/routers/profiles.py
================================================================================
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.models import sql_models, schemas
from app.dependencies import get_current_user
from app.services.coach_logic import CoachLogic

router = APIRouter(
    prefix="/api/v1",
    tags=["Athlete Profile & Memory"]
)

@router.get("/profiles/me", response_model=schemas.AthleteProfileResponse)
async def get_my_profile(
    current_user: sql_models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    if not current_user.athlete_profile:
        profile = sql_models.AthleteProfile(user_id=current_user.id)
        db.add(profile)
        db.commit()
        db.refresh(profile)
        return profile
    return current_user.athlete_profile

@router.post("/profiles/complete", response_model=schemas.AthleteProfileResponse)
async def complete_profile(
    profile_data: schemas.AthleteProfileCreate,
    current_user: sql_models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    sport = profile_data.sport_context.sport
    pos = profile_data.sport_context.position
    if not CoachLogic.validate_sport_position(sport, pos):
        raise HTTPException(status_code=400, detail=f"Position {pos} invalide pour le sport {sport}")

    db_profile = current_user.athlete_profile
    if not db_profile:
        db_profile = sql_models.AthleteProfile(user_id=current_user.id)
        db.add(db_profile)
    
    db_profile.basic_info = profile_data.basic_info.dict()
    db_profile.physical_metrics = profile_data.physical_metrics.dict()
    db_profile.sport_context = profile_data.sport_context.dict()
    db_profile.training_preferences = profile_data.training_preferences.dict()
    db_profile.goals = profile_data.goals
    db_profile.constraints = profile_data.constraints
    
    if not db_profile.coach_memory:
        memory = CoachLogic.initialize_memory(db_profile)
        db.add(memory)
    
    db.commit()
    db.refresh(db_profile)
    return db_profile

@router.get("/coach-memories/me", response_model=schemas.CoachMemoryResponse)
async def get_my_coach_memory(
    current_user: sql_models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    if not current_user.athlete_profile or not current_user.athlete_profile.coach_memory:
        raise HTTPException(status_code=404, detail="Profil ou M√©moire introuvable. Compl√©tez votre profil.")
    return current_user.athlete_profile.coach_memory

@router.post("/coach-memories/recalculate")
async def force_recalculate(
    current_user: sql_models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    profile = current_user.athlete_profile
    if not profile or not profile.coach_memory:
        raise HTTPException(status_code=404, detail="Introuvable")
        
    CoachLogic.update_daily(profile.coach_memory, profile)
    db.commit()
    return {"status": "updated", "new_readiness": profile.coach_memory.current_context.get('readiness_score')}
-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/routers/safety.py
================================================================================
from fastapi import APIRouter, HTTPException
from app.models.schemas import ACWRRequest, ACWRResponse
from app.domain import safety

router = APIRouter(
    prefix="/safety",
    tags=["Safety & Prevention"]
)

@router.post("/acwr", response_model=ACWRResponse)
async def compute_acwr_metrics(payload: ACWRRequest):
    """
    Calcule le Ratio Aigu/Chronique (ACWR) pour pr√©venir les blessures.
    Envoie l'historique des s√©ances (Date, Dur√©e, RPE).
    Retourne le statut de risque (Optimal, Surcharge, Danger).
    """
    try:
        # Conversion des mod√®les Pydantic en liste de dicts pour Pandas
        history_dicts = [log.dict() for log in payload.history]
        
        result = safety.calculate_acwr(history_dicts)
        
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/routers/user.py
================================================================================
import json
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import Dict, Any, Optional

from app.core.database import get_db
from app.models import sql_models, schemas
from app.dependencies import get_current_user

# üö® CORRECTIF ROUTING : On retire le pr√©fixe ici.
# Il sera inject√© depuis le main.py pour plus de contr√¥le.
router = APIRouter()

# --- ENDPOINTS PROFIL (Nouvelle Route: /api/v1/profiles/...) ---

@router.get("/me", response_model=schemas.UserResponse)
async def get_my_profile_data(
    current_user: sql_models.User = Depends(get_current_user),
):
    """
    R√©cup√®re le profil connect√©.
    URL Finale : GET /api/v1/profiles/me
    """
    if current_user.profile_data is None:
        current_user.profile_data = {}
    
    # SQLAlchemy avec type JSON renvoie d√©j√† un Dict, donc pas de parsing n√©cessaire ici.
    # Le validateur Pydantic (schemas.py) est l√† en s√©curit√© si jamais c'√©tait une string.
        
    return current_user

@router.post("/complete", response_model=schemas.UserResponse)
async def complete_profile(
    profile_update: schemas.ProfileUpdate,
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    Sauvegarde le profil complet.
    Logic : Input (Dict) -> DB (JSON Type - Auto Serialize) -> Output (Dict)
    """
    try:
        # 1. R√©cup√©ration des donn√©es brutes (Dict)
        data_dict = profile_update.profile_data
        
        # 2. [CORRECTION] Assignation DIRECTE du Dictionnaire
        # Le mod√®le SQL 'User' utilise le type JSON, SQLAlchemy g√®re la s√©rialisation.
        # On passe directement le dictionnaire Python.
        current_user.profile_data = data_dict
        
        # 3. Mise √† jour des champs relationnels (User table)
        if "basic_info" in data_dict:
            basic = data_dict["basic_info"]
            
            # Mise √† jour email si fourni et non vide
            if "email" in basic and basic["email"]:
                current_user.email = basic["email"]
            
            # Mise √† jour pseudo si fourni et non vide
            if "pseudo" in basic and basic["pseudo"]:
                current_user.username = basic["pseudo"]

        # Sauvegarde SQL effective
        db.commit()
        db.refresh(current_user)
        
        # 4. Retour
        # SQLAlchemy a mis √† jour current_user.profile_data qui est maintenant un Dict (gr√¢ce au type JSON).
        # Pydantic (UserResponse) attend un Dict. Tout est align√©.
        return current_user
        
    except Exception as e:
        db.rollback()
        # On log l'erreur pour le debug serveur
        print(f"üî• ERREUR CRITIQUE SAVE PROFILE: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur sauvegarde profil : {str(e)}"
        )

# --- SUPPORT LEGACY (Optionnel, conserv√© pour compatibilit√© existante) ---
# Ces routes seront d√©sormais pr√©fix√©es par /api/v1/profiles aussi via le main.py

@router.post("/sections/{section}")
async def update_profile_section(
    section: str,
    section_data: schemas.ProfileSectionUpdate,
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    Mise √† jour partielle d'une section.
    Adapt√© pour le type JSON de SQLAlchemy.
    """
    try:
        # 1. Chargement des donn√©es existantes
        # Avec le type JSON, SQLAlchemy nous renvoie directement un Dict ou None
        raw_data = current_user.profile_data
        
        current_data = {}
        if raw_data:
            if isinstance(raw_data, dict):
                current_data = raw_data.copy() # Copie pour √©viter les effets de bord
            elif isinstance(raw_data, str):
                # S√©curit√© au cas o√π d'anciennes donn√©es String tra√Ænent
                try:
                    current_data = json.loads(raw_data)
                except json.JSONDecodeError:
                    current_data = {}
        
        # 2. Mise √† jour de la section
        current_data[section] = section_data.section_data
        
        # 3. Sauvegarde (Direct Dict -> JSON Column)
        current_user.profile_data = current_data
        
        db.commit()
        
        return {
            "status": "success",
            "section": section,
            "updated_data": section_data.section_data
        }
    except Exception as e:
        db.rollback()
        print(f"üî• ERREUR LEGACY SECTION: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/routers/workouts.py
================================================================================
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from sqlalchemy.orm import Session
from typing import List
from app.core.database import get_db
from app.models import sql_models, schemas
from app.dependencies import get_current_user
import json

# Imports du Moteur de Feed
from app.services.feed.engine import TriggerEngine
from app.services.feed.triggers.workout_analysis import WorkoutAnalysisTrigger

router = APIRouter(
    prefix="/workouts",
    tags=["Workouts"]
)

@router.post("/", response_model=schemas.WorkoutSessionResponse)
async def create_workout(
    workout: schemas.WorkoutSessionCreate, 
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    Enregistre une s√©ance compl√®te avec gestion du Polymorphisme (Metric Type).
    V√©rifie la coh√©rence des donn√©es (ex: Watts max, RPE bounds).
    Supprime le brouillon associ√© une fois la s√©ance valid√©e.
    Active le Neural Feed pour l'analyse post-s√©ance.
    """

    # --- VALIDATION PHYSIOLOGIQUE ---
    def validate_physiological_limits(workout: schemas.WorkoutSessionCreate):
        """Valide les limites physiologiques humaines."""
        
        # Dur√©e r√©aliste (10min √† 4h)
        if workout.duration < 10 or workout.duration > 240:
            raise HTTPException(
                status_code=400, 
                detail=f"Dur√©e invalide ({workout.duration} min). Doit √™tre entre 10 et 240 minutes."
            )
        
        # RPE 1-10
        if workout.rpe < 1 or workout.rpe > 10:
            raise HTTPException(
                status_code=400,
                detail=f"RPE invalide ({workout.rpe}). Doit √™tre entre 1 et 10."
            )
        
        # √ânergie 1-10
        if workout.energy_level < 1 or workout.energy_level > 10:
            raise HTTPException(
                status_code=400,
                detail=f"Niveau d'√©nergie invalide ({workout.energy_level}). Doit √™tre entre 1 et 10."
            )
        
        # Validation des sets
        for s in workout.sets:
            # Watts max (record du monde ~2500W)
            if s.metric_type == 'POWER_TIME' and s.weight > 2000:
                raise HTTPException(
                    status_code=400,
                    detail=f"Puissance impossible ({s.weight}W). Record du monde ~2500W."
                )
            
            # Charge max (record +500kg)
            if s.metric_type == 'LOAD_REPS' and s.weight > 500:
                raise HTTPException(
                    status_code=400,
                    detail=f"Charge impossible ({s.weight}kg). Record du monde ~500kg."
                )
            
            # RPE s√©rie
            if s.rpe and (s.rpe < 1 or s.rpe > 10):
                raise HTTPException(
                    status_code=400,
                    detail=f"RPE s√©rie invalide ({s.rpe}). Doit √™tre entre 1 et 10."
                )
        
        return True

    # Appliquer la validation
    validate_physiological_limits(workout)

    # 1. Validation de haut niveau avant insertion
    for s in workout.sets:
        # Validation RPE
        if s.rpe is not None and (s.rpe < 0 or s.rpe > 10):
            # On cap plut√¥t que de crasher
            s.rpe = max(0, min(10, s.rpe))
            
        # Validation Physiologique selon le mode
        if s.metric_type == 'POWER_TIME':
            # Check Watts (weight)
            if s.weight > 2000:
                raise HTTPException(status_code=400, detail=f"Valeur impossible : {s.weight} Watts sur l'exercice {s.exercise_name}. V√©rifiez la saisie.")
        
        elif s.metric_type == 'PACE_DISTANCE':
            # Standard TitanFlow : Reps = Distance (m), Weight = 0 (ou vitesse m/s)
            if s.reps > 100000: # 100km max par s√©rie pour √™tre s√ªr
                 raise HTTPException(status_code=400, detail=f"Distance suspecte : {s.reps} m√®tres.")

    # 2. Cr√©ation de la Session (INSERT)
    db_workout = sql_models.WorkoutSession(
        date=workout.date,
        duration=workout.duration,
        rpe=workout.rpe,
        energy_level=workout.energy_level,
        notes=workout.notes,
        ai_analysis=workout.ai_analysis, # <--- AJOUT CRITIQUE POUR BE-03
        user_id=current_user.id
    )
    db.add(db_workout)
    db.commit()
    db.refresh(db_workout)
    
    # 3. Ajout des S√©ries (Sets)
    if workout.sets:
        for s in workout.sets:
            # Conversion explicite Pydantic -> SQL Model
            db_set = sql_models.WorkoutSet(
                session_id=db_workout.id,
                exercise_name=s.exercise_name,
                set_order=s.set_order,
                weight=s.weight, # D√©j√† nettoy√© par Pydantic (float)
                reps=s.reps,     # D√©j√† nettoy√© par Pydantic (float, secondes inclues)
                rpe=s.rpe,
                rest_seconds=s.rest_seconds, # <--- DEJA SUPPORTE PAR SQL MODEL
                metric_type=s.metric_type    # <--- DEJA SUPPORTE PAR SQL MODEL
            )
            db.add(db_set)
        
        # Nettoyage du brouillon apr√®s succ√®s
        current_user.draft_workout_data = None
        
        db.commit()
        db.refresh(db_workout)

    # 4. TRIGGER NEURAL FEED (L'IA s'active ici)
    try:
        # On passe le profil complet dans le contexte via user_data
        profile_data = {}
        if current_user.profile_data:
            try:
                profile_data = json.loads(current_user.profile_data)
            except:
                pass

        engine = TriggerEngine()
        engine.register(WorkoutAnalysisTrigger())
        await engine.run_all(db, current_user.id, {
            "workout": db_workout,
            "profile": profile_data
        })
    except Exception as e:
        # On ne bloque pas la r√©ponse si l'IA √©choue, c'est du bonus
        print(f"‚ö†Ô∏è Feed Engine Error: {e}")
    
    return db_workout

@router.get("/", response_model=List[schemas.WorkoutSessionResponse])
async def read_workouts(
    skip: int = 0, 
    limit: int = 100, 
    db: Session = Depends(get_db),
    current_user: sql_models.User = Depends(get_current_user)
):
    """
    R√©cup√®re l'historique complet.
    Les champs polymorphes (weight/reps) sont renvoy√©s tels quels,
    le Frontend utilisera 'metric_type' pour savoir si c'est des kg ou des watts.
    """
    workouts = db.query(sql_models.WorkoutSession)\
        .filter(sql_models.WorkoutSession.user_id == current_user.id)\
        .order_by(sql_models.WorkoutSession.date.desc())\
        .offset(skip)\
        .limit(limit)\
        .all()
    return workouts-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/services/coach_logic.py
================================================================================
from datetime import date
from typing import Dict, Any
from app.models import sql_models

VALID_SPORT_POSITIONS = {
    'Rugby': ['Pilier', 'Talonneur', '2√®me ligne', '3√®me ligne', 'Demi', 'Centre', 'Ailier', 'Arri√®re'],
    'Football': ['Gardien', 'D√©fenseur', 'Milieu', 'Attaquant'],
}

class CoachLogic:
    @staticmethod
    def validate_sport_position(sport: str, position: str) -> bool:
        if sport in VALID_SPORT_POSITIONS:
            if position and position not in VALID_SPORT_POSITIONS[sport]:
                return False
        return True

    @staticmethod
    def initialize_memory(profile: sql_models.AthleteProfile) -> sql_models.CoachMemory:
        sport = profile.sport_context.get('sport', 'Autre')
        insights = {
            "primary_sport": sport,
            "specificity_index": "High" if sport in ['Rugby', 'Football'] else "Medium",
            "focus_areas": ["Strength", "Hypertrophy"] 
        }
        context = {
            "macrocycle_phase": "Adaptation Anatomique",
            "fatigue_state": "Fresh",
            "readiness_score": 100,
            "season_week": 1
        }
        flags = {
            "needs_deload": False,
            "injury_risk": False,
            "adaptation_window_open": True
        }
        memory = sql_models.CoachMemory(
            athlete_profile_id=profile.id,
            sport_specific_insights=insights,
            current_context=context,
            memory_flags=flags,
            coach_notes={"initialization": f"Profil cr√©√© le {date.today()}"}
        )
        return memory

    @staticmethod
    def calculate_readiness(profile: sql_models.AthleteProfile) -> int:
        base_score = 80
        sleep = profile.physical_metrics.get('sleep_quality_avg', 5)
        if sleep >= 8: base_score += 10
        elif sleep <= 4: base_score -= 20
        stress = profile.constraints.get('work_stress_level', 5)
        if stress >= 8: base_score -= 15
        return max(0, min(100, base_score))

    @staticmethod
    def update_daily(memory: sql_models.CoachMemory, profile: sql_models.AthleteProfile):
        new_readiness = CoachLogic.calculate_readiness(profile)
        current_context = dict(memory.current_context or {})
        current_context['readiness_score'] = new_readiness
        
        if new_readiness < 40:
            current_context['fatigue_state'] = "High"
        elif new_readiness < 70:
            current_context['fatigue_state'] = "Moderate"
        else:
            current_context['fatigue_state'] = "Optimal"
            
        memory.current_context = current_context
        flags = dict(memory.memory_flags or {})
        flags['needs_deload'] = new_readiness < 30
        flags['adaptation_window_open'] = new_readiness > 70
        memory.memory_flags = flags
-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/services/coach_memory/service.py
================================================================================
"""
Service de gestion de la m√©moire du coach
"""
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
from sqlalchemy.orm import Session

from app.models import sql_models
from app.domain.bioenergetics import BioenergeticService

logger = logging.getLogger(__name__)

class CoachMemoryService:
    """Service principal pour la m√©moire du coach"""
    
    @staticmethod
    def initialize_coach_memory(athlete_profile: sql_models.AthleteProfile, db: Session) -> sql_models.CoachMemory:
        """Initialise la m√©moire du coach √† partir du profil"""
        logger.info(f"Initialisation de la m√©moire du coach pour l'athl√®te {athlete_profile.user_id}")
        
        # Extraire les donn√©es du profil
        basic_info = json.loads(athlete_profile.basic_info) if athlete_profile.basic_info else {}
        sport_context = json.loads(athlete_profile.sport_context) if athlete_profile.sport_context else {}
        performance_baseline = json.loads(athlete_profile.performance_baseline) if athlete_profile.performance_baseline else {}
        
        # Calculer les insights initiaux
        sport_insights = CoachMemoryService._calculate_initial_sport_insights(sport_context, basic_info)
        performance_baselines = CoachMemoryService._extract_initial_baselines(performance_baseline)
        initial_phase = CoachMemoryService._determine_initial_phase(athlete_profile)
        
        # Cr√©er la m√©moire
        memory = sql_models.CoachMemory(
            athlete_profile_id=athlete_profile.id,
            # [CORRECTION] Utilisation de metadata_info
            metadata_info=json.dumps({
                "athlete_id": athlete_profile.user_id,
                "created_at": datetime.utcnow().isoformat(),
                "last_updated": datetime.utcnow().isoformat(),
                "total_interactions": 0,
                "trust_score": 50,
                "data_points": 0
            }),
            current_context=json.dumps({
                'season_week': 1,
                'macrocycle_phase': initial_phase,
                'mesocycle_focus': 'base_fitness',
                'training_priority': 'volume',
                'next_competition': None,
                'days_to_competition': None,
                'fatigue_state': 'fresh',
                'readiness_score': 80,
                'current_constraints': json.loads(athlete_profile.constraints) if athlete_profile.constraints else {},
                'environmental_factors': {},
                'last_session_type': None,
                'last_session_rpe': None
            }),
            response_patterns=json.dumps({
                "volume_response": "neutral",
                "optimal_volumes": {},
                "intensity_tolerance": "medium",
                "recovery_profile": "normal",
                "fatigue_indicators": []
            }),
            performance_baselines=json.dumps(performance_baselines),
            adaptation_signals=json.dumps({
                "positive_adaptations": [],
                "last_adaptation_phase": None,
                "current_adaptation_status": "initial",
                "stagnation_signals": [],
                "regression_signals": [],
                "adaptation_windows": [],
                "next_suggested_focus": "base_fitness"
            }),
            sport_specific_insights=json.dumps(sport_insights),
            training_history_summary=json.dumps({
                "total_volume_by_type": {},
                "average_rpe_by_type": {},
                "successful_strategies": [],
                "failed_strategies": [],
                "lessons_learned": [],
                "seasonal_patterns": {},
                "best_training_weeks": [],
                "peak_periods": []
            }),
            athlete_preferences=json.dumps(json.loads(athlete_profile.training_preferences) if athlete_profile.training_preferences else {}),
            coach_notes=json.dumps({}),
            memory_flags=json.dumps({
                "needs_deload": False,
                "approaching_overtraining": False,
                "detraining_risk": False,
                "technique_regression": False,
                "adaptation_window_open": True,
                "pr_potential": False,
                "skill_integration_ready": False,
                "external_stress_high": False,
                "recovery_impaired": False,
                "motivation_low": False
            })
        )
        
        db.add(memory)
        db.commit()
        logger.info(f"M√©moire du coach cr√©√©e avec ID: {memory.id}")
        
        return memory
    
    @staticmethod
    def process_workout_session(
        coach_memory: sql_models.CoachMemory,
        athlete_profile: sql_models.AthleteProfile,
        session_data: Dict[str, Any],
        db: Session
    ) -> None:
        """Traite une s√©ance d'entra√Ænement et met √† jour la m√©moire"""
        logger.info(f"Traitement de la s√©ance pour la m√©moire {coach_memory.id}")
        
        # [CORRECTION] Mettre √† jour les m√©tadonn√©es via metadata_info
        metadata = json.loads(coach_memory.metadata_info) if coach_memory.metadata_info else {}
        metadata['total_interactions'] = metadata.get('total_interactions', 0) + 1
        metadata['last_updated'] = datetime.utcnow().isoformat()
        
        # Mettre √† jour le contexte
        context = json.loads(coach_memory.current_context) if coach_memory.current_context else {}
        context['last_session_type'] = session_data.get('type', 'unknown')
        context['last_session_rpe'] = session_data.get('rpe', 0)
        context['last_session_date'] = datetime.now().isoformat()
        
        # Mettre √† jour l'historique d'entra√Ænement
        history = json.loads(coach_memory.training_history_summary) if coach_memory.training_history_summary else {}
        
        session_type = session_data.get('type', 'strength')
        volume = session_data.get('volume', 0)
        rpe = session_data.get('rpe', 5)
        
        if 'total_volume_by_type' not in history:
            history['total_volume_by_type'] = {}
        
        history['total_volume_by_type'][session_type] = history['total_volume_by_type'].get(session_type, 0) + volume
        
        if 'average_rpe_by_type' not in history:
            history['average_rpe_by_type'] = {}
        
        if session_type not in history['average_rpe_by_type']:
            history['average_rpe_by_type'][session_type] = {'total': 0, 'count': 0}
        
        history['average_rpe_by_type'][session_type]['total'] += rpe
        history['average_rpe_by_type'][session_type]['count'] += 1
        
        # Calculer les r√©ponses √† l'entra√Ænement
        response_patterns = json.loads(coach_memory.response_patterns) if coach_memory.response_patterns else {}
        
        # [CORRECTION] Sauvegarde
        coach_memory.metadata_info = json.dumps(metadata)
        coach_memory.current_context = json.dumps(context)
        coach_memory.training_history_summary = json.dumps(history)
        coach_memory.response_patterns = json.dumps(response_patterns)
        
        db.commit()
        logger.info(f"S√©ance trait√©e pour la m√©moire {coach_memory.id}")
    
    # ... (Le reste des m√©thodes update_daily_context et generate_insights n'utilise pas metadata, on peut les laisser telles quelles)

    @staticmethod
    def recalculate_memory(
        coach_memory: sql_models.CoachMemory,
        athlete_profile: sql_models.AthleteProfile,
        db: Session
    ) -> None:
        """Recalcule compl√®tement la m√©moire"""
        logger.info(f"Recalcul complet de la m√©moire {coach_memory.id}")
        
        # [CORRECTION] Recalculer tous les composants via metadata_info
        metadata = json.loads(coach_memory.metadata_info) if coach_memory.metadata_info else {}
        metadata['last_recalculated'] = datetime.utcnow().isoformat()
        metadata['version'] = metadata.get('version', 1) + 1
        
        # Recalculer les performances de base
        performance_baseline = json.loads(athlete_profile.performance_baseline) if athlete_profile.performance_baseline else {}
        updated_baselines = CoachMemoryService._extract_initial_baselines(performance_baseline)
        
        # [CORRECTION] Mettre √† jour la m√©moire
        coach_memory.metadata_info = json.dumps(metadata)
        coach_memory.performance_baselines = json.dumps(updated_baselines)
        # Note: 'version' n'est pas une colonne SQL, elle est stock√©e dans le JSON metadata_info
        
        db.commit()
        logger.info(f"M√©moire {coach_memory.id} recalcul√©e - version {metadata['version']}")
    
    # ... (Les m√©thodes priv√©es helper et wrappers restent inchang√©es) ...

    # Wrappers pour compatibilit√©
    @staticmethod
    def update_daily_context(coach_memory, checkin_data, db):
        # ... Code existant inchang√© ...
        logger.info(f"Mise √† jour du contexte quotidien pour la m√©moire {coach_memory.id}")
        context = json.loads(coach_memory.current_context) if coach_memory.current_context else {}
        readiness_score = CoachMemoryService._calculate_readiness_score(checkin_data, context)
        context['readiness_score'] = readiness_score
        context['fatigue_state'] = CoachMemoryService._determine_fatigue_state(readiness_score)
        memory_flags = json.loads(coach_memory.memory_flags) if coach_memory.memory_flags else {}
        memory_flags['needs_deload'] = readiness_score < 40
        memory_flags['adaptation_window_open'] = readiness_score > 70
        memory_flags['recovery_impaired'] = checkin_data.get('sleep_quality', 5) < 4
        coach_memory.current_context = json.dumps(context)
        coach_memory.memory_flags = json.dumps(memory_flags)
        db.commit()
        logger.info(f"Contexte mis √† jour - Readiness: {readiness_score}")
        return context

    @staticmethod
    def generate_insights(coach_memory, athlete_profile, db):
        # ... Code existant inchang√© ...
        context = json.loads(coach_memory.current_context) if coach_memory.current_context else {}
        performance_baselines = json.loads(coach_memory.performance_baselines) if coach_memory.performance_baselines else {}
        sport_insights = json.loads(coach_memory.sport_specific_insights) if coach_memory.sport_specific_insights else {}
        insights = {
            "readiness_insight": CoachMemoryService._generate_readiness_insight(context),
            "fatigue_management": CoachMemoryService._generate_fatigue_insight(context),
            "progression_opportunities": CoachMemoryService._generate_progression_insights(performance_baselines),
            "sport_specific_recommendations": CoachMemoryService._generate_sport_recommendations(sport_insights),
            "risk_assessment": CoachMemoryService._generate_risk_assessment(coach_memory)
        }
        return insights

    # Helper methods (inchang√©s mais inclus pour r√©f√©rence de classe)
    @staticmethod
    def _calculate_initial_sport_insights(sport_context, basic_info):
        # ... (Identique √† l'original) ...
        return {"primary_sport": sport_context.get('primary_sport', 'Musculation')} 

    @staticmethod
    def _extract_initial_baselines(performance_baseline):
        # ... (Identique √† l'original) ...
        return {"current_prs": performance_baseline.get('current_prs', {})}

    @staticmethod
    def _determine_initial_phase(athlete_profile):
        # ... (Identique √† l'original) ...
        return "base_fitness"

    @staticmethod
    def _calculate_readiness_score(checkin_data, context):
        # ... (Identique √† l'original) ...
        return 80

    @staticmethod
    def _determine_fatigue_state(readiness_score):
        # ... (Identique √† l'original) ...
        return "fresh" if readiness_score >= 80 else "normal"

    @staticmethod
    def _generate_readiness_insight(context):
        return "Optimal"

    @staticmethod
    def _generate_fatigue_insight(context):
        return "Balanced"

    @staticmethod
    def _generate_progression_insights(performance_baselines):
        return []

    @staticmethod
    def _generate_sport_recommendations(sport_insights):
        return []

    @staticmethod
    def _generate_risk_assessment(coach_memory):
        return {"risk": "low"}

# Fonctions d'interface pour compatibilit√©
def initialize_coach_memory(athlete_profile: sql_models.AthleteProfile, db: Session) -> sql_models.CoachMemory:
    return CoachMemoryService.initialize_coach_memory(athlete_profile, db)

def process_workout_session(coach_memory, athlete_profile, session_data, db) -> None:
    return CoachMemoryService.process_workout_session(coach_memory, athlete_profile, session_data, db)

def update_daily_context(coach_memory, checkin_data, db) -> Dict[str, Any]:
    return CoachMemoryService.update_daily_context(coach_memory, checkin_data, db)

def generate_insights(coach_memory, athlete_profile, db) -> Dict[str, Any]:
    return CoachMemoryService.generate_insights(coach_memory, athlete_profile, db)

def recalculate_memory(coach_memory, athlete_profile, db) -> None:
    return CoachMemoryService.recalculate_memory(coach_memory, athlete_profile, db)-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/services/feed/engine.py
================================================================================
import logging
import uuid
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any
from sqlalchemy.orm import Session
from sqlalchemy import and_

from app.models import sql_models, schemas
from app.services.feed.triggers.base import BaseTrigger

# Configuration des logs pour ne pas perdre une miette du match
logger = logging.getLogger(__name__)

class TriggerEngine:
    """
    Le Moteur de Jeu.
    Il poss√®de un registre de Triggers et les ex√©cute tous pour un contexte donn√©.
    Il g√®re aussi la s√©curit√© (Anti-Crash) et la filtration (D√©duplication).
    """
    def __init__(self):
        self._registry: List[BaseTrigger] = []

    def register(self, trigger: BaseTrigger):
        """Enr√¥le un nouveau Trigger dans l'√©quipe."""
        self._registry.append(trigger)
        logger.info(f"‚úÖ Trigger enregistr√© : {trigger.__class__.__name__}")

    async def run_all(self, db: Session, user_id: int, context: Dict[str, Any]) -> List[sql_models.FeedItem]:
        """
        Lance tous les Triggers enregistr√©s.
        
        R√®gles du jeu :
        1. Isolation : Si un trigger plante, les autres continuent.
        2. D√©duplication : On √©vite de spammer le m√™me message (ex: 1x par 24h).
        3. Persistance : Sauvegarde imm√©diate en base.
        """
        generated_events = []

        for trigger in self._registry:
            try:
                # Le Trigger analyse le jeu...
                event_schema = await trigger.check(user_id, context)
                
                if event_schema:
                    # Arbitrage vid√©o (D√©duplication)
                    if not self._should_discard(db, user_id, event_schema):
                        
                        # Transformation Schema -> SQL Model
                        db_item = sql_models.FeedItem(
                            id=str(uuid.uuid4()),
                            user_id=user_id,
                            type=event_schema.type,
                            title=event_schema.title,
                            message=event_schema.message,
                            priority=event_schema.priority,
                            is_read=False,
                            is_completed=False,
                            # Gestion propre du JSON payload
                            action_payload=json.dumps(event_schema.action_payload) if event_schema.action_payload else None
                        )
                        
                        db.add(db_item)
                        generated_events.append(db_item)
                        logger.info(f"üì¢ Event g√©n√©r√© : {db_item.title} ({trigger.__class__.__name__})")
                    else:
                        logger.info(f"üîá Event ignor√© (Doublon) : {event_schema.title}")

            except Exception as e:
                # Carton jaune : Le trigger a plant√©, mais le match continue
                logger.error(f"‚ö†Ô∏è Erreur Trigger {trigger.__class__.__name__}: {str(e)}")
                continue

        # Coup de sifflet final : on valide les buts
        if generated_events:
            db.commit()
            for ev in generated_events:
                db.refresh(ev)
                
        return generated_events

    def _should_discard(self, db: Session, user_id: int, event: schemas.FeedItemCreate) -> bool:
        """
        V√©rifie si un √©v√©nement similaire existe d√©j√† r√©cemment.
        R√®gle actuelle : Pas de doublon (M√™me Titre + M√™me Type) non trait√©.
        Ou pas de doublon identique cr√©√© dans les derni√®res 24h.
        """
        # 1. Chercher si le m√™me event est d√©j√† en attente (Non compl√©t√©)
        existing_active = db.query(sql_models.FeedItem).filter(
            sql_models.FeedItem.user_id == user_id,
            sql_models.FeedItem.type == event.type,
            sql_models.FeedItem.title == event.title,
            sql_models.FeedItem.is_completed == False
        ).first()

        if existing_active:
            return True # On jette, l'utilisateur a d√©j√† √ßa dans son feed

        # 2. Chercher si le m√™me event a √©t√© cr√©√© il y a moins de 24h (Anti-Spam)
        one_day_ago = datetime.utcnow() - timedelta(hours=24)
        recent_duplicate = db.query(sql_models.FeedItem).filter(
            sql_models.FeedItem.user_id == user_id,
            sql_models.FeedItem.type == event.type,
            sql_models.FeedItem.title == event.title,
            sql_models.FeedItem.created_at >= one_day_ago
        ).first()

        if recent_duplicate:
            return True

        return False-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/services/feed/triggers/base.py
================================================================================
from abc import ABC, abstractmethod
from typing import Optional, Dict, Any
from app.models import schemas

class BaseTrigger(ABC):
    """
    Interface abstraite pour tous les d√©clencheurs d'√©v√©nements (Triggers).
    Chaque Trigger est un 'sp√©cialiste' (ex: Sp√©cialiste Analyse, Sp√©cialiste Sant√©).
    """

    @abstractmethod
    async def check(self, user_id: int, context: Dict[str, Any]) -> Optional[schemas.FeedItemCreate]:
        """
        Analyse le contexte et retourne un FeedItemCreate si la condition est remplie.
        Retourne None sinon.
        
        :param user_id: L'ID de l'athl√®te concern√©.
        :param context: Un dictionnaire riche contenant les donn√©es (ex: {'workout': ..., 'profile': ...})
        :return: Un objet FeedItemCreate pr√™t √† √™tre ins√©r√©, ou None.
        """
        pass-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/services/feed/triggers/workout_analysis.py
================================================================================
import os
import json
import re
import google.generativeai as genai
from typing import Dict, Any, Optional
from app.services.feed.triggers.base import BaseTrigger
from app.models import schemas, sql_models
from app.domain.bioenergetics import BioenergeticService

class WorkoutAnalysisTrigger(BaseTrigger):
    """
    Trigger : Analyse Post-S√©ance Avanc√©e (Bio-Twin + Gemini).
    Condition : Une s√©ance vient d'√™tre termin√©e.
    Action : 
        1. Calcule les m√©triques bio√©nerg√©tiques (Kcal, Macros).
        2. G√©n√®re un rapport JSON complet via IA.
        3. Sauvegarde le rapport dans la s√©ance (Persistance).
        4. Cr√©e une carte Feed pour notifier l'athl√®te.
    """
    
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")

    async def check(self, user_id: int, context: Dict[str, Any]) -> Optional[schemas.FeedItemCreate]:
        # 1. V√©rifie si le contexte contient les donn√©es requises
        workout: sql_models.WorkoutSession = context.get("workout")
        profile_data: Dict[str, Any] = context.get("profile", {})
        
        if not workout:
            return None

        # 2. Si pas de cl√© API, on sort silencieusement
        if not self.api_key:
            return None

        try:
            # 3. PHASE 1 : CALCULS BIO√âNERG√âTIQUES (Les Maths)
            bio_metrics = BioenergeticService.calculate_needs(
                profile_data, 
                workout.sets, 
                workout.duration, 
                workout.rpe
            )
            
            # 4. PHASE 2 : G√âN√âRATION IA (Le Cerveau)
            sets_summary = "\n".join([
                f"- {s.exercise_name}: {s.weight} (load/watts) x {s.reps} (reps/sec/m) [{s.metric_type}]"
                for s in workout.sets
            ])
            
            prompt = f"""
            R√îLE : Expert en Physiologie Sportive et Nutrition (TitanFlow).
            TACHE : Analyser la s√©ance et g√©n√©rer un rapport JSON strict.

            === DONN√âES ATHL√àTE ===
            - Profil : {json.dumps(profile_data, ensure_ascii=False)}
            
            === DONN√âES S√âANCE ===
            - Dur√©e : {workout.duration} min
            - RPE : {workout.rpe}/10 (Intensit√© Ressentie)
            - Contenu :
            {sets_summary}
            
            === DONN√âES BIO-TWIN (CALCUL√âES) ===
            - D√©pense : ~{bio_metrics['kcal_total']} kcal
            - Besoins Post-Effort (Estim√©s) : 
              * Prot√©ines : {bio_metrics['protein_g']}g
              * Glucides : {bio_metrics['carbs_g']}g
              * Eau : {bio_metrics['water_ml']}ml
            
            === STRUCTURE DE SORTIE (JSON UNIQUEMENT) ===
            {{
              "performance_analysis": "Analyse technique de la charge et du volume en 2 phrases max.",
              "nutrition_comment": "Conseil pr√©cis validant ou ajustant les macros calcul√©es ci-dessus.",
              "recovery_score": 8,
              "coach_questions": ["Question pertinente 1?", "Question pertinente 2?"],
              "food_suggestion": {{
                  "option_shake": "Ex: Whey + Banane",
                  "option_solid": "Ex: Poulet + Riz + L√©gumes"
              }},
              "feed_message": "Une phrase d'accroche tr√®s courte (max 12 mots) pour la notification."
            }}
            """

            genai.configure(api_key=self.api_key)
            model = genai.GenerativeModel('gemini-2.0-flash', generation_config={"response_mime_type": "application/json"})
            response = model.generate_content(prompt)
            
            # Nettoyage JSON
            json_str = self._clean_json(response.text)
            analysis_result = json.loads(json_str)

            # 5. PHASE 3 : PERSISTANCE (Sauvegarde en BDD)
            # On fusionne les m√©triques calcul√©es avec l'analyse IA
            full_report = {
                **analysis_result,
                "bio_metrics": bio_metrics
            }
            
            # On stocke le JSON stringifi√© dans la colonne ai_analysis de la s√©ance
            # Note: L'objet 'workout' est attach√© √† la session DB, donc le commit du TriggerEngine validera cette modif.
            workout.ai_analysis = json.dumps(full_report)

            # 6. PHASE 4 : NOTIFICATION (Le Feed)
            # On utilise le message court g√©n√©r√© par l'IA pour le feed
            feed_msg = analysis_result.get("feed_message", "Analyse de s√©ance disponible.")

            return schemas.FeedItemCreate(
                type=schemas.FeedItemType.ANALYSIS,
                title="Rapport de S√©ance",
                message=feed_msg,
                priority=5,
                action_payload={
                    "route": "/history", 
                    # On pourra passer des args pour ouvrir directement le d√©tail plus tard
                    "args": {"workout_id": workout.id}
                }
            )

        except Exception as e:
            print(f"‚ö†Ô∏è Erreur IA Analysis: {e}")
            # Fallback : Si l'IA plante, on ne cr√©e pas de FeedItem, 
            # ou on pourrait en cr√©er un g√©n√©rique. Ici on choisit la discr√©tion.
            return None

    def _clean_json(self, text: str) -> str:
        """Extrait le JSON si l'IA ajoute du markdown."""
        try:
            pattern = r"```(?:json)?\s*([\s\S]*?)\s*```"
            match = re.search(pattern, text)
            if match:
                return match.group(1).strip()
            return text.strip()
        except:
            return text-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/services/onboarding.py
================================================================================
import math
from typing import Dict, Any, Optional, List, Generic, TypeVar, Union
from pydantic import BaseModel
from dataclasses import dataclass

# --- TYPES G√âN√âRIQUES POUR LE PATTERN RESULT ---

T = TypeVar('T')

@dataclass
class ValidationError:
    field: str
    message: str
    value: Any

@dataclass
class ServiceResult(Generic[T]):
    success: bool
    data: Optional[T] = None
    errors: List[ValidationError] = None

    @staticmethod
    def ok(data: T) -> 'ServiceResult[T]':
        return ServiceResult(success=True, data=data)

    @staticmethod
    def fail(errors: List[ValidationError]) -> 'ServiceResult[T]':
        return ServiceResult(success=False, errors=errors)

# --- SERVICE D'ONBOARDING ---

class AthleteOnboardingService:
    """
    Service responsable de l'ingestion, de la validation et de l'enrichissement
    du profil athl√®te avant persistance.
    Agit comme un 'Expert Filter'.
    """

    @staticmethod
    def process_profile(raw_profile_data: Dict[str, Any]) -> ServiceResult[Dict[str, Any]]:
        """
        Traite les donn√©es brutes du profil.
        1. Valide les garde-fous (Sanity Checks).
        2. G√®re les Null-States (Flags).
        3. Calcule les m√©triques d√©riv√©es (CSS, Relative Strength).
        """
        errors = []
        enriched_data = raw_profile_data.copy()
        
        # Initialisation des sous-structures si absentes
        if 'performance_baseline' not in enriched_data:
            enriched_data['performance_baseline'] = {}
        if 'physical_metrics' not in enriched_data:
            enriched_data['physical_metrics'] = {}
        if 'memory_flags' not in enriched_data:
            enriched_data['memory_flags'] = {}

        perf = enriched_data['performance_baseline']
        phys = enriched_data['physical_metrics']
        flags = enriched_data['memory_flags']

        # --- 1. NULL-STATE LOGIC (Les drapeaux) ---
        
        # Check Force
        squat_1rm = perf.get('squat_1rm')
        if not squat_1rm:
            flags['NEEDS_TESTING_FORCE'] = True
            flags['force_status'] = "Unknown"
        else:
            flags['NEEDS_TESTING_FORCE'] = False
            flags['force_status'] = "Tested"

        # Check A√©robie (VMA)
        vma = perf.get('vma')
        if not vma:
            flags['NEEDS_TESTING_AEROBIC'] = True
            flags['aerobic_status'] = "Unknown"
        else:
            flags['NEEDS_TESTING_AEROBIC'] = False
            flags['aerobic_status'] = "Tested"

        # --- 2. SANITY CHECKS (Les Garde-fous) ---

        # VMA Humaine Max (~26km/h pour Kipchoge sur marathon, on est large mais safe)
        if vma and (isinstance(vma, (int, float))):
            if vma > 26.0:
                errors.append(ValidationError(
                    field="vma", 
                    message="VMA suspecte (> 26 km/h). √ätes-vous s√ªr ?", 
                    value=vma
                ))
            if vma < 3.0: # Marcher c'est 4-5km/h
                 errors.append(ValidationError(
                    field="vma", 
                    message="VMA trop faible (< 3 km/h).", 
                    value=vma
                ))

        # Poids de corps
        weight = phys.get('weight')
        if weight and (weight < 30 or weight > 250):
             errors.append(ValidationError(
                field="weight", 
                message="Poids hors normes physiologiques (30-250kg).", 
                value=weight
            ))

        # --- 3. COMPUTED FIELDS (Calculs Automatiques) ---

        # Relative Strength (Force Relative)
        if squat_1rm and weight and weight > 0:
            try:
                ratio = round(float(squat_1rm) / float(weight), 2)
                perf['relative_strength_squat'] = ratio
            except (ValueError, TypeError):
                pass # On ignore silencieusement si les types sont foireux (clean√©s par Pydantic ailleurs normalement)

        # Critical Swim Speed (CSS)
        # Formule : CSS = (400 - 200) / (T400 - T200)
        # T en secondes.
        t400 = perf.get('swim_400m_time_sec')
        t200 = perf.get('swim_200m_time_sec')

        if t400 and t200:
            try:
                t400_f = float(t400)
                t200_f = float(t200)
                
                delta_dist = 200.0 # 400m - 200m
                delta_time = t400_f - t200_f

                if delta_time <= 0:
                    errors.append(ValidationError(
                        field="swim_times", 
                        message="Le temps au 400m doit √™tre sup√©rieur au temps au 200m.", 
                        value=f"400:{t400}, 200:{t200}"
                    ))
                else:
                    css = round(delta_dist / delta_time, 2) # m/s

                    # Sanity Check CSS
                    if css < 0.5 or css > 2.5:
                        errors.append(ValidationError(
                            field="calculated_css", 
                            message=f"CSS calcul√© ({css} m/s) hors limites (0.5 - 2.5 m/s). V√©rifiez les temps.", 
                            value=css
                        ))
                    else:
                        perf['critical_swim_speed'] = css
                        
            except (ValueError, TypeError):
                # Si les inputs ne sont pas des nombres propres
                errors.append(ValidationError(
                    field="swim_times", 
                    message="Format des temps de natation invalide.", 
                    value=f"400:{t400}, 200:{t200}"
                ))

        # Si erreurs bloquantes, on rejette tout
        if errors:
            return ServiceResult.fail(errors)

        # Mise √† jour des donn√©es enrichies
        enriched_data['performance_baseline'] = perf
        enriched_data['memory_flags'] = flags
        
        return ServiceResult.ok(enriched_data)-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/services/schedule_validator.py
================================================================================
from typing import List, Dict, Optional
from dataclasses import dataclass
from app.models.domain import AthleteProfileDomain, TimeSlot
from app.models.enums import SlotStatus, LocationContext, CoachingMandate

@dataclass
class ConstraintWarning:
    """
    Avertissement g√©n√©r√© par le validateur pour l'interface utilisateur.
    """
    code: str
    message: str
    affected_days: List[str]

class ScheduleValidatorService:
    """
    Moteur de r√®gles physiologiques et logistiques.
    V√©rifie la coh√©rence du planning AVANT la g√©n√©ration du programme.
    """

    # Mapping temporel pour identifier les contigu√Øt√©s
    TIME_ORDER = {"Matin": 0, "Midi": 1, "Soir": 2}
    DAYS_ORDER = ["Lundi", "Mardi", "Mercredi", "Jeudi", "Vendredi", "Samedi", "Dimanche"]

    @staticmethod
    def validate_and_tag(profile: AthleteProfileDomain) -> List[ConstraintWarning]:
        """
        Applique les r√®gles strictes (Hard Rules).
        Modifie le profil IN-PLACE (ajout de tags) et retourne des warnings.
        """
        warnings: List[ConstraintWarning] = []
        
        # On trie la matrice pour faciliter l'analyse s√©quentielle
        # (M√™me si elle devrait l'√™tre, on s'assure de l'ordre Lundi Matin -> Dimanche Soir)
        sorted_slots = sorted(
            profile.time_matrix,
            key=lambda s: (
                ScheduleValidatorService.DAYS_ORDER.index(s.day_of_week),
                ScheduleValidatorService.TIME_ORDER[s.time_of_day]
            )
        )

        # --- R√àGLE 1 : CONFLIT mTOR/AMPK AIGU ---
        # Si slot EXTERNE INTENSE (PPS, RPE >= 7), le slot PR√âC√âDENT (<6h) est brid√©.
        
        for i, slot in enumerate(sorted_slots):
            if slot.status == SlotStatus.EXTERNAL_LOCKED and slot.external_load:
                # V√©rification des conditions d√©clenchantes
                is_pps = "PPS" in slot.external_load.type.upper() or "MATCH" in slot.external_load.type.upper()
                is_high_intensity = slot.external_load.estimated_rpe >= 7
                
                if (is_pps or is_high_intensity):
                    # Identifier le slot pr√©c√©dent
                    # Condition < 6h : On regarde uniquement le cr√©neau d'avant LE M√äME JOUR.
                    # (Soir J-1 -> Matin J est > 6h de sommeil en g√©n√©ral, donc hors scope conflit aigu imm√©diat)
                    if i > 0:
                        prev_slot = sorted_slots[i-1]
                        same_day = prev_slot.day_of_week == slot.day_of_week
                        
                        # Si c'est le m√™me jour et que le slot pr√©c√©dent est contigu
                        # Matin -> Midi OU Midi -> Soir
                        time_diff = ScheduleValidatorService.TIME_ORDER[slot.time_of_day] - ScheduleValidatorService.TIME_ORDER[prev_slot.time_of_day]
                        
                        if same_day and time_diff == 1:
                            # APPLICATION DE LA SANCTION PHYSIOLOGIQUE
                            if "RESTRICTED_LEG_VOLUME" not in prev_slot.tags:
                                prev_slot.tags.append("RESTRICTED_LEG_VOLUME")
                                warnings.append(ConstraintWarning(
                                    code="INTERFERENCE_ALERT",
                                    message=f"Interf√©rence d√©tect√©e le {slot.day_of_week}. Le volume jambes sera r√©duit avant votre s√©ance de {slot.external_load.type}.",
                                    affected_days=[slot.day_of_week]
                                ))

        # --- R√àGLE 2 : R√âCUP√âRATION SYST√àME NERVEUX (CNS) ---
        # Si PPG_ONLY + Charge Externe > 10h/semaine -> Cap Force
        
        if profile.mandate == CoachingMandate.PPG_ONLY:
            total_external_minutes = sum(
                s.external_load.duration_min 
                for s in sorted_slots 
                if s.status == SlotStatus.EXTERNAL_LOCKED and s.external_load
            )
            
            if total_external_minutes > 600: # 10 heures
                warnings.append(ConstraintWarning(
                    code="CNS_PROTECTION",
                    message="Charge externe √©lev√©e (>10h). Programme de force plafonn√© √† 2 s√©ances/semaine pour pr√©server le syst√®me nerveux.",
                    affected_days=[]
                ))
                # On taggue tous les slots disponibles pour informer le g√©n√©rateur
                for s in sorted_slots:
                    if s.status == SlotStatus.AVAILABLE:
                        s.tags.append("FORCE_VOLUME_CAP_2_SESSIONS")

        # --- R√àGLE 3 : LOGISTIQUE (MAT√âRIEL) ---
        # Si Location == HOME -> Pas de Deadlift (Lourd)
        
        home_days = []
        for slot in sorted_slots:
            if slot.location == LocationContext.HOME:
                if "NO_DEADLIFT" not in slot.tags:
                    slot.tags.append("NO_DEADLIFT")
                    # On √©vite les doublons de jours pour le warning
                    if slot.day_of_week not in home_days:
                        home_days.append(slot.day_of_week)
        
        if home_days:
            warnings.append(ConstraintWarning(
                code="LOGISTICS_LIMIT",
                message="S√©ances √† domicile d√©tect√©es : Les exercices n√©cessitant une barre olympique (ex: Deadlift) seront adapt√©s.",
                affected_days=home_days
            ))

        return warnings-e 

-e 
================================================================================
üìÑ FICHIER : backend/app/validators/athlete_profile_validators.py
================================================================================
"""
Validateurs pour les profils athl√®tes
"""
import re
from datetime import datetime
from typing import Dict, Any, Optional

# Sport ‚Üî Position coh√©rence
VALID_SPORT_POSITIONS = {
    'Rugby': ['Pilier', 'Talonneur', '2√®me ligne', '3√®me ligne', 'Demi', 'Centre', 'Ailier', 'Arri√®re'],
    'Football': ['Gardien', 'D√©fenseur', 'Milieu', 'Attaquant'],
    'Basketball': ['Meneur', 'Arri√®re', 'Ailier', 'Ailier fort', 'Pivot'],
    'Natation': ['Nage libre', 'Dos', 'Brasse', 'Papillon', '4 nages'],
    'Athl√©tisme': ['Sprint', 'Demi-fond', 'Fond', 'Haies', 'Saut', 'Lancer'],
    'Musculation': ['Powerlifting', 'Weightlifting', 'Bodybuilding', 'CrossFit', 'G√©n√©ral'],
    'Cyclisme': ['Route', 'Piste', 'VTT', 'Cyclocross'],
    'Triathlon': ['Sprint', 'Olympique', 'Half-Ironman', 'Ironman'],
    'Escalade': ['Bloc', 'Difficult√©', 'Vitesse'],
    'Arts martiaux': ['Judo', 'BJJ', 'Boxe', 'Muay Thai', 'MMA']
}

# Note : VALID_COMPETITION_LEVELS a √©t√© supprim√© car le niveau est d√©sormais calcul√© par le backend.

def validate_athlete_profile(profile_data: Dict[str, Any]) -> bool:
    """
    Valide la coh√©rence globale d'un profil athl√®te
    """
    errors = []
    
    # Valider le contexte sportif
    if 'sport_context' in profile_data:
        errors.extend(validate_sport_context(profile_data['sport_context']))
    
    # Valider les m√©triques physiques
    if 'physical_metrics' in profile_data:
        errors.extend(validate_physical_metrics(profile_data['physical_metrics']))
    
    # Valider les objectifs
    if 'goals' in profile_data:
        errors.extend(validate_goals(profile_data['goals']))
    
    # Valider les informations de base
    if 'basic_info' in profile_data:
        errors.extend(validate_basic_info(profile_data['basic_info']))

    # Valider les performances (y compris les nouvelles m√©triques)
    if 'performance_baseline' in profile_data:
        errors.extend(validate_performance_baseline(profile_data['performance_baseline']))
    
    if errors:
        raise ValueError(" | ".join(errors))
    
    return True

def validate_performance_baseline(perf_data: Dict[str, Any]) -> list:
    """Valide les donn√©es de performance, maintenant en entiers (secondes/watts)."""
    errors = []
    
    # 1. Validation Running (Secondes)
    running_limits = {
        'running_time_5k': (700, 7200),       # ~11min √† 2h
        'running_time_10k': (1500, 14400),    # ~25min √† 4h
        'running_time_21k': (3400, 28800),    # ~56min √† 8h
        'running_max_sprint_time': (5, 60)    # Sprint court
    }

    for field, (min_s, max_s) in running_limits.items():
        val = perf_data.get(field)
        if val is not None:
            if not isinstance(val, int):
                errors.append(f"{field} format invalide (doit √™tre un entier ou HH:MM:SS valide).")
            elif val < min_s or val > max_s:
                 errors.append(f"{field} valeur {val}s hors normes physiologiques ({min_s}s - {max_s}s).")

    # 2. Validation Swimming (Secondes)
    swim_limits = {
        'swimming_time_200m': (90, 1800),    # ~1:30 √† 30min
        'swimming_time_400m': (200, 3600),   # ~3:20 √† 1h
    }

    for field, (min_s, max_s) in swim_limits.items():
        val = perf_data.get(field)
        if val is not None:
            if not isinstance(val, int):
                errors.append(f"{field} format invalide (doit √™tre un entier ou MM:SS valide).")
            elif val < min_s or val > max_s:
                 errors.append(f"{field} valeur {val}s hors normes physiologiques ({min_s}s - {max_s}s).")

    # 3. Validation Cycling (Watts)
    for field in ['cycling_max_power_15s', 'cycling_max_power_3min', 'cycling_max_power_20min', 'cycling_ftp']:
        val = perf_data.get(field)
        if val is not None:
            if not isinstance(val, int) or val < 0 or val > 3000:
                 errors.append(f"{field} doit √™tre un entier positif r√©aliste (Watts)")

    return errors

def validate_sport_context(sport_context: Dict[str, Any]) -> list:
    """Valide le contexte sportif"""
    errors = []
    
    primary_sport = sport_context.get('primary_sport')
    if not primary_sport:
        errors.append("Le sport principal est requis")
    
    playing_position = sport_context.get('playing_position')
    if playing_position and primary_sport in VALID_SPORT_POSITIONS:
        if playing_position not in VALID_SPORT_POSITIONS[primary_sport]:
            errors.append(f"Position '{playing_position}' invalide pour le sport '{primary_sport}'")
    
    training_history = sport_context.get('training_history_years')
    if training_history and (training_history < 0 or training_history > 50):
        errors.append(f"Ann√©es d'entra√Ænement invalides: {training_history}")
    
    # [MODIF V2] Suppression de la validation de 'competition_level' car le champ a √©t√© retir√©.
    # [MODIF V2] Validation de l'√©quipement (optionnel, assur√© par Pydantic Enum, mais on peut ajouter des r√®gles m√©tier ici si besoin)
    
    return errors

def validate_physical_metrics(metrics: Dict[str, Any]) -> list:
    """Valide les m√©triques physiques"""
    errors = []
    
    # Validation BMI
    if metrics.get('weight') and metrics.get('height'):
        weight = float(metrics['weight'])
        height = float(metrics['height']) / 100  # Convertir en m√®tres
        
        if height <= 0:
            errors.append("La taille doit √™tre positive")
        elif weight <= 0:
            errors.append("Le poids doit √™tre positif")
        else:
            bmi = weight / (height ** 2)
            if not (16 <= bmi <= 40):
                errors.append(f"BMI {bmi:.1f} hors des limites plausibles (16-40)")
    
    # Validation fr√©quence cardiaque
    resting_hr = metrics.get('resting_heart_rate')
    if resting_hr:
        hr = float(resting_hr)
        if not (30 <= hr <= 120):
            errors.append(f"Fr√©quence cardiaque au repos {hr} hors limites (30-120 bpm)")
    
    # Validation pourcentage de graisse
    body_fat = metrics.get('body_fat_estimate')
    if body_fat:
        bf = float(body_fat)
        if not (5 <= bf <= 50):
            errors.append(f"Pourcentage de graisse {bf}% hors limites (5-50%)")
    
    # Validation qualit√© de sommeil
    sleep_quality = metrics.get('sleep_quality_average')
    if sleep_quality:
        sq = float(sleep_quality)
        if not (1 <= sq <= 10):
            errors.append(f"Qualit√© de sommeil {sq} hors √©chelle (1-10)")
    
    return errors

def validate_goals(goals: Dict[str, Any]) -> list:
    """Valide les objectifs"""
    errors = []
    
    primary_goal = goals.get('primary_goal')
    if not primary_goal:
        errors.append("L'objectif principal est requis")
    
    target_date = goals.get('target_date')
    if target_date:
        try:
            target = datetime.strptime(target_date, '%Y-%m-%d')
            if target < datetime.now():
                errors.append("La date cible ne peut pas √™tre dans le pass√©")
        except ValueError:
            errors.append(f"Format de date invalide: {target_date}")
    
    # Valider les m√©triques cibles
    target_metrics = goals.get('target_metrics', {})
    for metric, value in target_metrics.items():
        if isinstance(value, (int, float)) and value <= 0:
            errors.append(f"M√©trique cible '{metric}' doit √™tre positive")
    
    return errors

def validate_basic_info(basic_info: Dict[str, Any]) -> list:
    """Valide les informations de base"""
    errors = []
    
    # Validation email
    email = basic_info.get('email')
    if email and not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', email):
        errors.append("Format d'email invalide")
    
    # Validation date de naissance
    birth_date = basic_info.get('birth_date')
    if birth_date:
        try:
            birth = datetime.strptime(birth_date, '%Y-%m-%d')
            if birth > datetime.now():
                errors.append("La date de naissance ne peut pas √™tre dans le futur")
            
            # Calculer l'√¢ge
            age = datetime.now().year - birth.year
            if not (10 <= age <= 100):
                errors.append(f"√Çge {age} hors limites plausibles (10-100 ans)")
        except ValueError:
            errors.append(f"Format de date de naissance invalide: {birth_date}")
    
    # Validation √¢ge biologique
    bio_age = basic_info.get('biological_age')
    if bio_age and (bio_age < 10 or bio_age > 100):
        errors.append(f"√Çge biologique {bio_age} hors limites (10-100)")
    
    # Validation √¢ge d'entra√Ænement
    training_age = basic_info.get('training_age')
    if training_age and (training_age < 0 or training_age > 50):
        errors.append(f"√Çge d'entra√Ænement {training_age} hors limites (0-50)")
    
    # Validation sexe biologique
    biological_sex = basic_info.get('biological_sex')
    if biological_sex and biological_sex not in ['Homme', 'Femme', 'Autre']:
        errors.append(f"Sexe biologique invalide: {biological_sex}")
    
    # Validation main dominante
    dominant_hand = basic_info.get('dominant_hand')
    if dominant_hand and dominant_hand not in ['Droitier', 'Gaucher', 'Ambidextre']:
        errors.append(f"Main dominante invalide: {dominant_hand}")
    
    return errors

def validate_sport_position(sport: str, position: Optional[str]) -> bool:
    """Valide la coh√©rence sport/position"""
    if not position:
        return True
    
    if sport in VALID_SPORT_POSITIONS:
        return position in VALID_SPORT_POSITIONS[sport]
    
    return True

def validate_training_preferences(preferences: Dict[str, Any]) -> list:
    """Valide les pr√©f√©rences d'entra√Ænement"""
    errors = []
    
    max_duration = preferences.get('max_session_duration')
    if max_duration and (max_duration < 15 or max_duration > 240):
        errors.append(f"Dur√©e maximale de session {max_duration} hors limites (15-240 min)")
    
    feedback_style = preferences.get('feedback_style')
    if feedback_style and feedback_style not in ['Direct', 'Encourageant', 'Technique', 'Mixte']:
        errors.append(f"Style de feedback invalide: {feedback_style}")
    
    autonomy_preference = preferences.get('autonomy_preference')
    if autonomy_preference and autonomy_preference not in ['Faible', 'Moyenne', 'Forte']:
        errors.append(f"Pr√©f√©rence d'autonomie invalide: {autonomy_preference}")
    
    return errors

def validate_injury_prevention(injury_data: Dict[str, Any]) -> list:
    """Valide les donn√©es de pr√©vention des blessures"""
    errors = []
    
    medical_clearance = injury_data.get('medical_clearance')
    if medical_clearance is False:
        errors.append("Avis m√©dical requis pour l'entra√Ænement")
    
    return errors-e 

-e 
================================================================================
üìÑ FICHIER : backend/backend/app/models/core_models.py
================================================================================
from sqlalchemy import Column, Integer, String, Float, Date, ForeignKey, DateTime, Text, Boolean, JSON
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
from app.core.database import Base

class User(Base):
    __tablename__ = "users"
    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True, index=True)
    email = Column(String, unique=True, index=True, nullable=True)
    hashed_password = Column(String)
    profile_data = Column(Text, nullable=True)
    strategy_data = Column(Text, nullable=True)
    weekly_plan_data = Column(Text, nullable=True)
    draft_workout_data = Column(Text, nullable=True)
    workouts = relationship("WorkoutSession", back_populates="owner")
    feed_items = relationship("FeedItem", back_populates="owner", cascade="all, delete-orphan")
    athlete_profile = relationship("AthleteProfile", back_populates="user", uselist=False, cascade="all, delete-orphan")

class AthleteProfile(Base):
    __tablename__ = "athlete_profiles"
    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"), unique=True)
    basic_info = Column(JSON, default={})
    physical_metrics = Column(JSON, default={})
    sport_context = Column(JSON, default={})
    performance_baseline = Column(JSON, default={})
    injury_prevention = Column(JSON, default={})
    training_preferences = Column(JSON, default={})
    goals = Column(JSON, default={})
    constraints = Column(JSON, default={})
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    user = relationship("User", back_populates="athlete_profile")
    coach_memory = relationship("CoachMemory", back_populates="athlete_profile", uselist=False, cascade="all, delete-orphan")

class CoachMemory(Base):
    __tablename__ = "coach_memories"
    id = Column(Integer, primary_key=True, index=True)
    athlete_profile_id = Column(Integer, ForeignKey("athlete_profiles.id"), unique=True)
    metadata_info = Column(JSON, default={})
    current_context = Column(JSON, default={})
    response_patterns = Column(JSON, default={})
    performance_baselines = Column(JSON, default={})
    adaptation_signals = Column(JSON, default={})
    sport_specific_insights = Column(JSON, default={})
    training_history_summary = Column(JSON, default={})
    athlete_preferences = Column(JSON, default={})
    coach_notes = Column(JSON, default={})
    memory_flags = Column(JSON, default={})
    last_updated = Column(DateTime(timezone=True), server_default=func.now())
    athlete_profile = relationship("AthleteProfile", back_populates="coach_memory")

class WorkoutSession(Base):
    __tablename__ = "workout_sessions"
    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"))
    date = Column(Date, index=True)
    duration = Column(Float)
    rpe = Column(Float)
    energy_level = Column(Integer, default=5) 
    notes = Column(Text, nullable=True)      
    ai_analysis = Column(Text, nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    owner = relationship("User", back_populates="workouts")
    sets = relationship("WorkoutSet", back_populates="session", cascade="all, delete-orphan")

class WorkoutSet(Base):
    __tablename__ = "workout_sets"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(Integer, ForeignKey("workout_sessions.id"))
    exercise_name = Column(String, index=True)
    set_order = Column(Integer)
    weight = Column(Float, default=0.0)
    reps = Column(Float, default=0.0)
    rpe = Column(Float, default=0.0)
    rest_seconds = Column(Integer, default=0)
    metric_type = Column(String, nullable=False, default="LOAD_REPS") 
    session = relationship("WorkoutSession", back_populates="sets")

class FeedItem(Base):
    __tablename__ = "feed_items"
    id = Column(String, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"))
    type = Column(String, index=True)
    title = Column(String)
    message = Column(String)
    action_payload = Column(Text, nullable=True)
    is_read = Column(Boolean, default=False)
    is_completed = Column(Boolean, default=False)
    priority = Column(Integer, default=1)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    owner = relationship("User", back_populates="feed_items")
-e 

-e 
================================================================================
üìÑ FICHIER : backend/backend/app/models/schemas.py
================================================================================
from pydantic import BaseModel, Field, field_validator, ConfigDict
from typing import List, Optional, Dict, Any, Union
from datetime import date, datetime
import json

# --- SUB-SCHEMAS ---

class BasicInfo(BaseModel):
    pseudo: Optional[str] = None
    email: Optional[str] = None
    birth_date: Optional[str] = None
    biological_sex: Optional[str] = "Homme"
    training_age: Optional[int] = 0

class PhysicalMetrics(BaseModel):
    height: Optional[float] = 0
    weight: Optional[float] = 0
    body_fat: Optional[float] = None
    resting_hr: Optional[int] = None
    sleep_quality_avg: Optional[int] = 5

class SportContext(BaseModel):
    # [FIX 422] On accepte tout ce qui vient du Frontend
    sport: Optional[str] = "Autre"
    position: Optional[str] = None
    level: Optional[str] = "Interm√©diaire"
    equipment: Optional[List[str]] = ["Standard"]

class TrainingPreferences(BaseModel):
    days_available: List[str] = []
    duration_min: int = 60
    preferred_split: str = "Upper/Lower"

# --- MAIN PROFILE ---

class AthleteProfileBase(BaseModel):
    basic_info: BasicInfo = Field(default_factory=BasicInfo)
    physical_metrics: PhysicalMetrics = Field(default_factory=PhysicalMetrics)
    sport_context: SportContext = Field(default_factory=SportContext)
    training_preferences: TrainingPreferences = Field(default_factory=TrainingPreferences)
    
    # Dictionnaires libres pour le reste
    goals: Dict[str, Any] = {}
    constraints: Dict[str, Any] = {}
    injury_prevention: Dict[str, Any] = {}
    performance_baseline: Dict[str, Any] = {}

class AthleteProfileCreate(AthleteProfileBase):
    pass

class AthleteProfileResponse(AthleteProfileBase):
    id: int
    user_id: int
    created_at: Optional[datetime] = None
    class Config:
        from_attributes = True

# --- OTHER SCHEMAS (REQUIRED FOR BUILD) ---

class CoachMemoryResponse(BaseModel):
    id: int
    readiness_score: int = Field(alias="current_context", default=50)
    current_phase: str = "G√©n√©ral"
    flags: Dict[str, bool] = {}
    insights: Dict[str, Any] = {}
    @field_validator('readiness_score', mode='before')
    def extract_readiness(cls, v):
        if isinstance(v, dict): return v.get('readiness_score', 50)
        return v
    class Config:
        from_attributes = True

class WorkoutSetBase(BaseModel):
    exercise_name: str
    set_order: int
    weight: Union[float, str] = 0.0
    reps: Union[float, str] = 0.0
    rpe: Optional[float] = 0.0
    rest_seconds: int = 0
    metric_type: str = "LOAD_REPS"
    @field_validator('weight', 'reps', mode='before')
    def parse_polymorphic_fields(cls, v):
        if isinstance(v, str):
            try: return float(v.replace(',', '.'))
            except: return 0.0
        return v

class WorkoutSetCreate(WorkoutSetBase): pass
class WorkoutSetResponse(WorkoutSetBase):
    id: int
    weight: float
    reps: float
    class Config: from_attributes = True

class WorkoutSessionCreate(BaseModel):
    date: date
    duration: float
    rpe: float
    energy_level: int = 5
    notes: Optional[str] = None
    sets: List[WorkoutSetCreate] = []
    ai_analysis: Optional[str] = None

class WorkoutSessionResponse(WorkoutSessionCreate):
    id: int
    ai_analysis: Optional[str] = None
    sets: List[WorkoutSetResponse] = []
    class Config: from_attributes = True

class GenerateWorkoutRequest(BaseModel):
    profile_data: Dict[str, Any]
    context: Dict[str, Any]

class AIExercise(BaseModel):
    name: str
    sets: int
    reps: Union[str, int]
    rest: int
    tips: str
    recording_mode: str = "LOAD_REPS"
    @field_validator('reps')
    def force_string_reps(cls, v): return str(v)

class AIWorkoutPlan(BaseModel):
    title: str
    coach_comment: str
    warmup: List[str]
    exercises: List[AIExercise]
    cooldown: List[str]

class UserCreate(BaseModel):
    username: str
    email: Optional[str] = None
    password: str

class UserResponse(BaseModel):
    id: int
    username: str
    email: Optional[str] = None
    profile_data: Optional[Dict[str, Any]] = None
    @field_validator('profile_data', mode='before')
    def parse_profile_data(cls, v):
        if v is None: return {}
        if isinstance(v, dict): return v
        try: return json.loads(v)
        except: return {}
    class Config: from_attributes = True

class Token(BaseModel):
    access_token: str
    token_type: str

class TokenData(BaseModel):
    username: Optional[str] = None

class FeedItemCreate(BaseModel):
    type: str
    title: str
    message: str
    priority: int = 1
    action_payload: Optional[Dict[str, Any]] = None

class FeedItemResponse(FeedItemCreate):
    id: str
    is_read: bool
    is_completed: bool
    created_at: datetime
    @field_validator('action_payload', mode='before')
    def parse_payload(cls, v):
        if isinstance(v, str) and v.strip():
            try: return json.loads(v)
            except: return None
        return v
    class Config: from_attributes = True

class OneRepMaxRequest(BaseModel):
    weight: float
    reps: int
class OneRepMaxResponse(BaseModel):
    estimated_1rm: float
    method_used: str
class ACWRRequest(BaseModel):
    history: List[Dict[str, Any]]
class ACWRResponse(BaseModel):
    ratio: float
    status: str
    color: str
    message: str
class ProfileAuditRequest(BaseModel):
    profile_data: Dict[str, Any]
class ProfileAuditResponse(BaseModel):
    markdown_report: str
class StrategyResponse(BaseModel):
    periodization_title: str
    phases: List[Any]
class WeeklyPlanResponse(BaseModel):
    schedule: List[Any]
    reasoning: str
class UserProfileUpdate(BaseModel):
    profile_data: Dict[str, Any]
-e 

-e 
================================================================================
üìÑ FICHIER : backend/backend/app/routers/profiles.py
================================================================================
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.models import models_v2, schemas
from app.dependencies import get_current_user
from app.services.coach_logic import CoachLogic

router = APIRouter(
    prefix="/api/v1",
    tags=["Athlete Profile & Memory"]
)

@router.get("/profiles/me", response_model=schemas.AthleteProfileResponse)
async def get_my_profile(
    current_user: models_v2.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    if not current_user.athlete_profile:
        profile = models_v2.AthleteProfile(user_id=current_user.id)
        db.add(profile)
        db.commit()
        db.refresh(profile)
        return profile
    return current_user.athlete_profile

@router.post("/profiles/complete", response_model=schemas.AthleteProfileResponse)
async def complete_profile(
    profile_data: schemas.AthleteProfileCreate,
    current_user: models_v2.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    sport = profile_data.sport_context.sport
    pos = profile_data.sport_context.position
    # Validation basique
    if not CoachLogic.validate_sport_position(sport, pos):
        # On log mais on ne bloque pas forc√©ment en phase de dev
        print(f"Warning: Position {pos} mismatch for sport {sport}")

    db_profile = current_user.athlete_profile
    if not db_profile:
        db_profile = models_v2.AthleteProfile(user_id=current_user.id)
        db.add(db_profile)
    
    # 1. Update basic fields
    db_profile.basic_info = profile_data.basic_info.dict()
    db_profile.physical_metrics = profile_data.physical_metrics.dict()
    db_profile.sport_context = profile_data.sport_context.dict()
    db_profile.training_preferences = profile_data.training_preferences.dict()
    db_profile.goals = profile_data.goals
    db_profile.constraints = profile_data.constraints
    
    # 2. IMPORTANT : Update new fields (Labo & Sant√©)
    db_profile.performance_baseline = profile_data.performance_baseline
    db_profile.injury_prevention = profile_data.injury_prevention
    
    # 3. Initialize Memory if needed
    if not db_profile.coach_memory:
        memory = CoachLogic.initialize_memory(db_profile)
        db.add(memory)
    
    db.commit()
    db.refresh(db_profile)
    return db_profile

@router.get("/coach-memories/me", response_model=schemas.CoachMemoryResponse)
async def get_my_coach_memory(
    current_user: models_v2.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    if not current_user.athlete_profile or not current_user.athlete_profile.coach_memory:
        raise HTTPException(status_code=404, detail="Profil introuvable.")
    return current_user.athlete_profile.coach_memory

@router.post("/coach-memories/recalculate")
async def force_recalculate(
    current_user: models_v2.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    profile = current_user.athlete_profile
    if not profile or not profile.coach_memory:
        raise HTTPException(status_code=404, detail="Introuvable")
        
    CoachLogic.update_daily(profile.coach_memory, profile)
    db.commit()
    return {"status": "updated", "new_readiness": profile.coach_memory.current_context.get('readiness_score')}
-e 

-e 
================================================================================
üìÑ FICHIER : backend/backend/app/services/coach_logic.py
================================================================================
from datetime import date
from typing import Dict, Any
from app.models import models_v2

# Constantes de validation
VALID_SPORT_POSITIONS = {
    'Rugby': ['Pilier', 'Talonneur', '2√®me ligne', '3√®me ligne', 'Demi', 'Centre', 'Ailier', 'Arri√®re'],
    'Football': ['Gardien', 'D√©fenseur', 'Milieu', 'Attaquant'],
}

class CoachLogic:
    @staticmethod
    def validate_sport_position(sport: str, position: str) -> bool:
        if sport in VALID_SPORT_POSITIONS:
            if position and position not in VALID_SPORT_POSITIONS[sport]:
                return False
        return True

    @staticmethod
    def initialize_memory(profile: models_v2.AthleteProfile) -> models_v2.CoachMemory:
        """Cr√©e la structure initiale de la m√©moire du coach based sur le profil"""
        sport = profile.sport_context.get('sport', 'Autre')
        
        # Insights initiaux
        insights = {
            "primary_sport": sport,
            "specificity_index": "High" if sport in ['Rugby', 'Football'] else "Medium",
            "focus_areas": ["Strength", "Hypertrophy"] # D√©faut
        }
        
        # Contexte initial
        context = {
            "macrocycle_phase": "Adaptation Anatomique",
            "fatigue_state": "Fresh",
            "readiness_score": 100,
            "season_week": 1
        }
        
        # Drapeaux
        flags = {
            "needs_deload": False,
            "injury_risk": False,
            "adaptation_window_open": True
        }

        memory = models_v2.CoachMemory(
            athlete_profile_id=profile.id,
            sport_specific_insights=insights,
            current_context=context,
            memory_flags=flags,
            coach_notes={"initialization": f"Profil cr√©√© le {date.today()}"}
        )
        return memory

    @staticmethod
    def calculate_readiness(profile: models_v2.AthleteProfile) -> int:
        """Algorithme simple de readiness bas√© sur les m√©triques"""
        base_score = 80
        
        # Impact Sommeil
        sleep = profile.physical_metrics.get('sleep_quality_avg', 5)
        if sleep >= 8: base_score += 10
        elif sleep <= 4: base_score -= 20
        
        # Impact Stress
        stress = profile.constraints.get('work_stress_level', 5)
        if stress >= 8: base_score -= 15
        
        return max(0, min(100, base_score))

    @staticmethod
    def update_daily(memory: models_v2.CoachMemory, profile: models_v2.AthleteProfile):
        """Mise √† jour quotidienne (Batch Job simulation)"""
        # Recalcul Readiness
        new_readiness = CoachLogic.calculate_readiness(profile)
        
        # Update Context
        current_context = dict(memory.current_context or {})
        current_context['readiness_score'] = new_readiness
        
        if new_readiness < 40:
            current_context['fatigue_state'] = "High"
        elif new_readiness < 70:
            current_context['fatigue_state'] = "Moderate"
        else:
            current_context['fatigue_state'] = "Optimal"
            
        memory.current_context = current_context
        
        # Update Flags
        flags = dict(memory.memory_flags or {})
        flags['needs_deload'] = new_readiness < 30
        flags['adaptation_window_open'] = new_readiness > 70
        memory.memory_flags = flags
-e 

-e 
================================================================================
üìÑ FICHIER : backend/check_jwt_config.py
================================================================================
import os
import jwt
from datetime import datetime, timedelta
from dotenv import load_dotenv

load_dotenv()

SECRET_KEY = os.getenv("SECRET_KEY")
ALGORITHM = os.getenv("ALGORITHM", "HS256")
ACCESS_TOKEN_EXPIRE_MINUTES = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", 30))

print("üîß Configuration JWT Actuelle:")
print(f"   SECRET_KEY: {'SET' if SECRET_KEY else 'NOT SET'}")
print(f"   ALGORITHM: {ALGORITHM}")
print(f"   ACCESS_TOKEN_EXPIRE_MINUTES: {ACCESS_TOKEN_EXPIRE_MINUTES} min")

# V√©rifier si on peut g√©n√©rer un token
if SECRET_KEY:
    print("\nüß™ Test de g√©n√©ration de token...")
    
    data = {"sub": "testuser", "exp": datetime.utcnow() + timedelta(minutes=30)}
    token = jwt.encode(data, SECRET_KEY, algorithm=ALGORITHM)
    
    print(f"   Token g√©n√©r√©: {token[:50]}...")
    
    # V√©rifier qu'on peut le d√©coder
    try:
        decoded = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        print(f"   ‚úÖ Token d√©cod√©: {decoded}")
    except Exception as e:
        print(f"   ‚ùå Erreur d√©codage: {e}")
else:
    print("\n‚ùå SECRET_KEY non d√©finie!")
    print("   D√©finissez-la dans .env:")
    print("   SECRET_KEY=votre_clef_secrete_tres_longue_ici")
-e 

-e 
================================================================================
üìÑ FICHIER : backend/exe.py
================================================================================
import sys
import os
from datetime import datetime, timedelta

# --- CONFIGURATION DU PATH ---
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

try:
    # --- IMPORTS ---
    from app.core.database import Base, SQLALCHEMY_DATABASE_URL as DATABASE_URL
    # On importe TOUS les maillons de la cha√Æne
    from app.models.sql_models import CoachMemory, CoachEngram, User, AthleteProfile
    from app.models.enums import MemoryType, ImpactLevel, MemoryStatus

except ImportError as e:
    print(f"‚ùå Erreur d'import : {e}")
    sys.exit(1)

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

def repair_and_seed(target_user_id: int):
    db = SessionLocal()
    try:
        print(f"üîß D√©marrage du protocole de r√©paration pour User ID: {target_user_id}...")

        # √âTAPE 1 : Validation de l'Utilisateur
        user = db.query(User).filter(User.id == target_user_id).first()
        if not user:
            print(f"‚ùå Erreur Fatale : L'utilisateur {target_user_id} n'existe pas dans la table 'users'.")
            return

        print(f"  - ‚úÖ Utilisateur {target_user_id} trouv√©.")

        # √âTAPE 2 : Validation ou Cr√©ation du Profil Athl√©tique
        profile = user.athlete_profile # Via la relation SQLAlchemy
        
        if not profile:
            print(f"  - ‚ö†Ô∏è Aucun profil athl√©tique trouv√© pour cet user.")
            print(f"  - üõ†Ô∏è CR√âATION D'UN PROFIL D'URGENCE...")
            
            # Cr√©ation d'un profil minimal pour satisfaire la Foreign Key
            profile = AthleteProfile(
                user_id=user.id,
                biometrics={"weight": 80, "height": 180}, # Valeurs par d√©faut
                performance_metrics={}
            )
            db.add(profile)
            db.commit()
            db.refresh(profile)
            print(f"  - ‚úÖ Profil cr√©√© avec succ√®s ! Nouvel ID du profil : {profile.id}")
        else:
            print(f"  - ‚úÖ Profil athl√©tique existant trouv√© (ID: {profile.id}).")

        # C'est cet ID qu'on doit utiliser, pas forc√©ment 17 !
        real_profile_id = profile.id

        # √âTAPE 3 : Validation ou Cr√©ation de la M√©moire
        memory = db.query(CoachMemory).filter(CoachMemory.athlete_profile_id == real_profile_id).first()
        
        if not memory:
            print(f"  - Cr√©ation du conteneur CoachMemory pour le Profil {real_profile_id}...")
            memory = CoachMemory(
                athlete_profile_id=real_profile_id,
                coach_notes={},
                memory_flags={},
                current_context={}
            )
            db.add(memory)
            db.commit()
            db.refresh(memory)
        else:
            print(f"  - Conteneur CoachMemory trouv√© (ID: {memory.id})")

        # √âTAPE 4 : Injection des Engrammes (Souvenirs)
        engrams_data = [
            {
                "type": MemoryType.INJURY_REPORT,
                "impact": ImpactLevel.SEVERE,
                "status": MemoryStatus.ACTIVE,
                "content": "Douleur patellaire gauche (4/10). Stop Squat profond.",
                "tags": ["knee", "squat"],
                "start_date": datetime.now() - timedelta(days=2),
                "end_date": None
            },
            {
                "type": MemoryType.LIFE_CONSTRAINT,
                "impact": ImpactLevel.MODERATE,
                "status": MemoryStatus.SCHEDULED,
                "content": "D√©placement Londres. Mat√©riel limit√©.",
                "tags": ["travel"],
                "start_date": datetime.now() + timedelta(days=5),
                "end_date": datetime.now() + timedelta(days=10)
            },
            {
                "type": MemoryType.STRATEGIC_OVERRIDE,
                "impact": ImpactLevel.MODERATE,
                "status": MemoryStatus.ACTIVE,
                "content": "Focus Hypertrophie Dos.",
                "tags": ["back", "hypertrophy"],
                "start_date": datetime.now() - timedelta(days=1),
                "end_date": datetime.now() + timedelta(days=30)
            }
        ]

        count = 0
        for data in engrams_data:
            exists = db.query(CoachEngram).filter(
                CoachEngram.memory_id == memory.id,
                CoachEngram.content == data["content"]
            ).first()
            
            if not exists:
                engram = CoachEngram(
                    memory_id=memory.id,
                    author="REPAIR_SCRIPT",
                    **data
                )
                db.add(engram)
                count += 1
        
        db.commit()
        print(f"‚úÖ SUCC√àS TOTAL : {count} engrammes inject√©s pour l'Utilisateur {target_user_id} (Profil {real_profile_id}).")

    except Exception as e:
        print(f"‚ùå Erreur Critique : {e}")
        import traceback
        traceback.print_exc()
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    # On cible l'USER 17, le script se d√©brouillera pour trouver/cr√©er le reste
    repair_and_seed(target_user_id=17)-e 

-e 
================================================================================
üìÑ FICHIER : backend/frontend/app.py
================================================================================
import streamlit as st
import requests
import pandas as pd
import os  # <--- Ajout de l'import os

# Configuration de la page
st.set_page_config(page_title="TitanFlow Pro", page_icon="‚ö°", layout="wide")

# L'URL de ton API (Backend)
# En PROD (Render) : Il utilisera la variable d'environnement BACKEND_URL
# En LOCAL (Ton PC) : Il utilisera http://127.0.0.1:8000 par d√©faut
API_URL = os.getenv("BACKEND_URL", "http://127.0.0.1:8000")

# --- GESTION DE LA SESSION (Token) ---
if "token" not in st.session_state:
    st.session_state.token = None

def login():
    st.sidebar.header("üîê Connexion")
    username = st.sidebar.text_input("Pseudo")
    password = st.sidebar.text_input("Mot de passe", type="password")
    
    if st.sidebar.button("Se connecter"):
        try:
            # Appel √† l'API pour r√©cup√©rer le token
            response = requests.post(
                f"{API_URL}/auth/token",
                data={"username": username, "password": password}
            )
            if response.status_code == 200:
                st.session_state.token = response.json()["access_token"]
                st.sidebar.success("Connect√© !")
                st.rerun()
            else:
                st.sidebar.error("Erreur de connexion")
        except Exception as e:
            st.sidebar.error(f"API introuvable : {e}")

def logout():
    if st.sidebar.button("Se d√©connecter"):
        st.session_state.token = None
        st.rerun()

# --- INTERFACE PRINCIPALE ---
st.title("‚ö° TitanFlow : Monitoring Athl√©tique")

# V√©rification de l'√©tat de l'API
try:
    health = requests.get(f"{API_URL}/health").json()
    st.success(f"Backend connect√© v{health['version']}")
except:
    st.error("üö® Le Backend semble √©teint. V√©rifie que l'URL est correcte.")

# Gestion Login/Logout
if not st.session_state.token:
    st.info("Veuillez vous connecter dans la barre lat√©rale pour acc√©der aux donn√©es.")
    login()
else:
    logout()
    st.write("---")
    
    # Onglets de l'application
    tab1, tab2 = st.tabs(["üèãÔ∏è‚Äç‚ôÇÔ∏è Historique", "‚ûï Nouvelle S√©ance"])
    
    # --- ONGLET 1 : HISTORIQUE ---
    with tab1:
        st.subheader("Vos s√©ances enregistr√©es")
        headers = {"Authorization": f"Bearer {st.session_state.token}"}
        
        try:
            res = requests.get(f"{API_URL}/workouts/", headers=headers)
            if res.status_code == 200:
                workouts = res.json()
                if workouts:
                    df = pd.DataFrame(workouts)
                    st.dataframe(df, use_container_width=True)
                else:
                    st.info("Aucune s√©ance trouv√©e.")
            else:
                st.error("Erreur chargement donn√©es")
        except Exception as e:
            st.error(f"Erreur : {e}")

    # --- ONGLET 2 : AJOUTER S√âANCE ---
    with tab2:
        st.subheader("Enregistrer un entra√Ænement")
        with st.form("new_workout"):
            col1, col2 = st.columns(2)
            date = col1.date_input("Date")
            duration = col2.number_input("Dur√©e (min)", min_value=0, value=60)
            rpe = st.slider("Intensit√© (RPE)", 0, 10, 5)
            
            submitted = st.form_submit_button("Sauvegarder")
            
            if submitted:
                payload = {
                    "date": str(date),
                    "duration": duration,
                    "rpe": rpe
                }
                res = requests.post(f"{API_URL}/workouts/", json=payload, headers=headers)
                
                if res.status_code == 200:
                    st.success("S√©ance enregistr√©e ! üéâ")
                    st.rerun()
                else:
                    st.error(f"Erreur : {res.text}")-e 

-e 
================================================================================
üìÑ FICHIER : backend/frontend/lib/models/profile_draft.dart
================================================================================

class ProfileDraft {
  static final ProfileDraft _instance = ProfileDraft._internal();

  factory ProfileDraft() {
    return _instance;
  }

  ProfileDraft._internal();

  // Stockage temporaire pour agr√©ger les donn√©es
  Map<String, dynamic> performanceBaseline = {};
  Map<String, dynamic> constraints = {}; // Matrice hebdo
  Map<String, dynamic> injuryPrevention = {}; // Blessures
  List<String> equipment = ["Standard"];

  void clear() {
    performanceBaseline = {};
    constraints = {};
    injuryPrevention = {};
    equipment = ["Standard"];
  }
}
-e 

-e 
================================================================================
üìÑ FICHIER : backend/frontend/lib/screens/bio_calibration_screen.dart
================================================================================
import 'package:flutter/material.dart';
import 'package:google_fonts/google_fonts.dart';
import '../models/profile_draft.dart'; // <--- SEUL AJOUT

class BioCalibrationScreen extends StatefulWidget {
  const BioCalibrationScreen({super.key});

  @override
  State<BioCalibrationScreen> createState() => _BioCalibrationScreenState();
}

class _BioCalibrationScreenState extends State<BioCalibrationScreen>
    with SingleTickerProviderStateMixin {
  late TabController _tabController;
  // --- THEME COLORS ---
  final Color _bgDark = const Color(0xFF000000);
  final Color _cardDark = const Color(0xFF1C1C1E);
  final Color _voltYellow = const Color(0xFFCCFF00);
  final Color _cyanSwim = const Color(0xFF03DAC6);
  final Color _orangeBike = const Color(0xFFFF9F0A);
  final Color _redStrength = const Color(0xFFFF453A);
  final Color _textWhite = const Color(0xFFFFFFFF);
  final Color _textGrey = const Color(0xFF8E8E93);
  // --- STATES TOGGLES ---
  bool _knowsRunStats = true;
  bool _knowsBikeStats = true;
  bool _knowsSwimStats = true;
  bool _knows1RM = true;
  // --- CONTROLLERS RUNNING ---
  final _runShortDistCtrl = TextEditingController();
  final _runShortMinCtrl = TextEditingController();
  final _runShortSecCtrl = TextEditingController();
  final _runLongDistCtrl = TextEditingController();
  final _runLongMinCtrl = TextEditingController();
  final _runLongSecCtrl = TextEditingController();
  final _runSprintCtrl = TextEditingController();
  String _runResult = "";
  // --- CONTROLLERS CYCLING ---
  final _bikeShortMinCtrl = TextEditingController();
  final _bikeShortSecCtrl = TextEditingController();
  final _bikeShortWattsCtrl = TextEditingController();
  final _bikeLongMinCtrl = TextEditingController();
  final _bikeLongSecCtrl = TextEditingController();
  final _bikeLongWattsCtrl = TextEditingController();
  final _bikePeakCtrl = TextEditingController();
  String _bikeResult = "";
  // --- CONTROLLERS SWIMMING ---
  final _swim200MinCtrl = TextEditingController();
  final _swim200SecCtrl = TextEditingController();
  final _swim400MinCtrl = TextEditingController();
  final _swim400SecCtrl = TextEditingController();
  String _swimResult = "";
  // --- CONTROLLERS STRENGTH ---
  final _squatCtrl = TextEditingController();
  final _benchCtrl = TextEditingController();
  final _deadliftCtrl = TextEditingController();
  final _pullCtrl = TextEditingController();

  @override
  void initState() {
    super.initState();
    _tabController = TabController(length: 4, vsync: this);
  }

  @override
  void dispose() {
    _tabController.dispose();
    super.dispose();
  }

  // --- CALCULATORS ---
  void _calcRunning() {
    try {
      double d1 = double.parse(_runShortDistCtrl.text);
      double t1 = (double.parse(_runShortMinCtrl.text) * 60) + double.parse(_runShortSecCtrl.text);
      double d2 = double.parse(_runLongDistCtrl.text);
      double t2 = (double.parse(_runLongMinCtrl.text) * 60) + double.parse(_runLongSecCtrl.text);
      if (t2 <= t1) { setState(() => _runResult = "‚ö†Ô∏è Le test long doit √™tre plus long !"); return; }
      double csMetersPerSec = (d2 - d1) / (t2 - t1);
      double vmaKmh = csMetersPerSec * 3.6;
      setState(() { _runResult = "Vitesse Critique : ${vmaKmh.toStringAsFixed(1)} km/h\nASR calcul√©e."; });
    } catch (e) { setState(() => _runResult = ""); }
  }

  void _calcCycling() {
    try {
      double t1 = (double.parse(_bikeShortMinCtrl.text) * 60) + double.parse(_bikeShortSecCtrl.text);
      double p1 = double.parse(_bikeShortWattsCtrl.text);
      double t2 = (double.parse(_bikeLongMinCtrl.text) * 60) + double.parse(_bikeLongSecCtrl.text);
      double p2 = double.parse(_bikeLongWattsCtrl.text);
      if (t2 == t1) return;
      double w1 = p1 * t1;
      double w2 = p2 * t2;
      double cp = (w2 - w1) / (t2 - t1);
      double wPrime = w1 - (cp * t1);
      setState(() { _bikeResult = "CP (FTP Est.) : ${cp.toStringAsFixed(0)} W\nW' : ${(wPrime / 1000).toStringAsFixed(1)} kJ"; });
    } catch (e) { setState(() => _bikeResult = ""); }
  }

  void _calcSwim() {
    try {
      double t200 = (double.parse(_swim200MinCtrl.text) * 60) + double.parse(_swim200SecCtrl.text);
      double t400 = (double.parse(_swim400MinCtrl.text) * 60) + double.parse(_swim400SecCtrl.text);
      if (t400 <= t200) return;
      double cssSpeed = (400 - 200) / (t400 - t200);
      double secPer100 = 100 / cssSpeed;
      int min = (secPer100 / 60).floor();
      int sec = (secPer100 % 60).round();
      setState(() { _swimResult = "CSS Pace : $min:${sec.toString().padLeft(2, '0')}/100m"; });
    } catch (e) { setState(() => _swimResult = ""); }
  }

  // --- SAVE DATA (CONNECT√â) ---
  void _saveData() {
    // 1. Sauvegarde dans le Singleton Draft
    final draft = ProfileDraft();
    
    draft.performanceBaseline = {
      // Donn√©es brutes Force
      "squat_1rm": double.tryParse(_squatCtrl.text),
      "bench_1rm": double.tryParse(_benchCtrl.text),
      "deadlift_1rm": double.tryParse(_deadliftCtrl.text),
      "pull_load": double.tryParse(_pullCtrl.text),
      
      // Donn√©es Running
      "running_max_sprint_time": double.tryParse(_runSprintCtrl.text), // C'est des km/h ici en fait selon ton UI
      "vma_estimated": _runResult, 
      
      // Donn√©es Cycling
      "cycling_ftp": _bikeResult.isNotEmpty ? 250 : null, // (Simplification: il faudrait extraire la valeur du string _bikeResult)
      "cycling_max_power_5s": double.tryParse(_bikePeakCtrl.text),
      
      // Donn√©es Swim
      "css_pace": _swimResult
    };

    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(
        content: const Text("üíæ Protocoles enregistr√©s. Zones mises √† jour !"),
        backgroundColor: _voltYellow,
        behavior: SnackBarBehavior.floating,
      ),
    );
    Navigator.pop(context);
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: _bgDark,
      appBar: AppBar(
        backgroundColor: _bgDark,
        title: Text("LABORATOIRE",
            style: GoogleFonts.bebasNeue(
                fontSize: 24, letterSpacing: 2, color: _textWhite)),
        leading: IconButton(
          icon: Icon(Icons.arrow_back_ios, color: _textWhite),
          onPressed: () => Navigator.pop(context),
        ),
        bottom: TabBar(
          controller: _tabController,
          indicatorColor: _voltYellow,
          labelColor: _voltYellow,
          unselectedLabelColor: _textGrey,
          labelStyle: const TextStyle(fontWeight: FontWeight.bold),
          tabs: const [
            Tab(icon: Icon(Icons.directions_run), text: "RUN"),
            Tab(icon: Icon(Icons.directions_bike), text: "BIKE"),
            Tab(icon: Icon(Icons.pool), text: "SWIM"),
            Tab(icon: Icon(Icons.fitness_center), text: "GYM"),
          ],
        ),
      ),
      body: TabBarView(
        controller: _tabController,
        children: [
          _buildRunTab(),
          _buildBikeTab(),
          _buildSwimTab(),
          _buildStrengthTab(),
        ],
      ),
      bottomNavigationBar: Container(
        padding: const EdgeInsets.all(20),
        color: _bgDark,
        child: ElevatedButton(
          onPressed: _saveData,
          style: ElevatedButton.styleFrom(
            backgroundColor: _voltYellow,
            foregroundColor: Colors.black,
            padding: const EdgeInsets.symmetric(vertical: 18),
            shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(12)),
          ),
          child: Text("VALIDER LES TESTS",
              style: GoogleFonts.rubik(fontWeight: FontWeight.bold, letterSpacing: 1)),
        ),
      ),
    );
  }

  // --- TABS CONTENT (COPI√â COLL√â EXACT DE TA VERSION) ---

  Widget _buildRunTab() {
    return SingleChildScrollView(
      padding: const EdgeInsets.all(20),
      child: Column(
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          _sectionHeader("TEST VITESSE CRITIQUE", _voltYellow),
          const SizedBox(height: 16),
          SwitchListTile(
            title: Text("Je connais mes chronos", style: TextStyle(color: _textWhite, fontWeight: FontWeight.bold)),
            subtitle: const Text("Pour calculer ta VMA/CS pr√©cise.", style: TextStyle(color: Colors.grey, fontSize: 12)),
            value: _knowsRunStats,
            activeTrackColor: _voltYellow,
            activeThumbColor: Colors.black,
            contentPadding: EdgeInsets.zero,
            onChanged: (val) => setState(() => _knowsRunStats = val),
          ),
          const SizedBox(height: 16),
          if (_knowsRunStats) ...[
            _testCard(
              title: "TEST COURT (Ex: 1200m)", color: _voltYellow,
              child: Column(children: [
                  _inputField("Distance (m)", _runShortDistCtrl, numeric: true, suffix: "m", onChanged: (_) => _calcRunning()),
                  const SizedBox(height: 12),
                  _durationPicker("Chrono", _runShortMinCtrl, _runShortSecCtrl, onChanged: _calcRunning),
                ]),
            ),
            const SizedBox(height: 16),
            _testCard(
              title: "TEST LONG (Ex: 3600m)", color: _voltYellow,
              child: Column(children: [
                  _inputField("Distance (m)", _runLongDistCtrl, numeric: true, suffix: "m", onChanged: (_) => _calcRunning()),
                  const SizedBox(height: 12),
                  _durationPicker("Chrono", _runLongMinCtrl, _runLongSecCtrl, onChanged: _calcRunning),
                ]),
            ),
            const SizedBox(height: 24),
            _inputField("Vitesse Max Sprint (km/h)", _runSprintCtrl, numeric: true, suffix: "km/h"),
            if (_runResult.isNotEmpty) ...[const SizedBox(height: 24), _resultBox(_runResult, _voltYellow),]
          ] else ...[
            _buildEstimationBox("Mode Estimation activ√©.\nL'IA utilisera ton temps sur 5km/10km r√©cent ou ton niveau global pour d√©finir tes allures.", _voltYellow),
          ]
        ],
      ),
    );
  }

  Widget _buildBikeTab() {
    return SingleChildScrollView(
      padding: const EdgeInsets.all(20),
      child: Column(crossAxisAlignment: CrossAxisAlignment.start, children: [
          _sectionHeader("PROFIL PUISSANCE (CP)", _orangeBike),
          const SizedBox(height: 16),
          SwitchListTile(
            title: Text("Je connais ma puissance", style: TextStyle(color: _textWhite, fontWeight: FontWeight.bold)),
            subtitle: const Text("Tests CP ou FTP r√©cents.", style: TextStyle(color: Colors.grey, fontSize: 12)),
            value: _knowsBikeStats,
            activeTrackColor: _orangeBike,
            activeThumbColor: Colors.white,
            contentPadding: EdgeInsets.zero,
            onChanged: (val) => setState(() => _knowsBikeStats = val),
          ),
          const SizedBox(height: 16),
          if (_knowsBikeStats) ...[
            _testCard(
              title: "TEST COURT (3 √† 5 min)", color: _orangeBike,
              child: Column(children: [
                  _durationPicker("Dur√©e", _bikeShortMinCtrl, _bikeShortSecCtrl, onChanged: _calcCycling),
                  const SizedBox(height: 12),
                  _inputField("Puissance Moy. (Watts)", _bikeShortWattsCtrl, numeric: true, suffix: "W", maxLen: 4, onChanged: (_) => _calcCycling()),
                ]),
            ),
            const SizedBox(height: 16),
            _testCard(
              title: "TEST LONG (12 √† 20 min)", color: _orangeBike,
              child: Column(children: [
                  _durationPicker("Dur√©e", _bikeLongMinCtrl, _bikeLongSecCtrl, onChanged: _calcCycling),
                  const SizedBox(height: 12),
                  _inputField("Puissance Moy. (Watts)", _bikeLongWattsCtrl, numeric: true, suffix: "W", maxLen: 4, onChanged: (_) => _calcCycling()),
                ]),
            ),
            const SizedBox(height: 24),
            _inputField("Peak Power 5s (Watts)", _bikePeakCtrl, numeric: true, suffix: "W", maxLen: 4),
            if (_bikeResult.isNotEmpty) ...[const SizedBox(height: 24), _resultBox(_bikeResult, _orangeBike),]
          ] else ...[
            _buildEstimationBox("Mode Estimation activ√©.\nL'IA estimera ta FTP via ton Poids, ton Age et ton niveau d'exp√©rience cycliste.", _orangeBike),
          ]
        ]),
    );
  }

  Widget _buildSwimTab() {
    return SingleChildScrollView(
      padding: const EdgeInsets.all(20),
      child: Column(crossAxisAlignment: CrossAxisAlignment.start, children: [
          _sectionHeader("CRITICAL SWIM SPEED", _cyanSwim),
          const SizedBox(height: 16),
          SwitchListTile(
            title: Text("Je connais mes chronos", style: TextStyle(color: _textWhite, fontWeight: FontWeight.bold)),
            subtitle: const Text("Tests 200m/400m r√©cents.", style: TextStyle(color: Colors.grey, fontSize: 12)),
            value: _knowsSwimStats,
            activeTrackColor: _cyanSwim,
            activeThumbColor: Colors.black,
            contentPadding: EdgeInsets.zero,
            onChanged: (val) => setState(() => _knowsSwimStats = val),
          ),
          const SizedBox(height: 16),
          if (_knowsSwimStats) ...[
            _testCard(
              title: "CHRONO 200m", color: _cyanSwim,
              child: _durationPicker("Temps", _swim200MinCtrl, _swim200SecCtrl, onChanged: _calcSwim),
            ),
            const SizedBox(height: 16),
            _testCard(
              title: "CHRONO 400m", color: _cyanSwim,
              child: _durationPicker("Temps", _swim400MinCtrl, _swim400SecCtrl, onChanged: _calcSwim),
            ),
            if (_swimResult.isNotEmpty) ...[const SizedBox(height: 24), _resultBox(_swimResult, _cyanSwim),]
          ] else ...[
            _buildEstimationBox("Mode Estimation activ√©.\nL'IA d√©duira ton allure CSS selon ton niveau d√©clar√© (D√©butant √† √âlite).", _cyanSwim),
          ]
        ]),
    );
  }

  Widget _buildStrengthTab() {
    return SingleChildScrollView(
      padding: const EdgeInsets.all(20),
      child: Column(crossAxisAlignment: CrossAxisAlignment.start, children: [
          _sectionHeader("MAX FORCE (1RM)", _redStrength),
          const SizedBox(height: 16),
          SwitchListTile(
            title: Text("Je connais mes max (1RM)", style: TextStyle(color: _textWhite, fontWeight: FontWeight.bold)),
            subtitle: const Text("Sinon, l'IA les estimera.", style: TextStyle(color: Colors.grey, fontSize: 12)),
            value: _knows1RM,
            activeTrackColor: _redStrength,
            activeThumbColor: _textWhite,
            contentPadding: EdgeInsets.zero,
            onChanged: (val) => setState(() => _knows1RM = val),
          ),
          const SizedBox(height: 16),
          if (_knows1RM) ...[
            _inputField("Squat Max", _squatCtrl, numeric: true, suffix: "kg"),
            const SizedBox(height: 12),
            _inputField("Bench Press Max", _benchCtrl, numeric: true, suffix: "kg"),
            const SizedBox(height: 12),
            _inputField("Deadlift Max", _deadliftCtrl, numeric: true, suffix: "kg"),
            const SizedBox(height: 12),
            _inputField("Tirage / Pull-up Lest", _pullCtrl, numeric: true, suffix: "kg"),
          ] else ...[
            _buildEstimationBox("Mode Estimation activ√©.\nL'IA utilisera ton Poids et ton Niveau saisis dans le Profil pour g√©n√©rer tes charges.", _redStrength),
          ]
        ]),
    );
  }

  // --- REUSABLE COMPONENTS (ISO) ---
  Widget _sectionHeader(String title, Color color) {
    return Row(children: [Container(width: 4, height: 18, color: color), const SizedBox(width: 8), Text(title, style: const TextStyle(color: Colors.grey, fontSize: 12, fontWeight: FontWeight.bold, letterSpacing: 1.5))]);
  }
  Widget _buildEstimationBox(String message, Color color) {
    return Container(padding: const EdgeInsets.all(16), decoration: BoxDecoration(border: Border.all(color: color.withOpacity(0.3)), borderRadius: BorderRadius.circular(12), color: color.withOpacity(0.1)), child: Row(children: [Icon(Icons.auto_awesome, color: _textWhite), const SizedBox(width: 12), Expanded(child: Text(message, style: const TextStyle(color: Colors.white70, fontSize: 12)))]));
  }
  Widget _testCard({required String title, required Color color, required Widget child}) {
    return Container(padding: const EdgeInsets.all(16), decoration: BoxDecoration(color: _cardDark, borderRadius: BorderRadius.circular(16), border: Border.all(color: _textWhite.withOpacity(0.05))), child: Column(crossAxisAlignment: CrossAxisAlignment.start, children: [Text(title, style: TextStyle(color: color, fontWeight: FontWeight.bold, fontSize: 14)), const SizedBox(height: 12), child]));
  }
  Widget _inputField(String label, TextEditingController controller, {bool numeric = false, String? suffix, int? maxLen, Function(String)? onChanged}) {
    return TextFormField(controller: controller, keyboardType: numeric ? TextInputType.number : TextInputType.text, style: GoogleFonts.robotoMono(color: _textWhite, fontSize: 16), maxLength: maxLen, onChanged: onChanged, decoration: InputDecoration(labelText: label, labelStyle: const TextStyle(color: Colors.grey), suffixText: suffix, suffixStyle: TextStyle(color: _voltYellow), counterText: "", filled: true, fillColor: const Color(0xFF2C2C2E), border: OutlineInputBorder(borderRadius: BorderRadius.circular(12), borderSide: BorderSide.none), contentPadding: const EdgeInsets.symmetric(horizontal: 16, vertical: 14)));
  }
  Widget _durationPicker(String label, TextEditingController minCtrl, TextEditingController secCtrl, {required VoidCallback onChanged}) {
    return Column(crossAxisAlignment: CrossAxisAlignment.start, children: [Text(label, style: const TextStyle(color: Colors.grey, fontSize: 12)), const SizedBox(height: 6), Row(children: [Expanded(child: TextFormField(controller: minCtrl, keyboardType: TextInputType.number, style: GoogleFonts.robotoMono(color: _textWhite, fontSize: 18), textAlign: TextAlign.center, onChanged: (_) => onChanged(), decoration: InputDecoration(hintText: "00", suffixText: "min", filled: true, fillColor: const Color(0xFF2C2C2E), border: OutlineInputBorder(borderRadius: BorderRadius.circular(12), borderSide: BorderSide.none), contentPadding: const EdgeInsets.symmetric(vertical: 12)))), Padding(padding: const EdgeInsets.symmetric(horizontal: 8.0), child: Text(":", style: TextStyle(color: _textWhite, fontSize: 24, fontWeight: FontWeight.bold))), Expanded(child: TextFormField(controller: secCtrl, keyboardType: TextInputType.number, style: GoogleFonts.robotoMono(color: _textWhite, fontSize: 18), textAlign: TextAlign.center, onChanged: (_) => onChanged(), decoration: InputDecoration(hintText: "00", suffixText: "sec", filled: true, fillColor: const Color(0xFF2C2C2E), border: OutlineInputBorder(borderRadius: BorderRadius.circular(12), borderSide: BorderSide.none), contentPadding: const EdgeInsets.symmetric(vertical: 12))))])]);
  }
  Widget _resultBox(String text, Color color) {
    return Container(width: double.infinity, padding: const EdgeInsets.all(16), decoration: BoxDecoration(color: color.withOpacity(0.1), border: Border.all(color: color), borderRadius: BorderRadius.circular(12)), child: Text(text, style: GoogleFonts.robotoMono(color: color, fontSize: 14, fontWeight: FontWeight.bold), textAlign: TextAlign.center));
  }
}
-e 

-e 
================================================================================
üìÑ FICHIER : backend/frontend/lib/screens/equipment_health_screen.dart
================================================================================
import 'package:flutter/material.dart';
import 'package:google_fonts/google_fonts.dart';
import '../models/profile_draft.dart'; // <--- AJOUT

class EquipmentHealthScreen extends StatefulWidget {
  const EquipmentHealthScreen({super.key});
  @override
  State<EquipmentHealthScreen> createState() => _EquipmentHealthScreenState();
}

class _EquipmentHealthScreenState extends State<EquipmentHealthScreen> {
  // --- CONSTANTES ---
  final List<String> _equipmentList = [
    "Salle de sport commerciale (Acc√®s total)", "Home Gym complet (Rack + Barre + Banc)", "Box de CrossFit",
    "Halt√®res (Dumbbells)", "Barre Olympique + Disques", "Kettlebells", "Barre de traction", "Banc de musculation", "Station √† Dips / Chaise romaine",
    "√âlastiques / Bandes de r√©sistance", "Anneaux de gymnastique / TRX", "Corde √† sauter", "Gilet lest√©", "M√©decine Ball / Wall Ball",
    "V√©lo de route / VTT (Ext√©rieur)", "Home Trainer / Zwift", "Rameur (Ergo)", "Tapis de course", "V√©lo Elliptique / Assault Bike", "Piscine / Bassin"
  ];
  final List<String> _injuryZones = [
    "Cervicales / Cou", "√âpaule (Coiffe des rotateurs)", "Coude / Avant-bras", "Poignet / Main", "Dos (Haut / Trap√®zes)",
    "Lombaires (Bas du dos)", "Hanche / Psoas", "Adducteurs / Aine", "Ischios-jambiers", "Quadriceps",
    "Genou (M√©nisque/Ligaments)", "Rotule / Tendon rotulien", "Mollet / Achille", "Cheville", "Pied / Vo√ªte plantaire"
  ];
  final List<String> _injuryTypes = [
    "Douleur active (Aigu√´)", "G√™ne / Inconfort l√©ger", "Raideur / Manque de mobilit√©", "Tendinite / Tendinopathie",
    "Entorse en gu√©rison", "D√©chirure musculaire (R√©hab)", "Post-Op√©ratoire (< 6 mois)", "Fragilit√© chronique (Pr√©vention)"
  ];
  // --- STATE ---
  final List<String> _selectedEquipment = [];
  final List<Map<String, String?>> _declaredInjuries = [];
  // --- COLORS ---
  final Color _bgDark = const Color(0xFF000000);
  final Color _cardDark = const Color(0xFF1C1C1E);
  final Color _voltYellow = const Color(0xFFCCFF00);
  final Color _redAlert = const Color(0xFFFF453A);

  @override
  void initState() {
    super.initState();
    _selectedEquipment.add("Salle de sport commerciale (Acc√®s total)");
  }

  void _addInjury() => setState(() => _declaredInjuries.add({'zone': null, 'type': null}));
  void _removeInjury(int index) => setState(() => _declaredInjuries.removeAt(index));

  // --- SAVE DATA (CONNECT√â) ---
  void _saveData() {
    bool injuriesComplete = _declaredInjuries.every((inj) => inj['zone'] != null && inj['type'] != null);
    if (!injuriesComplete) {
      ScaffoldMessenger.of(context).showSnackBar(const SnackBar(content: Text("‚ö†Ô∏è Compl√®te toutes les infos blessures."), backgroundColor: Colors.orange));
      return;
    }

    // Sauvegarde Draft
    ProfileDraft().equipment = _selectedEquipment;
    ProfileDraft().injuryPrevention = {'injuries': _declaredInjuries};

    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(
        content: Text("üíæ Inventaire : ${_selectedEquipment.length} items. Blessures : ${_declaredInjuries.length}."),
        backgroundColor: _voltYellow,
        behavior: SnackBarBehavior.floating,
      ),
    );
    Navigator.pop(context);
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: _bgDark,
      appBar: AppBar(backgroundColor: _bgDark, title: Text("MAT√âRIEL & SANT√â", style: GoogleFonts.bebasNeue(fontSize: 24, letterSpacing: 2, color: Colors.white)), leading: IconButton(icon: const Icon(Icons.arrow_back_ios, color: Colors.white), onPressed: () => Navigator.pop(context))),
      body: SingleChildScrollView(
        padding: const EdgeInsets.all(20),
        child: Column(crossAxisAlignment: CrossAxisAlignment.start, children: [
            _sectionHeader("ARMURERIE (√âQUIPEMENTS)", Icons.fitness_center),
            const SizedBox(height: 12),
            Container(width: double.infinity, padding: const EdgeInsets.all(16), decoration: BoxDecoration(color: _cardDark, borderRadius: BorderRadius.circular(16)),
              child: Column(crossAxisAlignment: CrossAxisAlignment.start, children: [
                  const Text("S√©lectionne tout ce dont tu disposes :", style: TextStyle(color: Colors.grey, fontSize: 12)),
                  const SizedBox(height: 16),
                  Wrap(spacing: 8.0, runSpacing: 8.0, children: _equipmentList.map((equip) {
                      final isSelected = _selectedEquipment.contains(equip);
                      return FilterChip(
                        label: Text(equip), selected: isSelected,
                        onSelected: (bool selected) { setState(() { if (selected) { _selectedEquipment.add(equip); } else { _selectedEquipment.remove(equip); } }); },
                        backgroundColor: const Color(0xFF2C2C2E), selectedColor: _voltYellow, checkmarkColor: Colors.black,
                        labelStyle: TextStyle(color: isSelected ? Colors.black : Colors.white, fontWeight: isSelected ? FontWeight.bold : FontWeight.normal, fontSize: 12),
                        padding: const EdgeInsets.symmetric(horizontal: 4, vertical: 4), shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(8), side: BorderSide(color: isSelected ? _voltYellow : Colors.transparent)), showCheckmark: false,
                      );
                    }).toList()),
                ]),
            ),
            const SizedBox(height: 32),
            _sectionHeader("INFIRMERIE (BLESSURES)", Icons.local_hospital),
            const SizedBox(height: 12),
            Container(width: double.infinity, padding: const EdgeInsets.all(16), decoration: BoxDecoration(color: _cardDark, borderRadius: BorderRadius.circular(16), border: Border.all(color: _redAlert.withOpacity(0.1))),
              child: Column(children: [
                  if (_declaredInjuries.isEmpty) Padding(padding: const EdgeInsets.symmetric(vertical: 20), child: Column(children: [Icon(Icons.check_circle_outline, color: Colors.greenAccent.withOpacity(0.5), size: 40), const SizedBox(height: 8), const Text("Aucune blessure signal√©e.\nMachine op√©rationnelle √† 100%.", textAlign: TextAlign.center, style: TextStyle(color: Colors.grey, fontSize: 12))]))
                  else ListView.separated(shrinkWrap: true, physics: const NeverScrollableScrollPhysics(), itemCount: _declaredInjuries.length, separatorBuilder: (ctx, i) => const Divider(color: Colors.white10, height: 24, thickness: 1), itemBuilder: (ctx, i) => _buildInjuryRow(i)),
                  const SizedBox(height: 16),
                  OutlinedButton.icon(onPressed: _addInjury, icon: Icon(Icons.add, color: _redAlert), label: Text("D√âCLARER UNE BLESSURE", style: TextStyle(color: _redAlert)), style: OutlinedButton.styleFrom(side: BorderSide(color: _redAlert.withOpacity(0.5)), shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(8)))),
                ]),
            ),
          ]),
      ),
      bottomNavigationBar: Container(padding: const EdgeInsets.all(20), decoration: BoxDecoration(color: _bgDark, border: Border(top: BorderSide(color: Colors.white.withOpacity(0.1)))), child: ElevatedButton(onPressed: _saveData, style: ElevatedButton.styleFrom(backgroundColor: _voltYellow, foregroundColor: Colors.black, padding: const EdgeInsets.symmetric(vertical: 18), shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(12))), child: Text("VALIDER MAT√âRIEL & SANT√â", style: GoogleFonts.rubik(fontWeight: FontWeight.bold, letterSpacing: 1)))),
    );
  }

  Widget _sectionHeader(String title, IconData icon) => Row(children: [Icon(icon, color: Colors.grey, size: 18), const SizedBox(width: 8), Text(title, style: const TextStyle(color: Colors.grey, fontSize: 12, fontWeight: FontWeight.bold, letterSpacing: 1.5))]);
  Widget _buildInjuryRow(int index) {
    return Column(crossAxisAlignment: CrossAxisAlignment.start, children: [
        Row(mainAxisAlignment: MainAxisAlignment.spaceBetween, children: [Text("Blessure #${index + 1}", style: const TextStyle(color: Colors.white, fontWeight: FontWeight.bold, fontSize: 14)), IconButton(icon: const Icon(Icons.delete_outline, color: Colors.grey), onPressed: () => _removeInjury(index), padding: EdgeInsets.zero, constraints: const BoxConstraints())]),
        const SizedBox(height: 12),
        _buildDropdownMap("Zone touch√©e", _injuryZones, _declaredInjuries[index]['zone'], (val) => setState(() => _declaredInjuries[index]['zone'] = val)),
        const SizedBox(height: 12),
        _buildDropdownMap("Type de probl√®me", _injuryTypes, _declaredInjuries[index]['type'], (val) => setState(() => _declaredInjuries[index]['type'] = val)),
      ]);
  }
  Widget _buildDropdownMap(String label, List<String> items, String? currentValue, Function(String?) onChanged) {
    return DropdownButtonFormField<String>(value: currentValue, isExpanded: true, dropdownColor: const Color(0xFF2C2C2E), style: const TextStyle(color: Colors.white, fontSize: 13), decoration: InputDecoration(labelText: label, labelStyle: const TextStyle(color: Colors.grey, fontSize: 12), filled: true, fillColor: const Color(0xFF2C2C2E), border: OutlineInputBorder(borderRadius: BorderRadius.circular(8), borderSide: BorderSide.none), contentPadding: const EdgeInsets.symmetric(horizontal: 12, vertical: 12)), items: items.map((e) => DropdownMenuItem(value: e, child: Text(e, overflow: TextOverflow.ellipsis))).toList(), onChanged: onChanged);
  }
}
-e 

-e 
================================================================================
üìÑ FICHIER : backend/frontend/lib/screens/home_screen.dart
================================================================================
import 'package:flutter/material.dart';
import 'package:google_fonts/google_fonts.dart';
import 'profile_setup_screen.dart';
import 'bio_calibration_screen.dart';

class HomeScreen extends StatelessWidget {
  const HomeScreen({super.key});

  final Color _bgDark = const Color(0xFF000000);
  final Color _cardDark = const Color(0xFF1C1C1E);
  final Color _voltYellow = const Color(0xFFCCFF00);
  final Color _purpleAI = const Color(0xFFA020F0);
  final Color _textWhite = const Color(0xFFFFFFFF);
  final Color _textGrey = const Color(0xFF8E8E93);
  final Color _successGreen = const Color(0xFF32D74B);

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: _bgDark,
      body: SafeArea(
        child: SingleChildScrollView(
          padding: const EdgeInsets.all(20.0),
          child: Column(
            crossAxisAlignment: CrossAxisAlignment.start,
            children: [
              _buildHeader(context),
              const SizedBox(height: 24),
              _buildHeroCard(context),
              const SizedBox(height: 24),
              const Text(
                "COCKPIT INSIGHT",
                style: TextStyle(fontSize: 14, fontWeight: FontWeight.w600, color: Color(0xFF8E8E93), letterSpacing: 1.0),
              ),
              const SizedBox(height: 12),
              _buildCoachWidget(),
              const SizedBox(height: 24),
              _buildTimelineSection(),
            ],
          ),
        ),
      ),
    );
  }

  Widget _buildHeader(BuildContext context) {
    return Row(
      mainAxisAlignment: MainAxisAlignment.spaceBetween,
      children: [
        InkWell(
          onTap: () {
            Navigator.push(context, MaterialPageRoute(builder: (context) => const ProfileSetupScreen()));
          },
          borderRadius: BorderRadius.circular(30),
          child: Row(
            children: [
              Container(
                width: 44, height: 44,
                decoration: BoxDecoration(shape: BoxShape.circle, gradient: const LinearGradient(colors: [Color(0xFF333333), Color(0xFF555555)], begin: Alignment.topLeft, end: Alignment.bottomRight), border: Border.all(color: _voltYellow, width: 2)),
                child: Icon(Icons.person, color: _textWhite, size: 24),
              ),
              const SizedBox(width: 12),
              Column(
                crossAxisAlignment: CrossAxisAlignment.start,
                children: [
                  Text("Alexandre", style: GoogleFonts.rubik(fontSize: 16, fontWeight: FontWeight.w700, color: _textWhite)),
                  Text("ELITE SQUAD", style: GoogleFonts.rubik(fontSize: 12, fontWeight: FontWeight.w800, color: _voltYellow, letterSpacing: 1.0)),
                ],
              ),
            ],
          ),
        ),
        InkWell(
          onTap: () {
            Navigator.push(context, MaterialPageRoute(builder: (context) => const BioCalibrationScreen()));
          },
          borderRadius: BorderRadius.circular(20),
          child: Container(
            padding: const EdgeInsets.symmetric(horizontal: 12, vertical: 6),
            decoration: BoxDecoration(color: _successGreen.withOpacity(0.1), borderRadius: BorderRadius.circular(20), border: Border.all(color: _successGreen)),
            child: Column(
              crossAxisAlignment: CrossAxisAlignment.end,
              children: [
                Text("92%", style: GoogleFonts.rubik(fontSize: 14, fontWeight: FontWeight.bold, color: _successGreen)),
                Text("READINESS (LAB)", style: GoogleFonts.rubik(fontSize: 8, fontWeight: FontWeight.bold, color: _successGreen.withOpacity(0.8))),
              ],
            ),
          ),
        )
      ],
    );
  }

  Widget _buildHeroCard(BuildContext context) {
    return Container(
      width: double.infinity,
      constraints: const BoxConstraints(minHeight: 280),
      padding: const EdgeInsets.all(24),
      decoration: BoxDecoration(
        color: _cardDark, borderRadius: BorderRadius.circular(24), border: Border.all(color: const Color(0xFF333333)),
        boxShadow: [BoxShadow(color: Colors.black.withOpacity(0.5), blurRadius: 30, offset: const Offset(0, 10))],
      ),
      child: Stack(
        children: [
          Positioned(right: -20, top: -20, child: Icon(Icons.flash_on, size: 150, color: Colors.white.withOpacity(0.05))),
          Column(
            crossAxisAlignment: CrossAxisAlignment.start,
            mainAxisAlignment: MainAxisAlignment.spaceBetween,
            children: [
              Row(
                mainAxisAlignment: MainAxisAlignment.spaceBetween,
                children: [
                  Container(
                    padding: const EdgeInsets.symmetric(horizontal: 10, vertical: 4),
                    decoration: BoxDecoration(color: const Color(0xFF333333), borderRadius: BorderRadius.circular(8)),
                    child: Text("RUNNING ‚Ä¢ INTERVALLE", style: GoogleFonts.rubik(fontSize: 12, fontWeight: FontWeight.w600, color: _textWhite)),
                  ),
                  const Text("üî•", style: TextStyle(fontSize: 20)),
                ],
              ),
              const SizedBox(height: 15),
              Text("VMA\nPYRAMIDALE", style: GoogleFonts.rubik(fontSize: 28, fontWeight: FontWeight.w900, color: _textWhite, height: 1.1)),
              const SizedBox(height: 20),
              Row(children: [_buildMetric("55'", "Dur√©e"), const SizedBox(width: 20), _buildMetric("110", "TSS"), const SizedBox(width: 20), _buildMetric("High", "Intensit√©")]),
              const SizedBox(height: 30),
              SizedBox(
                width: double.infinity,
                child: ElevatedButton(
                  onPressed: () { ScaffoldMessenger.of(context).showSnackBar(const SnackBar(content: Text("üöÄ Lancement du Module 5..."))); },
                  style: ElevatedButton.styleFrom(backgroundColor: _voltYellow, foregroundColor: Colors.black, padding: const EdgeInsets.symmetric(vertical: 18), shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(16)), elevation: 10, shadowColor: _voltYellow.withOpacity(0.3)),
                  child: Text("D√âMARRER LA S√âANCE", style: GoogleFonts.rubik(fontSize: 18, fontWeight: FontWeight.w900, letterSpacing: 1.0)),
                ),
              ),
            ],
          ),
        ],
      ),
    );
  }

  Widget _buildMetric(String value, String label) {
    return Column(crossAxisAlignment: CrossAxisAlignment.start, children: [Text(value, style: GoogleFonts.robotoMono(fontSize: 18, fontWeight: FontWeight.bold, color: _voltYellow)), Text(label, style: TextStyle(fontSize: 12, color: _textGrey))]);
  }

  // [CORRECTION] Ajustement des paddings et suppression de l'IntrinsicHeight strict qui cause l'overflow
  Widget _buildCoachWidget() {
    return Container(
      width: double.infinity,
      padding: const EdgeInsets.all(16),
      decoration: BoxDecoration(
        gradient: const LinearGradient(colors: [Color(0xFF1C1C1E), Color(0xFF2C2C2E)], begin: Alignment.topLeft, end: Alignment.bottomRight),
        borderRadius: BorderRadius.circular(20),
        border: Border.all(color: Colors.transparent),
      ),
      child: Row(
        crossAxisAlignment: CrossAxisAlignment.start, // Alignement en haut pour √©viter le stretch forc√©
        children: [
          Container(
            width: 4,
            height: 40, // Hauteur fixe pour la barre d√©corative au lieu de IntrinsicHeight
            decoration: BoxDecoration(color: _purpleAI, borderRadius: BorderRadius.circular(2)),
          ),
          const SizedBox(width: 12),
          Expanded(
            child: Column(
              crossAxisAlignment: CrossAxisAlignment.start,
              children: [
                Text("‚ú¶ ANALYSE EN COURS...", style: TextStyle(fontSize: 14, fontWeight: FontWeight.bold, color: _purpleAI)),
                const SizedBox(height: 6), // R√©duit de 8 √† 6
                Container(height: 12, width: double.infinity, decoration: BoxDecoration(color: const Color(0xFF333333), borderRadius: BorderRadius.circular(4))),
                const SizedBox(height: 6), // R√©duit de 6 √† 6
                Container(height: 12, width: 150, decoration: BoxDecoration(color: const Color(0xFF333333), borderRadius: BorderRadius.circular(4))),
              ],
            ),
          ),
        ],
      ),
    );
  }

  Widget _buildTimelineSection() {
    return Column(crossAxisAlignment: CrossAxisAlignment.start, children: [
        Text("CETTE SEMAINE", style: TextStyle(fontSize: 14, fontWeight: FontWeight.w600, color: _textGrey, letterSpacing: 1.0)),
        const SizedBox(height: 12),
        Row(mainAxisAlignment: MainAxisAlignment.spaceBetween, children: [
            _buildDayItem("L", "‚úî", state: "done"), _buildDayItem("M", "‚úî", state: "done"), _buildDayItem("M", "14", state: "active"),
            _buildDayItem("J", "15", state: "future"), _buildDayItem("V", "16", state: "future"), _buildDayItem("S", "17", state: "future"), _buildDayItem("D", "18", state: "future"),
          ]),
        const SizedBox(height: 20),
      ]);
  }

  Widget _buildDayItem(String dayName, String content, {required String state}) {
    Color circleColor; Color textColor; Color borderColor;
    if (state == "done") { circleColor = const Color(0xFF333333); textColor = _textGrey; borderColor = Colors.transparent; }
    else if (state == "active") { circleColor = _voltYellow.withOpacity(0.1); textColor = _voltYellow; borderColor = _voltYellow; }
    else { circleColor = const Color(0xFF222222); textColor = _textWhite; borderColor = const Color(0xFF333333); }
    return Column(children: [
        Text(dayName, style: TextStyle(fontSize: 12, fontWeight: FontWeight.bold, color: state == "future" ? _textGrey : _textWhite)),
        const SizedBox(height: 6),
        Container(width: 36, height: 36, decoration: BoxDecoration(color: circleColor, shape: BoxShape.circle, border: Border.all(color: borderColor, width: 2)), child: Center(child: Text(content, style: TextStyle(fontSize: 14, fontWeight: FontWeight.bold, color: textColor, decoration: state == "done" ? TextDecoration.lineThrough : null)))),
      ]);
  }
}
-e 

-e 
================================================================================
üìÑ FICHIER : backend/frontend/lib/screens/profile_setup_screen.dart
================================================================================
import 'package:flutter/material.dart';
import 'package:google_fonts/google_fonts.dart';
import 'bio_calibration_screen.dart';
import 'weekly_matrix_screen.dart';
import 'equipment_health_screen.dart';
import '../models/profile_draft.dart'; // <--- AJOUT
import '../services/profile_service.dart'; // <--- AJOUT

class ProfileSetupScreen extends StatefulWidget {
  const ProfileSetupScreen({super.key});

  @override
  State<ProfileSetupScreen> createState() => _ProfileSetupScreenState();
}

class _ProfileSetupScreenState extends State<ProfileSetupScreen> {
  final _formKey = GlobalKey<FormState>();
  final _profileService = ProfileService(); // <--- SERVICE
  bool _isSaving = false;

  // --- CONTROLLERS & STATE ---
  final TextEditingController _pseudoController = TextEditingController(text: "Alexandre");
  String _gender = "Homme";
  int _age = 30;
  double _weight = 75.0;
  int _height = 180;
  String? _selectedLevel;
  String? _selectedSport;
  String? _selectedSpecialty;

  final List<String> _genders = ["Homme", "Femme", "Autre"];
  final Map<String, String> _levels = {
    "D√©butant": "Apprentissage des mouvements, faible capacit√©",
    "Interm√©diaire": "Pratique r√©guli√®re, technique acquise",
    "Avanc√©": "Performance comp√©titive, gros volume",
    "Expert / √âlite": "Niveau national/inter, optimisation marginale",
  };
  final Map<String, List<String>> _sportsSpecs = {
    "Running (Route / Piste)": ["Sprint (100m - 400m)", "Demi-fond (800m - 3000m)", "Fond (5km - 10km)", "Marathon / Semi-Marathon", "VMA & Piste g√©n√©rale"],
    "Trail / Ultra-Trail": ["Trail Court (< 40km)", "Ultra-Trail (> 80km)", "Kilom√®tre Vertical (KV)", "Skyrunning"],
    "Cyclisme (Route / VTT)": ["Grimpeur (Montagne)", "Sprinteur", "Rouleur / Contre-la-montre", "Cyclosportive (Endurance)", "VTT Cross-Country (XC)", "VTT Enduro / Descente", "Gravel"],
    "Triathlon / Ironman": ["Sprint / Olympique (Courte distance)", "Half-Ironman (70.3)", "Ironman (Full Distance)", "Duathlon"],
    "Musculation / Bodybuilding": ["Hypertrophie (Prise de masse)", "Esth√©tique (Men's Physique / Bikini)", "Pr√©paration G√©n√©rale"],
    "Powerlifting / Force Athl√©tique": ["Force Maximale (SBD)", "Bench Press Specialist", "Strongman"],
    "CrossFit / Hyrox": ["CrossFit (WOD & Skills)", "Hyrox / Fitness Racing", "Conditionning pur"],
    "Natation": ["Vitesse (50m - 100m)", "Demi-fond (200m - 400m)", "Eau Libre / Longue distance"],
    "Sports de Combat": ["MMA / Grappling", "Boxe Anglaise / Pieds-Poings", "Judo / Lutte (Pr√©pa Physique)"],
    "Autre": ["G√©n√©ral / Remise en forme"]
  };

  // --- SAVE PROFILE (LE COEUR DU SYST√àME) ---
  Future<void> _submitProfile() async {
    if (_formKey.currentState!.validate()) {
      setState(() => _isSaving = true);

      // 1. R√©cup√©ration des donn√©es du brouillon (Singleton)
      final draft = ProfileDraft();

      // 2. Construction du JSON final pour l'API
      final Map<String, dynamic> payload = {
        "basic_info": {
          "pseudo": _pseudoController.text,
          "birth_date": "${DateTime.now().year - _age}-01-01",
          "training_age": 2 // Valeur par d√©faut si non demand√©e
        },
        "physical_metrics": {
          "weight": _weight,
          "height": _height.toDouble(),
          "sleep_quality_avg": 7
        },
        "sport_context": {
          "sport": _selectedSport ?? "Autre",
          "level": _selectedLevel ?? "Interm√©diaire",
          "position": _selectedSpecialty,
          "equipment": draft.equipment // Vient de EquipmentScreen
        },
        "training_preferences": {
          "duration_min": 60,
          "preferred_split": "Upper/Lower"
        },
        // Les sous-structures venant des autres √©crans
        "performance_baseline": draft.performanceBaseline,
        "constraints": draft.constraints,
        "injury_prevention": draft.injuryPrevention,
        "goals": {
          "primary_goal": "Optimisation Performance"
        }
      };

      // 3. Appel API
      final success = await _profileService.saveCompleteProfile(payload);

      setState(() => _isSaving = false);

      if (success) {
        if (mounted) {
          ScaffoldMessenger.of(context).showSnackBar(const SnackBar(content: Text("‚úÖ Profil Athl√®te mis √† jour. Calibrage IA en cours..."), backgroundColor: Color(0xFF32D74B)));
          Navigator.pop(context);
        }
      } else {
        if (mounted) {
          ScaffoldMessenger.of(context).showSnackBar(const SnackBar(content: Text("‚ùå Erreur de sauvegarde"), backgroundColor: Colors.red));
        }
      }
    }
  }

  void _goToLab() => Navigator.push(context, MaterialPageRoute(builder: (context) => const BioCalibrationScreen()));
  void _goToMatrix() => Navigator.push(context, MaterialPageRoute(builder: (context) => const WeeklyMatrixScreen()));
  void _goToEquipment() => Navigator.push(context, MaterialPageRoute(builder: (context) => const EquipmentHealthScreen()));

  @override
  Widget build(BuildContext context) {
    // Style ISO
    final Color voltYellow = const Color(0xFFCCFF00);
    final Color cardBg = const Color(0xFF1C1C1E);
    final Color textWhite = const Color(0xFFFFFFFF);

    return Scaffold(
      backgroundColor: Colors.black,
      appBar: AppBar(backgroundColor: Colors.black, title: Text("IDENTIT√â ATHL√âTIQUE", style: GoogleFonts.bebasNeue(fontSize: 24, letterSpacing: 2, color: textWhite)), leading: IconButton(icon: const Icon(Icons.arrow_back_ios, color: Colors.white), onPressed: () => Navigator.pop(context))),
      body: SingleChildScrollView(
        padding: const EdgeInsets.all(20),
        child: Form(
          key: _formKey,
          child: Column(crossAxisAlignment: CrossAxisAlignment.start, children: [
              _sectionTitle("INFOS DE BASE"),
              Row(children: [Expanded(flex: 3, child: _buildTextField("Pseudo", _pseudoController)), const SizedBox(width: 16), Expanded(flex: 2, child: _buildDropdown("Genre", _genders, _gender, (val) => setState(() => _gender = val!)))]),
              const SizedBox(height: 24),
              _sectionTitle("ANTHROPOM√âTRIE"),
              Container(padding: const EdgeInsets.all(16), decoration: BoxDecoration(color: cardBg, borderRadius: BorderRadius.circular(16)), child: Column(children: [_buildStepperRow("√Çge", "$_age ans", onMinus: () => setState(() => _age = (_age > 14) ? _age - 1 : _age), onPlus: () => setState(() => _age++)), const Divider(color: Colors.grey, height: 24, thickness: 0.2), _buildStepperRow("Poids", "$_weight kg", onMinus: () => setState(() => _weight = (_weight > 30) ? _weight - 0.5 : _weight), onPlus: () => setState(() => _weight += 0.5)), const Divider(color: Colors.grey, height: 24, thickness: 0.2), _buildStepperRow("Taille", "$_height cm", onMinus: () => setState(() => _height = (_height > 100) ? _height - 1 : _height), onPlus: () => setState(() => _height++))])),
              const SizedBox(height: 24),
              _sectionTitle("PROFIL SPORTIF"),
              _buildDropdownMap("Niveau d'exp√©rience", _levels, _selectedLevel, (val) { setState(() => _selectedLevel = val); }),
              const SizedBox(height: 16),
              _buildDropdown("Sport Principal", _sportsSpecs.keys.toList(), _selectedSport, (val) { setState(() { _selectedSport = val; _selectedSpecialty = null; }); }),
              const SizedBox(height: 16),
              if (_selectedSport != null) _buildDropdown("Sp√©cialit√©", _sportsSpecs[_selectedSport]!, _selectedSpecialty, (val) { setState(() => _selectedSpecialty = val); }),
              const SizedBox(height: 40),
              _sectionTitle("CALIBRATION & PLANIFICATION"),
              InkWell(onTap: _goToLab, borderRadius: BorderRadius.circular(16), child: Container(padding: const EdgeInsets.all(16), decoration: BoxDecoration(border: Border.all(color: Colors.white24), borderRadius: BorderRadius.circular(16), color: Colors.white10), child: Row(children: [const Icon(Icons.science, color: Colors.cyanAccent, size: 30), const SizedBox(width: 16), const Expanded(child: Column(crossAxisAlignment: CrossAxisAlignment.start, children: [Text("Laboratoire de Performance", style: TextStyle(color: Colors.white, fontWeight: FontWeight.bold)), Text("VMA, FTP, 1RM, Zones...", style: TextStyle(color: Colors.grey, fontSize: 12))])), const Icon(Icons.arrow_forward_ios, color: Colors.white, size: 16)]))),
              const SizedBox(height: 16),
              InkWell(onTap: _goToMatrix, borderRadius: BorderRadius.circular(16), child: Container(padding: const EdgeInsets.all(16), decoration: BoxDecoration(border: Border.all(color: Colors.white24), borderRadius: BorderRadius.circular(16), color: Colors.white10), child: Row(children: [const Icon(Icons.calendar_month, color: Colors.purpleAccent, size: 30), const SizedBox(width: 16), const Expanded(child: Column(crossAxisAlignment: CrossAxisAlignment.start, children: [Text("Semaine Type (Matrice)", style: TextStyle(color: Colors.white, fontWeight: FontWeight.bold)), Text("Disponibilit√©s, Club & Cr√©neaux...", style: TextStyle(color: Colors.grey, fontSize: 12))])), const Icon(Icons.arrow_forward_ios, color: Colors.white, size: 16)]))),
              const SizedBox(height: 16),
              InkWell(onTap: _goToEquipment, borderRadius: BorderRadius.circular(16), child: Container(padding: const EdgeInsets.all(16), decoration: BoxDecoration(border: Border.all(color: Colors.white24), borderRadius: BorderRadius.circular(16), color: Colors.white10), child: Row(children: [const Icon(Icons.fitness_center, color: Color(0xFFFF453A), size: 30), const SizedBox(width: 16), const Expanded(child: Column(crossAxisAlignment: CrossAxisAlignment.start, children: [Text("Mat√©riel & Sant√©", style: TextStyle(color: Colors.white, fontWeight: FontWeight.bold)), Text("√âquipements dispo & Blessures...", style: TextStyle(color: Colors.grey, fontSize: 12))])), const Icon(Icons.arrow_forward_ios, color: Colors.white, size: 16)]))),
              const SizedBox(height: 32),
              SizedBox(width: double.infinity, child: ElevatedButton(onPressed: _isSaving ? null : _submitProfile, style: ElevatedButton.styleFrom(backgroundColor: voltYellow, foregroundColor: Colors.black, padding: const EdgeInsets.symmetric(vertical: 18), shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(12))), child: _isSaving ? const CircularProgressIndicator(color: Colors.black) : Text("ENREGISTRER LE PROFIL", style: GoogleFonts.rubik(fontSize: 16, fontWeight: FontWeight.w900, letterSpacing: 1)))),
              const SizedBox(height: 40),
            ]),
        ),
      ),
    );
  }

  Widget _sectionTitle(String title) => Padding(padding: const EdgeInsets.only(bottom: 12), child: Text(title, style: const TextStyle(color: Colors.grey, fontSize: 12, fontWeight: FontWeight.bold, letterSpacing: 1)));
  Widget _buildTextField(String label, TextEditingController controller) => TextFormField(controller: controller, style: const TextStyle(color: Colors.white), decoration: InputDecoration(labelText: label, labelStyle: const TextStyle(color: Colors.grey), filled: true, fillColor: const Color(0xFF1C1C1E), border: OutlineInputBorder(borderRadius: BorderRadius.circular(12), borderSide: BorderSide.none)), validator: (val) => val!.isEmpty ? "Requis" : null);
  Widget _buildDropdown(String label, List<String> items, String? currentValue, Function(String?) onChanged) => DropdownButtonFormField<String>(value: currentValue, dropdownColor: const Color(0xFF2C2C2E), style: const TextStyle(color: Colors.white), decoration: InputDecoration(labelText: label, labelStyle: const TextStyle(color: Colors.grey), filled: true, fillColor: const Color(0xFF1C1C1E), border: OutlineInputBorder(borderRadius: BorderRadius.circular(12), borderSide: BorderSide.none)), items: items.map((e) => DropdownMenuItem(value: e, child: Text(e, overflow: TextOverflow.ellipsis))).toList(), onChanged: onChanged, validator: (val) => val == null ? "Requis" : null);
  Widget _buildDropdownMap(String label, Map<String, String> items, String? currentValue, Function(String?) onChanged) => DropdownButtonFormField<String>(value: currentValue, isExpanded: true, dropdownColor: const Color(0xFF2C2C2E), style: const TextStyle(color: Colors.white), decoration: InputDecoration(labelText: label, labelStyle: const TextStyle(color: Colors.grey), filled: true, fillColor: const Color(0xFF1C1C1E), border: OutlineInputBorder(borderRadius: BorderRadius.circular(12), borderSide: BorderSide.none)), items: items.entries.map((e) => DropdownMenuItem(value: e.key, child: Column(crossAxisAlignment: CrossAxisAlignment.start, mainAxisAlignment: MainAxisAlignment.center, children: [Text(e.key, style: const TextStyle(fontWeight: FontWeight.bold)), Text(e.value, style: const TextStyle(fontSize: 10, color: Colors.grey))]))).toList(), onChanged: onChanged, validator: (val) => val == null ? "Requis" : null);
  Widget _buildStepperRow(String label, String valueDisplay, {required VoidCallback onMinus, required VoidCallback onPlus}) => Row(mainAxisAlignment: MainAxisAlignment.spaceBetween, children: [Text(label, style: const TextStyle(color: Colors.white, fontSize: 16)), Row(children: [_circleBtn(Icons.remove, onMinus), Container(alignment: Alignment.center, width: 80, child: Text(valueDisplay, style: GoogleFonts.robotoMono(color: const Color(0xFFCCFF00), fontSize: 18, fontWeight: FontWeight.bold))), _circleBtn(Icons.add, onPlus)])]);
  Widget _circleBtn(IconData icon, VoidCallback onTap) => InkWell(onTap: onTap, borderRadius: BorderRadius.circular(20), child: Container(width: 32, height: 32, decoration: const BoxDecoration(color: Color(0xFF333333), shape: BoxShape.circle), child: Icon(icon, color: Colors.white, size: 18)));
}
-e 

-e 
================================================================================
üìÑ FICHIER : backend/frontend/lib/screens/weekly_matrix_screen.dart
================================================================================
import 'package:flutter/material.dart';
import 'package:google_fonts/google_fonts.dart';
import '../models/profile_draft.dart'; // <--- AJOUT

class WeeklyMatrixScreen extends StatefulWidget {
  const WeeklyMatrixScreen({super.key});

  @override
  State<WeeklyMatrixScreen> createState() => _WeeklyMatrixScreenState();
}

class _WeeklyMatrixScreenState extends State<WeeklyMatrixScreen> {
  // --- COLORS ---
  final Color _bgDark = const Color(0xFF000000);
  final Color _cardDark = const Color(0xFF1C1C1E);
  final Color _voltYellow = const Color(0xFFCCFF00);
  final Color _redStrength = const Color(0xFFFF453A);
  final Color _blueClub = const Color(0xFF2196F3);
  final Color _purpleLibre = const Color(0xFFA020F0);
  final Color _textGrey = const Color(0xFF8E8E93);
  // --- DATA MODEL ---
  final List<String> _days = ["LUNDI", "MARDI", "MERCREDI", "JEUDI", "VENDREDI", "SAMEDI", "DIMANCHE"];
  final List<String> _types = ["Repos", "PPS (Sport)", "PPG (Renfo)", "Libre (IA)", "Club (Fixe)"];

  late Map<String, List<Map<String, dynamic>>> _matrix;

  @override
  void initState() {
    super.initState();
    _initMatrix();
  }

  void _initMatrix() {
    _matrix = {
      for (var day in _days)
        day: [
          {'type': 'Repos', 'duration': 0.0}, 
          {'type': 'Repos', 'duration': 0.0},
        ]
    };
  }

  // --- SAVE DATA (CONNECT√â) ---
  void _saveMatrix() {
    // On sauvegarde la matrice brute dans le Draft
    ProfileDraft().constraints['time_matrix'] = _matrix;

    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(
        content: const Text("üíæ Semaine type enregistr√©e ! L'IA va structurer le cycle."),
        backgroundColor: _voltYellow,
        behavior: SnackBarBehavior.floating,
      ),
    );
    Navigator.pop(context);
  }

  Color _getTypeColor(String type) {
    if (type.contains("PPS")) return _voltYellow;
    if (type.contains("PPG")) return _redStrength;
    if (type.contains("Club")) return _blueClub;
    if (type.contains("Libre")) return _purpleLibre;
    return _textGrey;
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: _bgDark,
      appBar: AppBar(
        backgroundColor: _bgDark,
        title: Text("SEMAINE TYPE", style: GoogleFonts.bebasNeue(fontSize: 24, letterSpacing: 2, color: Colors.white)),
        leading: IconButton(
          icon: const Icon(Icons.arrow_back_ios, color: Colors.white),
          onPressed: () => Navigator.pop(context),
        ),
        actions: [
           IconButton(
            icon: const Icon(Icons.refresh, color: Colors.grey),
            onPressed: () => setState(() => _initMatrix()),
            tooltip: "Reset",
          ),
        ],
      ),
      body: Column(
        children: [
          Container(
            padding: const EdgeInsets.symmetric(horizontal: 20, vertical: 10),
            color: _bgDark,
            child: Row(
              children: [
                const Icon(Icons.info_outline, color: Colors.grey, size: 16),
                const SizedBox(width: 8),
                Expanded(child: Text("D√©finis tes disponibilit√©s. L'IA comblera les cr√©neaux 'Libre' selon ta fatigue.", style: GoogleFonts.rubik(color: Colors.grey, fontSize: 12))),
              ],
            ),
          ),
          Expanded(
            child: ListView.separated(
              padding: const EdgeInsets.all(16),
              itemCount: _days.length,
              separatorBuilder: (ctx, i) => const SizedBox(height: 16),
              itemBuilder: (ctx, i) {
                return _buildDayCard(_days[i]);
              },
            ),
          ),
        ],
      ),
      bottomNavigationBar: Container(
        padding: const EdgeInsets.all(20),
        decoration: BoxDecoration(color: _bgDark, border: Border(top: BorderSide(color: Colors.white.withOpacity(0.1)))),
        child: ElevatedButton(
          onPressed: _saveMatrix,
          style: ElevatedButton.styleFrom(backgroundColor: _voltYellow, foregroundColor: Colors.black, padding: const EdgeInsets.symmetric(vertical: 18), shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(12))),
          child: Text("VALIDER LA SEMAINE", style: GoogleFonts.rubik(fontWeight: FontWeight.bold, letterSpacing: 1)),
        ),
      ),
    );
  }

  Widget _buildDayCard(String day) {
    List<Map<String, dynamic>> slots = _matrix[day]!;
    bool isActiveDay = slots.any((s) => s['type'] != 'Repos');
    return Container(
      decoration: BoxDecoration(color: _cardDark, borderRadius: BorderRadius.circular(12), border: Border.all(color: isActiveDay ? Colors.white.withOpacity(0.1) : Colors.transparent)),
      child: Column(crossAxisAlignment: CrossAxisAlignment.start, children: [
          Container(width: double.infinity, padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 8), decoration: BoxDecoration(color: isActiveDay ? Colors.white.withOpacity(0.05) : Colors.transparent, borderRadius: const BorderRadius.vertical(top: Radius.circular(12))), child: Text(day, style: GoogleFonts.bebasNeue(fontSize: 18, letterSpacing: 1.5, color: isActiveDay ? Colors.white : _textGrey))),
          Padding(padding: const EdgeInsets.all(12), child: Column(children: [
                _buildSlotRow(day, 0, "Cr√©neau 1 (Matin)"),
                const Divider(color: Colors.white10, height: 24),
                _buildSlotRow(day, 1, "Cr√©neau 2 (Soir)"),
              ])),
        ]),
    );
  }

  Widget _buildSlotRow(String day, int slotIndex, String label) {
    Map<String, dynamic> slot = _matrix[day]![slotIndex];
    String currentType = slot['type'];
    double currentDuration = slot['duration'];
    bool isRest = currentType == 'Repos';
    Color typeColor = _getTypeColor(currentType);

    return Column(crossAxisAlignment: CrossAxisAlignment.start, children: [
        Row(mainAxisAlignment: MainAxisAlignment.spaceBetween, children: [
            Text(label, style: const TextStyle(color: Colors.grey, fontSize: 10)),
            Container(height: 32, padding: const EdgeInsets.symmetric(horizontal: 12), decoration: BoxDecoration(color: isRest ? Colors.transparent : typeColor.withOpacity(0.1), borderRadius: BorderRadius.circular(8), border: Border.all(color: isRest ? Colors.white24 : typeColor)),
              child: DropdownButton<String>(
                value: currentType, dropdownColor: const Color(0xFF2C2C2E), underline: const SizedBox(),
                icon: Icon(Icons.arrow_drop_down, color: isRest ? Colors.grey : typeColor, size: 18),
                style: GoogleFonts.rubik(fontSize: 12, fontWeight: FontWeight.bold, color: isRest ? Colors.grey : typeColor),
                items: _types.map((String value) { return DropdownMenuItem<String>(value: value, child: Text(value)); }).toList(),
                onChanged: (newValue) { setState(() { _matrix[day]![slotIndex]['type'] = newValue!; if (newValue == 'Repos') { _matrix[day]![slotIndex]['duration'] = 0.0; } else if (currentDuration == 0) { _matrix[day]![slotIndex]['duration'] = 60.0; } }); },
              ),
            ),
          ]),
        if (!isRest) ...[
          const SizedBox(height: 8),
          Row(children: [
              const Icon(Icons.timer_outlined, color: Colors.grey, size: 16),
              const SizedBox(width: 8),
              Expanded(child: SliderTheme(data: SliderThemeData(activeTrackColor: typeColor, inactiveTrackColor: Colors.white10, thumbColor: Colors.white, overlayColor: typeColor.withOpacity(0.2), trackHeight: 4, thumbShape: const RoundSliderThumbShape(enabledThumbRadius: 6)), child: Slider(value: currentDuration, min: 30, max: 300, divisions: 18, label: "${currentDuration.round()} min", onChanged: (val) { setState(() { _matrix[day]![slotIndex]['duration'] = val; }); }))),
              const SizedBox(width: 8),
              SizedBox(width: 60, child: Text(_formatDuration(currentDuration), textAlign: TextAlign.end, style: GoogleFonts.robotoMono(color: Colors.white, fontSize: 13))),
            ]),
        ] else ...[ const SizedBox(height: 20, child: Align(alignment: Alignment.centerLeft, child: Text("‚Äî OFF ‚Äî", style: TextStyle(color: Colors.white10, fontSize: 10)))) ]
      ]);
  }

  String _formatDuration(double minutes) {
    int h = minutes ~/ 60;
    int m = (minutes % 60).toInt();
    if (h > 0) return "${h}h${m.toString().padLeft(2, '0')}";
    return "${m} min";
  }
}
-e 

-e 
================================================================================
üìÑ FICHIER : backend/frontend/lib/services/profile_service.dart
================================================================================

import 'dart:convert';
import 'package:http/http.dart' as http;
import 'package:shared_preferences/shared_preferences.dart';
import 'auth_service.dart';

class ProfileService {
  final String baseUrl = AuthService.baseUrl;

  Future<bool> saveCompleteProfile(Map<String, dynamic> profileJson) async {
    final prefs = await SharedPreferences.getInstance();
    final token = prefs.getString('token');

    if (token == null) {
      print("‚õî Pas de token trouv√©");
      return false;
    }

    print("üöÄ [PROFILE] Envoi du JSON...");
    try {
      final response = await http.post(
        Uri.parse('$baseUrl/api/v1/profiles/complete'),
        headers: {
          'Authorization': 'Bearer $token',
          'Content-Type': 'application/json',
        },
        body: jsonEncode(profileJson),
      );

      print("üì° Status: ${response.statusCode}");
      if (response.statusCode == 200 || response.statusCode == 201) {
        return true;
      }
      print("‚ùå Erreur Backend: ${response.body}");
      return false;
    } catch (e) {
      print("üî• Exception R√©seau: $e");
      return false;
    }
  }
}
-e 

-e 
================================================================================
üìÑ FICHIER : backend/generate_map.py
================================================================================
import sys
import os
import json
import inspect
import re

# --- CONFIGURATION DES CHEMINS ---
# On se place dans backend/tools/, on veut remonter √† la racine du projet
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../'))
BACKEND_DIR = os.path.join(BASE_DIR, 'backend')
PUBSPEC_PATH = os.path.join(BASE_DIR, 'pubspec.yaml') # Hypoth√®se: pubspec √† la racine ou dans frontend/
REQUIREMENTS_PATH = os.path.join(BACKEND_DIR, 'requirements.txt')
MAP_FILE = os.path.join(BASE_DIR, 'TITANFLOW_MAP.json')

# Ajout du backend au path pour les imports SQLAlchemy
sys.path.append(BACKEND_DIR)

try:
    from app.models import sql_models
    from app.core.database import Base
except ImportError as e:
    print(f"‚ùå Erreur d'import Backend : {e}")
    print("Assurez-vous d'√™tre dans l'environnement virtuel (venv).")
    sys.exit(1)

def get_flutter_environment():
    """Lit le pubspec.yaml pour extraire les versions."""
    env = {"sdk": "Unknown", "packages": {}}
    
    if not os.path.exists(PUBSPEC_PATH):
        print(f"‚ö†Ô∏è  pubspec.yaml introuvable ici : {PUBSPEC_PATH}")
        return env

    with open(PUBSPEC_PATH, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        
    in_dependencies = False
    for line in lines:
        line = line.strip()
        # SDK Version
        if line.startswith('sdk:'):
            env['sdk'] = line.split(':')[1].strip()
        
        # D√©tection bloc dependencies
        if line == 'dependencies:':
            in_dependencies = True
            continue
        if line == 'dev_dependencies:':
            in_dependencies = False
            continue
            
        # Extraction packages cl√©s (http, provider, etc.)
        if in_dependencies and ':' in line:
            parts = line.split(':')
            pkg_name = parts[0].strip()
            version = parts[1].strip()
            # On garde seulement les packages int√©ressants pour l'IA
            interesting_libs = ['http', 'shared_preferences', 'intl', 'flutter', 'provider', 'riverpod', 'bloc', 'go_router']
            if pkg_name in interesting_libs:
                env['packages'][pkg_name] = version
                
    return env

def get_backend_environment():
    """Lit le requirements.txt pour les versions Python."""
    env = {"python": sys.version.split()[0], "libs": {}}
    
    if not os.path.exists(REQUIREMENTS_PATH):
        return env

    with open(REQUIREMENTS_PATH, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if '==' in line:
                parts = line.split('==')
                env['libs'][parts[0]] = parts[1]
            elif '>=' in line:
                parts = line.split('>=')
                env['libs'][parts[0]] = f">={parts[1]}"
                
    return env

def generate_db_schema():
    """Scan les mod√®les SQLAlchemy."""
    schema = {}
    for name, obj in inspect.getmembers(sql_models):
        if inspect.isclass(obj) and issubclass(obj, Base) and obj != Base:
            table_name = obj.__tablename__
            columns = []
            
            for col in obj.__table__.columns:
                col_type = str(col.type)
                info = f"{col.name} ({col_type})"
                if col.primary_key: info += " [PK]"
                if col.foreign_keys: info += " [FK]"
                columns.append(info)
            
            schema[table_name] = {
                "description": f"Table SQL {table_name}",
                "columns": columns
            }
    return schema

def main():
    print("üöÄ D√©marrage de la cartographie TitanFlow...")
    
    # 1. Chargement existant
    data = {}
    if os.path.exists(MAP_FILE):
        try:
            with open(MAP_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except json.JSONDecodeError:
            print("‚ö†Ô∏è  Fichier JSON corrompu, cr√©ation d'un nouveau.")

    # 2. Mise √† jour Environment (Versions)
    print("üì¶ Analyse des d√©pendances (Flutter & Python)...")
    data["environment"] = {
        "frontend": get_flutter_environment(),
        "backend": get_backend_environment()
    }

    # 3. Mise √† jour DB Schema
    print("üóÑÔ∏è  Introspection de la Base de Donn√©es...")
    data["database_schema"] = generate_db_schema()

    # 4. Sauvegarde
    with open(MAP_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ Succ√®s ! Fichier mis √† jour : {MAP_FILE}")
    print("   -> L'IA aura maintenant une vision exacte de tes versions et de ta BDD.")

if __name__ == "__main__":
    main()-e 

-e 
================================================================================
üìÑ FICHIER : backend/implement.py
================================================================================
import os
import sys
import logging
from sqlalchemy import create_engine, text, inspect
from dotenv import load_dotenv
import json

# Configuration
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger("TitanUpgrader")

# --- CHEMIN DYNAMIQUE ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# 1. NOUVEAUX MOD√àLES SQL
SQL_MODELS_CONTENT = """from sqlalchemy import Column, Integer, String, Float, Date, ForeignKey, DateTime, Text, Boolean, JSON
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
from app.core.database import Base

class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True, index=True)
    email = Column(String, unique=True, index=True, nullable=True)
    hashed_password = Column(String)
    
    # Anciens champs (Legacy support)
    profile_data = Column(Text, nullable=True)
    strategy_data = Column(Text, nullable=True)
    weekly_plan_data = Column(Text, nullable=True)
    draft_workout_data = Column(Text, nullable=True)

    # Relations
    workouts = relationship("WorkoutSession", back_populates="owner")
    feed_items = relationship("FeedItem", back_populates="owner", cascade="all, delete-orphan")
    
    # [NOUVEAU] Relation vers le Profil Enrichi
    athlete_profile = relationship("AthleteProfile", back_populates="user", uselist=False, cascade="all, delete-orphan")

class AthleteProfile(Base):
    __tablename__ = "athlete_profiles"

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"), unique=True)

    # Blocs de donn√©es JSONB
    basic_info = Column(JSON, default={})
    physical_metrics = Column(JSON, default={})
    sport_context = Column(JSON, default={})
    performance_baseline = Column(JSON, default={})
    injury_prevention = Column(JSON, default={})
    training_preferences = Column(JSON, default={})
    goals = Column(JSON, default={})
    constraints = Column(JSON, default={})

    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())

    user = relationship("User", back_populates="athlete_profile")
    coach_memory = relationship("CoachMemory", back_populates="athlete_profile", uselist=False, cascade="all, delete-orphan")

class CoachMemory(Base):
    __tablename__ = "coach_memories"

    id = Column(Integer, primary_key=True, index=True)
    athlete_profile_id = Column(Integer, ForeignKey("athlete_profiles.id"), unique=True)

    # M√©moire contextuelle IA
    metadata_info = Column(JSON, default={})
    current_context = Column(JSON, default={})
    response_patterns = Column(JSON, default={})
    performance_baselines = Column(JSON, default={})
    adaptation_signals = Column(JSON, default={})
    sport_specific_insights = Column(JSON, default={})
    training_history_summary = Column(JSON, default={})
    athlete_preferences = Column(JSON, default={})
    coach_notes = Column(JSON, default={})
    memory_flags = Column(JSON, default={})

    last_updated = Column(DateTime(timezone=True), server_default=func.now())

    athlete_profile = relationship("AthleteProfile", back_populates="coach_memory")

# --- MOD√àLES EXISTANTS ---
class WorkoutSession(Base):
    __tablename__ = "workout_sessions"
    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"))
    date = Column(Date, index=True)
    duration = Column(Float)
    rpe = Column(Float)
    energy_level = Column(Integer, default=5) 
    notes = Column(Text, nullable=True)      
    ai_analysis = Column(Text, nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    owner = relationship("User", back_populates="workouts")
    sets = relationship("WorkoutSet", back_populates="session", cascade="all, delete-orphan")

class WorkoutSet(Base):
    __tablename__ = "workout_sets"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(Integer, ForeignKey("workout_sessions.id"))
    exercise_name = Column(String, index=True)
    set_order = Column(Integer)
    weight = Column(Float, default=0.0)
    reps = Column(Float, default=0.0)
    rpe = Column(Float, default=0.0)
    rest_seconds = Column(Integer, default=0)
    metric_type = Column(String, nullable=False, default="LOAD_REPS") 
    session = relationship("WorkoutSession", back_populates="sets")

class FeedItem(Base):
    __tablename__ = "feed_items"
    id = Column(String, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"))
    type = Column(String, index=True)
    title = Column(String)
    message = Column(String)
    action_payload = Column(Text, nullable=True)
    is_read = Column(Boolean, default=False)
    is_completed = Column(Boolean, default=False)
    priority = Column(Integer, default=1)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    owner = relationship("User", back_populates="feed_items")
"""

# 2. SCHEMAS PYDANTIC
SCHEMAS_CONTENT = """from pydantic import BaseModel, Field, field_validator
from typing import List, Optional, Dict, Any, Union
from datetime import date, datetime
from enum import Enum
import json

# --- ENUMS & TYPES ---
class SportType(str, Enum):
    RUGBY = "Rugby"
    FOOTBALL = "Football"
    CROSSFIT = "CrossFit"
    HYBRID = "Hybrid"
    RUNNING = "Running"
    OTHER = "Autre"

# --- SUB-SCHEMAS FOR PROFILE ---
class BasicInfo(BaseModel):
    pseudo: Optional[str] = None
    email: Optional[str] = None
    birth_date: Optional[str] = None
    training_age: Optional[int] = 0

class PhysicalMetrics(BaseModel):
    height: float = 0
    weight: float = 0
    body_fat: Optional[float] = None
    resting_hr: Optional[int] = None
    sleep_quality_avg: Optional[int] = 5

class SportContext(BaseModel):
    sport: SportType = SportType.OTHER
    position: Optional[str] = None
    level: str = "Interm√©diaire"
    equipment: List[str] = ["Standard"]

class TrainingPreferences(BaseModel):
    days_available: List[str] = []
    duration_min: int = 60
    preferred_split: str = "Upper/Lower"

# --- MAIN PROFILE SCHEMAS ---
class AthleteProfileBase(BaseModel):
    basic_info: BasicInfo = Field(default_factory=BasicInfo)
    physical_metrics: PhysicalMetrics = Field(default_factory=PhysicalMetrics)
    sport_context: SportContext = Field(default_factory=SportContext)
    training_preferences: TrainingPreferences = Field(default_factory=TrainingPreferences)
    goals: Dict[str, Any] = {}
    constraints: Dict[str, Any] = {}
    injury_prevention: Dict[str, Any] = {}
    performance_baseline: Dict[str, Any] = {}

class AthleteProfileCreate(AthleteProfileBase):
    pass

class AthleteProfileResponse(AthleteProfileBase):
    id: int
    user_id: int
    created_at: datetime
    class Config:
        from_attributes = True

# --- MEMORY SCHEMAS ---
class CoachMemoryResponse(BaseModel):
    id: int
    readiness_score: int = Field(alias="current_context", default={}).get("readiness_score", 0)
    current_phase: str = "G√©n√©ral"
    flags: Dict[str, bool] = {}
    insights: Dict[str, Any] = {}
    
    @field_validator('readiness_score', mode='before')
    def extract_readiness(cls, v):
        if isinstance(v, dict): return v.get('readiness_score', 50)
        return v

    class Config:
        from_attributes = True

# --- LEGACY SCHEMAS ---
class WorkoutSetBase(BaseModel):
    exercise_name: str
    set_order: int
    weight: Union[float, str] = 0.0
    reps: Union[float, str] = 0.0
    rpe: Optional[float] = 0.0
    rest_seconds: int = 0
    metric_type: str = "LOAD_REPS"

    @field_validator('weight', 'reps', mode='before')
    def parse_polymorphic_fields(cls, v):
        if isinstance(v, str):
            v = v.strip().replace(',', '.')
            if ':' in v:
                parts = v.split(':')
                try:
                    seconds = 0.0
                    if len(parts) == 2:
                        seconds = float(parts[0]) * 60 + float(parts[1])
                    elif len(parts) == 3:
                        seconds = float(parts[0]) * 3600 + float(parts[1]) * 60 + float(parts[2])
                    return seconds
                except ValueError:
                    return 0.0
            try:
                return float(v)
            except ValueError:
                return 0.0
        return v

class WorkoutSetCreate(WorkoutSetBase):
    pass

class WorkoutSessionCreate(BaseModel):
    date: date
    duration: float
    rpe: float
    energy_level: int = 5
    notes: Optional[str] = None
    sets: List[WorkoutSetCreate] = []

class WorkoutSetResponse(WorkoutSetBase):
    id: int
    weight: float
    reps: float
    class Config:
        from_attributes = True

class WorkoutSessionResponse(WorkoutSessionCreate):
    id: int
    ai_analysis: Optional[str] = None
    sets: List[WorkoutSetResponse] = []
    class Config:
        from_attributes = True

class GenerateWorkoutRequest(BaseModel):
    profile_data: Dict[str, Any]
    context: Dict[str, Any]

class AIExercise(BaseModel):
    name: str
    sets: int
    reps: Union[str, int]
    rest: int
    tips: str
    recording_mode: str = "LOAD_REPS"
    @field_validator('reps')
    def force_string_reps(cls, v):
        return str(v)

class AIWorkoutPlan(BaseModel):
    title: str
    coach_comment: str
    warmup: List[str]
    exercises: List[AIExercise]
    cooldown: List[str]

class UserCreate(BaseModel):
    username: str
    email: Optional[str] = None
    password: str

class UserResponse(BaseModel):
    id: int
    username: str
    email: Optional[str] = None
    profile_data: Optional[str] = None 
    class Config:
        from_attributes = True

class Token(BaseModel):
    access_token: str
    token_type: str

class TokenData(BaseModel):
    username: Optional[str] = None

class FeedItemType(str, Enum):
    INFO = "INFO"
    ANALYSIS = "ANALYSIS"
    ACTION = "ACTION"
    ALERT = "ALERT"

class FeedItemCreate(BaseModel):
    type: FeedItemType
    title: str
    message: str
    priority: int = 1
    action_payload: Optional[Dict[str, Any]] = None

class FeedItemResponse(FeedItemCreate):
    id: str
    is_read: bool
    is_completed: bool
    created_at: datetime
    
    @field_validator('action_payload', mode='before')
    def parse_payload(cls, v):
        if isinstance(v, str) and v.strip():
            try: return json.loads(v)
            except: return None
        return v
    class Config:
        from_attributes = True

# --- PERFORMANCE ---
class OneRepMaxRequest(BaseModel):
    weight: float
    reps: int
class OneRepMaxResponse(BaseModel):
    estimated_1rm: float
    method_used: str
class ACWRRequest(BaseModel):
    history: List[Dict[str, Any]]
class ACWRResponse(BaseModel):
    ratio: float
    status: str
    color: str
    message: str
class ProfileAuditRequest(BaseModel):
    profile_data: Dict[str, Any]
class ProfileAuditResponse(BaseModel):
    markdown_report: str
class StrategyResponse(BaseModel):
    periodization_title: str
    phases: List[Any]
class WeeklyPlanResponse(BaseModel):
    schedule: List[Any]
    reasoning: str
class UserProfileUpdate(BaseModel):
    profile_data: Dict[str, Any]
"""

# 3. LOGIQUE M√âTIER
LOGIC_CONTENT = """from datetime import date
from typing import Dict, Any
from app.models import sql_models

VALID_SPORT_POSITIONS = {
    'Rugby': ['Pilier', 'Talonneur', '2√®me ligne', '3√®me ligne', 'Demi', 'Centre', 'Ailier', 'Arri√®re'],
    'Football': ['Gardien', 'D√©fenseur', 'Milieu', 'Attaquant'],
}

class CoachLogic:
    @staticmethod
    def validate_sport_position(sport: str, position: str) -> bool:
        if sport in VALID_SPORT_POSITIONS:
            if position and position not in VALID_SPORT_POSITIONS[sport]:
                return False
        return True

    @staticmethod
    def initialize_memory(profile: sql_models.AthleteProfile) -> sql_models.CoachMemory:
        sport = profile.sport_context.get('sport', 'Autre')
        insights = {
            "primary_sport": sport,
            "specificity_index": "High" if sport in ['Rugby', 'Football'] else "Medium",
            "focus_areas": ["Strength", "Hypertrophy"] 
        }
        context = {
            "macrocycle_phase": "Adaptation Anatomique",
            "fatigue_state": "Fresh",
            "readiness_score": 100,
            "season_week": 1
        }
        flags = {
            "needs_deload": False,
            "injury_risk": False,
            "adaptation_window_open": True
        }
        memory = sql_models.CoachMemory(
            athlete_profile_id=profile.id,
            sport_specific_insights=insights,
            current_context=context,
            memory_flags=flags,
            coach_notes={"initialization": f"Profil cr√©√© le {date.today()}"}
        )
        return memory

    @staticmethod
    def calculate_readiness(profile: sql_models.AthleteProfile) -> int:
        base_score = 80
        sleep = profile.physical_metrics.get('sleep_quality_avg', 5)
        if sleep >= 8: base_score += 10
        elif sleep <= 4: base_score -= 20
        stress = profile.constraints.get('work_stress_level', 5)
        if stress >= 8: base_score -= 15
        return max(0, min(100, base_score))

    @staticmethod
    def update_daily(memory: sql_models.CoachMemory, profile: sql_models.AthleteProfile):
        new_readiness = CoachLogic.calculate_readiness(profile)
        current_context = dict(memory.current_context or {})
        current_context['readiness_score'] = new_readiness
        
        if new_readiness < 40:
            current_context['fatigue_state'] = "High"
        elif new_readiness < 70:
            current_context['fatigue_state'] = "Moderate"
        else:
            current_context['fatigue_state'] = "Optimal"
            
        memory.current_context = current_context
        flags = dict(memory.memory_flags or {})
        flags['needs_deload'] = new_readiness < 30
        flags['adaptation_window_open'] = new_readiness > 70
        memory.memory_flags = flags
"""

# 4. NOUVEAU ROUTEUR
ROUTER_CONTENT = """from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.models import sql_models, schemas
from app.dependencies import get_current_user
from app.services.coach_logic import CoachLogic

router = APIRouter(
    prefix="/api/v1",
    tags=["Athlete Profile & Memory"]
)

@router.get("/profiles/me", response_model=schemas.AthleteProfileResponse)
async def get_my_profile(
    current_user: sql_models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    if not current_user.athlete_profile:
        profile = sql_models.AthleteProfile(user_id=current_user.id)
        db.add(profile)
        db.commit()
        db.refresh(profile)
        return profile
    return current_user.athlete_profile

@router.post("/profiles/complete", response_model=schemas.AthleteProfileResponse)
async def complete_profile(
    profile_data: schemas.AthleteProfileCreate,
    current_user: sql_models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    sport = profile_data.sport_context.sport
    pos = profile_data.sport_context.position
    if not CoachLogic.validate_sport_position(sport, pos):
        raise HTTPException(status_code=400, detail=f"Position {pos} invalide pour le sport {sport}")

    db_profile = current_user.athlete_profile
    if not db_profile:
        db_profile = sql_models.AthleteProfile(user_id=current_user.id)
        db.add(db_profile)
    
    db_profile.basic_info = profile_data.basic_info.dict()
    db_profile.physical_metrics = profile_data.physical_metrics.dict()
    db_profile.sport_context = profile_data.sport_context.dict()
    db_profile.training_preferences = profile_data.training_preferences.dict()
    db_profile.goals = profile_data.goals
    db_profile.constraints = profile_data.constraints
    
    if not db_profile.coach_memory:
        memory = CoachLogic.initialize_memory(db_profile)
        db.add(memory)
    
    db.commit()
    db.refresh(db_profile)
    return db_profile

@router.get("/coach-memories/me", response_model=schemas.CoachMemoryResponse)
async def get_my_coach_memory(
    current_user: sql_models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    if not current_user.athlete_profile or not current_user.athlete_profile.coach_memory:
        raise HTTPException(status_code=404, detail="Profil ou M√©moire introuvable. Compl√©tez votre profil.")
    return current_user.athlete_profile.coach_memory

@router.post("/coach-memories/recalculate")
async def force_recalculate(
    current_user: sql_models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    profile = current_user.athlete_profile
    if not profile or not profile.coach_memory:
        raise HTTPException(status_code=404, detail="Introuvable")
        
    CoachLogic.update_daily(profile.coach_memory, profile)
    db.commit()
    return {"status": "updated", "new_readiness": profile.coach_memory.current_context.get('readiness_score')}
"""

# --- FONCTIONS UTILITAIRES ---
def write_file(path, content):
    full_path = os.path.join(BASE_DIR, path)
    os.makedirs(os.path.dirname(full_path), exist_ok=True)
    with open(full_path, "w", encoding="utf-8") as f:
        f.write(content)
    logger.info(f"‚úÖ Fichier √©crit : {path}")

def update_main_py():
    main_path = os.path.join(BASE_DIR, "app/main.py")
    if not os.path.exists(main_path):
        logger.error(f"‚ùå Impossible de trouver {main_path}. V√©rifiez l'emplacement du script.")
        return

    with open(main_path, "r", encoding="utf-8") as f:
        content = f.read()
    
    if "app.routers import profiles" in content:
        logger.info("‚ÑπÔ∏è main.py d√©j√† √† jour.")
        return

    content = content.replace(
        "from app.routers import performance, safety, auth, workouts, coach, user, feed",
        "from app.routers import performance, safety, auth, workouts, coach, user, feed, profiles"
    )
    
    if "app.include_router(feed.router)" in content:
        content = content.replace(
            "app.include_router(feed.router)",
            "app.include_router(feed.router)\napp.include_router(profiles.router)"
        )
    
    with open(main_path, "w", encoding="utf-8") as f:
        f.write(content)
    logger.info("‚úÖ main.py mis √† jour avec le routeur profiles.")

def migrate_database():
    """Migration SQL + Donn√©es"""
    logger.info("üîÑ D√©marrage de la migration base de donn√©es...")
    load_dotenv(os.path.join(BASE_DIR, ".env"))
    
    db_url = os.getenv("DATABASE_URL", "sqlite:///./sql_app.db")
    if db_url.startswith("postgres://"):
        db_url = db_url.replace("postgres://", "postgresql://", 1)
        
    engine = create_engine(db_url)
    
    with engine.connect() as conn:
        trans = conn.begin()
        try:
            # 1. CR√âATION DES TABLES V2
            logger.info("üÜï Cr√©ation des tables V2 (si absentes)...")
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS athlete_profiles (
                    id SERIAL PRIMARY KEY,
                    user_id INTEGER UNIQUE REFERENCES users(id) ON DELETE CASCADE,
                    basic_info JSON DEFAULT '{}',
                    physical_metrics JSON DEFAULT '{}',
                    sport_context JSON DEFAULT '{}',
                    performance_baseline JSON DEFAULT '{}',
                    injury_prevention JSON DEFAULT '{}',
                    training_preferences JSON DEFAULT '{}',
                    goals JSON DEFAULT '{}',
                    constraints JSON DEFAULT '{}',
                    created_at TIMESTAMPTZ DEFAULT NOW(),
                    updated_at TIMESTAMPTZ DEFAULT NOW()
                );
            """))
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS coach_memories (
                    id SERIAL PRIMARY KEY,
                    athlete_profile_id INTEGER UNIQUE REFERENCES athlete_profiles(id) ON DELETE CASCADE,
                    metadata_info JSON DEFAULT '{}',
                    current_context JSON DEFAULT '{}',
                    response_patterns JSON DEFAULT '{}',
                    performance_baselines JSON DEFAULT '{}',
                    adaptation_signals JSON DEFAULT '{}',
                    sport_specific_insights JSON DEFAULT '{}',
                    training_history_summary JSON DEFAULT '{}',
                    athlete_preferences JSON DEFAULT '{}',
                    coach_notes JSON DEFAULT '{}',
                    memory_flags JSON DEFAULT '{}',
                    last_updated TIMESTAMPTZ DEFAULT NOW()
                );
            """))

            # 1.5. PATCH DES TABLES EXISTANTES (Correction de l'erreur email)
            # Cette √©tape ajoute les colonnes AVANT d'essayer de les lire pour la migration
            logger.info("üîß V√©rification et r√©paration du sch√©ma 'users'...")
            try:
                # Tentative d'ajout des colonnes si elles manquent
                conn.execute(text("ALTER TABLE users ADD COLUMN IF NOT EXISTS email VARCHAR UNIQUE;"))
                conn.execute(text("ALTER TABLE users ADD COLUMN IF NOT EXISTS profile_data TEXT;"))
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Note sur le patch de sch√©ma: {e}")
                # En cas d'erreur ici, on continue, l'√©tape de migration de donn√©es √©chouera plus tard si critique

            # 2. MIGRATION DES DONN√âES
            logger.info("üîÑ Migration des donn√©es utilisateurs existants...")
            
            # Maintenant que la colonne email existe forc√©ment, cette requ√™te ne plantera plus
            result = conn.execute(text("SELECT id, username, email, profile_data FROM users"))
            users = result.fetchall()
            
            migrated_count = 0
            for u in users:
                # V√©rifier si profil existe d√©j√†
                exists = conn.execute(text(f"SELECT 1 FROM athlete_profiles WHERE user_id = {u.id}")).scalar()
                if not exists:
                    # Parsing old data
                    old_data = {}
                    if u.profile_data:
                        try:
                            old_data = json.loads(u.profile_data)
                        except:
                            pass
                    
                    # Construction new data structure
                    basic_info = json.dumps({"pseudo": u.username, "email": u.email})
                    physical_metrics = json.dumps({"weight": old_data.get("weight", 0), "height": old_data.get("height", 0)})
                    sport_context = json.dumps({"sport": old_data.get("sport", "Autre"), "level": old_data.get("level", "Interm√©diaire")})
                    
                    # Insert AthleteProfile
                    conn.execute(text("""
                        INSERT INTO athlete_profiles (user_id, basic_info, physical_metrics, sport_context)
                        VALUES (:uid, :bi, :pm, :sc)
                    """), {"uid": u.id, "bi": basic_info, "pm": physical_metrics, "sc": sport_context})
                    
                    # Get Profile ID
                    pid_result = conn.execute(text(f"SELECT id FROM athlete_profiles WHERE user_id = {u.id}"))
                    pid = pid_result.scalar()
                    
                    # Insert Default CoachMemory
                    if pid:
                        conn.execute(text("""
                            INSERT INTO coach_memories (athlete_profile_id, current_context, memory_flags)
                            VALUES (:pid, '{"readiness_score": 80, "phase": "Integration"}', '{"migrated": true}')
                        """), {"pid": pid})
                    
                    migrated_count += 1
            
            trans.commit()
            logger.info(f"‚úÖ Migration termin√©e : {migrated_count} utilisateurs migr√©s vers v2.")
            
        except Exception as e:
            trans.rollback()
            logger.error(f"‚ùå Erreur migration DB: {e}")
            raise e

# --- EXECUTION PRINCIPALE ---

if __name__ == "__main__":
    print("üöÄ D√©marrage de la mise √† jour TitanFlow v2 (Fix Email)...")
    
    # 1. √âcriture des fichiers
    write_file("app/models/sql_models.py", SQL_MODELS_CONTENT)
    write_file("app/models/schemas.py", SCHEMAS_CONTENT)
    write_file("app/services/coach_logic.py", LOGIC_CONTENT)
    write_file("app/routers/profiles.py", ROUTER_CONTENT)
    
    # 2. Mise √† jour main.py
    update_main_py()
    
    # 3. Migration DB
    try:
        migrate_database()
    except Exception as e:
        logger.error(f"‚ùå √âchec critique: {e}")

    print("\n‚ú® Installation termin√©e ! Relancez le serveur Uvicorn.")-e 

-e 
================================================================================
üìÑ FICHIER : backend/init_db.py
================================================================================
from app.core.database import engine, Base
from app.models import sql_models

print("üèóÔ∏è  Force-Cr√©ation des tables en cours...")
try:
    Base.metadata.create_all(bind=engine)
    print("‚úÖ  Succ√®s ! Toutes les tables (users + workout_sessions) sont pr√™tes.")
except Exception as e:
    print(f"‚ùå  Erreur : {e}")-e 

-e 
================================================================================
üìÑ FICHIER : backend/migrate_db.py
================================================================================
#!/usr/bin/env python3
"""
SCRIPT DE MIGRATION S√âCURIS√â TITAN V2
Objectif : Ajouter le support JSON (profile_data) SANS casser l'existant.
"""

import sys
import os
from pathlib import Path
from sqlalchemy import create_engine, text, inspect
from dotenv import load_dotenv

# Ajouter le backend au path
sys.path.append(str(Path(__file__).parent))

load_dotenv()

def get_db_url():
    db_url = os.getenv("DATABASE_URL", "sqlite:///./sql_app.db")
    if db_url.startswith("postgres://"):
        db_url = db_url.replace("postgres://", "postgresql://", 1)
    return db_url

def run_migration():
    print("üöÄ D√âMARRAGE DE LA MIGRATION S√âCURIS√âE...")
    
    engine = create_engine(get_db_url())
    
    with engine.connect() as conn:
        trans = conn.begin()
        try:
            inspector = inspect(engine)
            existing_tables = inspector.get_table_names()
            
            # --- √âTAPE 1 : AJOUTER LA COLONNE JSON √Ä USERS (CRITIQUE POUR AUTH.PY) ---
            print("\n1Ô∏è‚É£  V√©rification de la table 'users'...")
            if 'users' in existing_tables:
                columns = [col['name'] for col in inspector.get_columns('users')]
                
                if 'profile_data' not in columns:
                    print("   ‚ûï Ajout de la colonne 'profile_data'...")
                    # Syntaxe compatible Postgres (JSONB) et SQLite (TEXT/JSON)
                    is_postgres = "postgresql" in str(engine.url)
                    col_type = "JSONB" if is_postgres else "JSON"
                    
                    # Fallback SQLite si besoin
                    if "sqlite" in str(engine.url): col_type = "TEXT" 

                    conn.execute(text(f"ALTER TABLE users ADD COLUMN profile_data {col_type} DEFAULT '{{}}'"))
                    print("   ‚úÖ Colonne ajout√©e avec succ√®s.")
                else:
                    print("   ‚úÖ Colonne 'profile_data' d√©j√† pr√©sente.")
            else:
                print("   ‚ö†Ô∏è Table 'users' introuvable (sera cr√©√©e au red√©marrage via init_db).")

            # --- √âTAPE 2 : PROTECTION DES TABLES EXISTANTES ---
            # On NE SUPPRIME PAS les tables tant que les mod√®les SQL les r√©f√©rencent encore.
            print("\n2Ô∏è‚É£  V√©rification des tables historiques (Mode Non-Destructif)...")
            tables_to_check = ['coach_memories', 'athlete_profiles']
            
            for table in tables_to_check:
                if table in existing_tables:
                    print(f"   üõ°Ô∏è  Table {table} pr√©serv√©e (Code SQL encore actif).")
                else:
                    print(f"   ‚ÑπÔ∏è  Table {table} absente (Sera recr√©√©e si n√©cessaire par SQLAlchemy).")

            # --- √âTAPE 3 : CR√âER FEED_ITEMS (SI MANQUANTE) ---
            print("\n3Ô∏è‚É£  V√©rification de 'feed_items'...")
            if 'feed_items' not in existing_tables:
                print("   ‚ûï Cr√©ation de 'feed_items'...")
                conn.execute(text("""
                    CREATE TABLE feed_items (
                        id VARCHAR PRIMARY KEY,
                        user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
                        type VARCHAR NOT NULL,
                        title VARCHAR NOT NULL,
                        message VARCHAR NOT NULL,
                        action_payload TEXT,
                        is_read BOOLEAN DEFAULT FALSE,
                        is_completed BOOLEAN DEFAULT FALSE,
                        priority INTEGER DEFAULT 1,
                        created_at TIMESTAMPTZ DEFAULT NOW()
                    );
                """))
                print("   ‚úÖ Table cr√©√©e.")
            else:
                print("   ‚úÖ Table 'feed_items' d√©j√† pr√©sente.")

            trans.commit()
            print("\nüéâ MIGRATION TERMIN√âE AVEC SUCC√àS !")
            print("   Votre base est pr√™te pour le profil JSON sans perte de donn√©es.")
            
        except Exception as e:
            trans.rollback()
            print(f"\n‚ùå ERREUR MIGRATION : {e}")
            raise e

if __name__ == "__main__":
    run_migration()-e 

-e 
================================================================================
üìÑ FICHIER : backend/synchro.py
================================================================================
#!/usr/bin/env python3
"""
Script de v√©rification backend TitanFlow
Teste la compatibilit√© avec le frontend Flutter
"""

import os
import sys
import json
import time
import asyncio
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import aiohttp
import jwt
from sqlalchemy import create_engine, text
from dotenv import load_dotenv

# Configuration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class BackendCompatibilityChecker:
    """V√©rifie la compatibilit√© compl√®te du backend TitanFlow"""
    
    def __init__(self):
        self.results = {
            'timestamp': datetime.now().isoformat(),
            'environment': {},
            'database': {},
            'api_endpoints': {},
            'data_models': {},
            'security': {},
            'performance': {},
            'issues': [],
            'recommendations': []
        }
        self.base_url = "http://localhost:8000"
        self.auth_token = None
        
    async def run_comprehensive_check(self):
        """Ex√©cute tous les tests de compatibilit√©"""
        print("üîß D√âMARRAGE DES TESTS BACKEND TITANFLOW")
        print("=" * 60)
        
        try:
            # 1. V√©rification de l'environnement
            await self._check_environment()
            
            # 2. V√©rification de la base de donn√©es
            await self._check_database()
            
            # 3. V√©rification des endpoints API
            await self._check_api_endpoints()
            
            # 4. V√©rification des mod√®les de donn√©es
            await self._check_data_models()
            
            # 5. V√©rification de la s√©curit√©
            await self._check_security()
            
            # 6. Tests de performance
            await self._check_performance()
            
            # 7. G√©n√©ration du rapport
            self._generate_report()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors des tests: {e}")
            self.results['issues'].append(f"Erreur critique: {str(e)}")
            
        return self.results
    
    async def _check_environment(self):
        """V√©rifie l'environnement d'ex√©cution"""
        print("\nüîç 1/6: V√©rification de l'environnement")
        
        try:
            # Variables d'environnement
            load_dotenv()
            
            env_vars = {
                'DATABASE_URL': os.getenv('DATABASE_URL'),
                'SECRET_KEY': 'D√âFINIE' if os.getenv('SECRET_KEY') else 'MANQUANTE',
                'GEMINI_API_KEY': 'D√âFINIE' if os.getenv('GEMINI_API_KEY') else 'MANQUANTE',
                'ALGORITHM': os.getenv('ALGORITHM', 'HS256'),
                'ACCESS_TOKEN_EXPIRE_MINUTES': os.getenv('ACCESS_TOKEN_EXPIRE_MINUTES', '30'),
            }
            
            self.results['environment'] = env_vars
            
            # V√©rifications critiques
            issues = []
            if not env_vars['DATABASE_URL']:
                issues.append("‚ùå DATABASE_URL non d√©finie")
            if env_vars['SECRET_KEY'] == 'MANQUANTE':
                issues.append("‚ùå SECRET_KEY non d√©finie (JWT requis)")
            if env_vars['GEMINI_API_KEY'] == 'MANQUANTE':
                issues.append("‚ö†Ô∏è GEMINI_API_KEY non d√©finie (Coach IA d√©sactiv√©)")
            
            for issue in issues:
                self.results['issues'].append(issue)
                logger.info(f"   {issue}")
                
            logger.info("   ‚úÖ Environnement charg√©")
            
        except Exception as e:
            logger.error(f"   ‚ùå Erreur environnement: {e}")
            self.results['issues'].append(f"Erreur environnement: {str(e)}")
    
    async def _check_database(self):
        """V√©rifie la connexion et le sch√©ma de la base"""
        print("\nüóÑÔ∏è  2/6: V√©rification de la base de donn√©es")
        
        try:
            db_url = os.getenv('DATABASE_URL')
            if not db_url:
                logger.error("   ‚ùå URL de base non d√©finie")
                return
            
            # Correction PostgreSQL
            if db_url.startswith("postgres://"):
                db_url = db_url.replace("postgres://", "postgresql://", 1)
            
            engine = create_engine(db_url)
            
            with engine.connect() as conn:
                # Test de connexion
                start = time.time()
                conn.execute(text("SELECT 1"))
                latency = (time.time() - start) * 1000
                
                # V√©rifier les tables
                result = conn.execute(text("""
                    SELECT table_name 
                    FROM information_schema.tables 
                    WHERE table_schema = 'public'
                    ORDER BY table_name
                """))
                
                tables = [row[0] for row in result]
                
                # V√©rifier les tables critiques
                critical_tables = [
                    'users', 'athlete_profiles', 'coach_memories',
                    'workout_sessions', 'workout_sets', 'feed_items'
                ]
                
                missing_tables = [t for t in critical_tables if t not in tables]
                
                self.results['database'] = {
                    'connection': '‚úÖ OK',
                    'latency_ms': round(latency, 2),
                    'tables_found': len(tables),
                    'critical_tables_found': len(critical_tables) - len(missing_tables),
                    'missing_tables': missing_tables,
                    'all_tables': tables
                }
                
                logger.info(f"   ‚úÖ Connexion: {latency:.2f}ms")
                logger.info(f"   üìä Tables: {len(tables)} trouv√©es")
                
                if missing_tables:
                    logger.warning(f"   ‚ö†Ô∏è Tables manquantes: {missing_tables}")
                    self.results['issues'].extend(
                        [f"Table manquante: {t}" for t in missing_tables]
                    )
                
                # V√©rifier les contraintes
                constraints = conn.execute(text("""
                    SELECT 
                        tc.table_name, 
                        tc.constraint_type,
                        tc.constraint_name
                    FROM information_schema.table_constraints tc
                    WHERE tc.table_schema = 'public'
                    ORDER BY tc.table_name, tc.constraint_type
                """))
                
                constraints_list = [
                    f"{row[0]}.{row[2]} ({row[1]})" 
                    for row in constraints
                ]
                
                self.results['database']['constraints'] = constraints_list
                
        except Exception as e:
            logger.error(f"   ‚ùå Erreur base de donn√©es: {e}")
            self.results['database'] = {'error': str(e)}
            self.results['issues'].append(f"Erreur base de donn√©es: {str(e)}")
    
    async def _check_api_endpoints(self):
        """Teste tous les endpoints API"""
        print("\nüåê 3/6: Test des endpoints API")
        
        endpoints = [
            # Endpoints publics
            {'method': 'GET', 'path': '/health', 'auth': False},
            {'method': 'GET', 'path': '/docs', 'auth': False},
            {'method': 'GET', 'path': '/redoc', 'auth': False},
            
            # Authentification
            {'method': 'POST', 'path': '/auth/signup', 'auth': False},
            {'method': 'POST', 'path': '/auth/token', 'auth': False},
            
            # Endpoints prot√©g√©s (n√©cessitent auth)
            {'method': 'GET', 'path': '/user/profile', 'auth': True},
            {'method': 'GET', 'path': '/workouts/', 'auth': True},
            {'method': 'GET', 'path': '/feed/', 'auth': True},
            {'method': 'GET', 'path': '/api/v1/profiles/me', 'auth': True},
            {'method': 'GET', 'path': '/api/v1/coach-memories/me', 'auth': True},
            
            # Coach IA
            {'method': 'POST', 'path': '/coach/audit', 'auth': True},
            {'method': 'GET', 'path': '/coach/strategy', 'auth': True},
            {'method': 'GET', 'path': '/coach/week', 'auth': True},
            
            # Performance & Safety
            {'method': 'POST', 'path': '/performance/1rm', 'auth': True},
            {'method': 'POST', 'path': '/safety/acwr', 'auth': True},
            
            # R√©paration syst√®me
            {'method': 'GET', 'path': '/fix_db', 'auth': False},
        ]
        
        results = {}
        successful = 0
        failed = 0
        warnings = 0
        
        async with aiohttp.ClientSession() as session:
            for endpoint in endpoints:
                url = f"{self.base_url}{endpoint['path']}"
                method = endpoint['method']
                requires_auth = endpoint['auth']
                
                # Pr√©parer les headers
                headers = {'Content-Type': 'application/json'}
                if requires_auth and self.auth_token:
                    headers['Authorization'] = f'Bearer {self.auth_token}'
                
                # Pr√©parer le payload si n√©cessaire
                data = None
                if method == 'POST':
                    if 'auth/token' in endpoint['path']:
                        data = {'username': 'testuser', 'password': 'password123'}
                    elif 'auth/signup' in endpoint['path']:
                        data = {
                            'username': f'test_{int(time.time())}',
                            'email': f'test_{int(time.time())}@example.com',
                            'password': 'Test123!'
                        }
                    elif 'performance/1rm' in endpoint['path']:
                        data = {'weight': 100, 'reps': 5}
                    elif 'coach/audit' in endpoint['path']:
                        data = {'profile_data': {'sport': 'Musculation', 'level': 'Interm√©diaire'}}
                    else:
                        data = {}
                
                try:
                    start = time.time()
                    
                    if method == 'GET':
                        async with session.get(url, headers=headers) as response:
                            status = response.status
                            latency = (time.time() - start) * 1000
                    elif method == 'POST':
                        async with session.post(url, headers=headers, json=data) as response:
                            status = response.status
                            latency = (time.time() - start) * 1000
                            
                            # Sauvegarder le token si c'est une connexion r√©ussie
                            if 'auth/token' in endpoint['path'] and status == 200:
                                response_data = await response.json()
                                self.auth_token = response_data.get('access_token')
                    
                    # √âvaluer le r√©sultat
                    if status in [200, 201]:
                        result = '‚úÖ OK'
                        successful += 1
                    elif status == 404:
                        result = '‚ö†Ô∏è NON IMPL√âMENT√â'
                        warnings += 1
                    elif status == 401 and requires_auth:
                        result = 'üîí AUTH REQUISE'
                        warnings += 1
                    else:
                        result = f'‚ùå {status}'
                        failed += 1
                    
                    results[endpoint['path']] = {
                        'status': status,
                        'latency_ms': round(latency, 2),
                        'result': result
                    }
                    
                    logger.info(f"   {result} {method} {endpoint['path']} ({latency:.2f}ms)")
                    
                except Exception as e:
                    results[endpoint['path']] = {'error': str(e), 'result': '‚ùå ERREUR'}
                    failed += 1
                    logger.error(f"   ‚ùå ERREUR {method} {endpoint['path']}: {e}")
        
        self.results['api_endpoints'] = {
            'tested': len(endpoints),
            'successful': successful,
            'failed': failed,
            'warnings': warnings,
            'details': results
        }
        
        logger.info(f"   üìä R√©sum√©: {successful}‚úÖ {failed}‚ùå {warnings}‚ö†Ô∏è")
    
    async def _check_data_models(self):
        """V√©rifie la coh√©rence des mod√®les de donn√©es"""
        print("\nüìä 4/6: V√©rification des mod√®les de donn√©es")
        
        try:
            # Importer les mod√®les SQLAlchemy
            sys.path.append('.')
            from app.models import sql_models
            
            models_to_check = [
                ('User', sql_models.User),
                ('AthleteProfile', sql_models.AthleteProfile),
                ('CoachMemory', sql_models.CoachMemory),
                ('WorkoutSession', sql_models.WorkoutSession),
                ('WorkoutSet', sql_models.WorkoutSet),
                ('FeedItem', sql_models.FeedItem),
            ]
            
            results = {}
            
            for model_name, model_class in models_to_check:
                try:
                    # V√©rifier que le mod√®le peut √™tre instanci√©
                    instance = model_class()
                    
                    # V√©rifier les colonnes
                    columns = [col.name for col in model_class.__table__.columns]
                    
                    # V√©rifier les relations
                    relationships = []
                    if hasattr(model_class, '__mapper__'):
                        for rel in model_class.__mapper__.relationships:
                            relationships.append(rel.key)
                    
                    results[model_name] = {
                        'status': '‚úÖ VALIDE',
                        'columns': columns,
                        'relationships': relationships,
                        'table_name': model_class.__tablename__
                    }
                    
                    logger.info(f"   ‚úÖ {model_name}: {len(columns)} colonnes")
                    
                except Exception as e:
                    results[model_name] = {'status': f'‚ùå ERREUR: {e}'}
                    logger.error(f"   ‚ùå {model_name}: {e}")
                    self.results['issues'].append(f"Mod√®le {model_name}: {str(e)}")
            
            self.results['data_models'] = results
            
        except ImportError as e:
            logger.error(f"   ‚ùå Impossible d'importer les mod√®les: {e}")
            self.results['issues'].append(f"Import mod√®les: {str(e)}")
        except Exception as e:
            logger.error(f"   ‚ùå Erreur mod√®les: {e}")
            self.results['issues'].append(f"Erreur mod√®les: {str(e)}")
    
    async def _check_security(self):
        """V√©rifie les aspects de s√©curit√©"""
        print("\nüîí 5/6: V√©rification de s√©curit√©")
        
        security_checks = {
            'jwt_config': '‚ùå NON V√âRIFI√â',
            'password_hashing': '‚ùå NON V√âRIFI√â',
            'cors_headers': '‚ùå NON V√âRIFI√â',
            'rate_limiting': '‚ö†Ô∏è  NON D√âTECT√â',
            'input_validation': '‚úÖ TEST REQUIS'
        }
        
        try:
            # Tester JWT
            secret = os.getenv('SECRET_KEY')
            if secret and secret != 'your-super-secret-key-change-in-production':
                try:
                    # G√©n√©rer un token de test
                    payload = {'sub': 'test', 'exp': datetime.now().timestamp() + 3600}
                    token = jwt.encode(payload, secret, algorithm='HS256')
                    jwt.decode(token, secret, algorithms=['HS256'])
                    security_checks['jwt_config'] = '‚úÖ CONFIGUR√â'
                except:
                    security_checks['jwt_config'] = '‚ùå ERREUR JWT'
            else:
                security_checks['jwt_config'] = '‚ùå SECRET PAR D√âFAIT'
            
            # Tester CORS
            async with aiohttp.ClientSession() as session:
                async with session.options(f"{self.base_url}/health") as response:
                    if 'Access-Control-Allow-Origin' in response.headers:
                        security_checks['cors_headers'] = '‚úÖ ACTIV√â'
                    else:
                        security_checks['cors_headers'] = '‚ö†Ô∏è  NON D√âTECT√â'
            
            for check, status in security_checks.items():
                logger.info(f"   {status} {check.replace('_', ' ').title()}")
            
            self.results['security'] = security_checks
            
        except Exception as e:
            logger.error(f"   ‚ùå Erreur s√©curit√©: {e}")
            self.results['security'] = {'error': str(e)}
    
    async def _check_performance(self):
        """Effectue des tests de performance"""
        print("\n‚ö° 6/6: Tests de performance")
        
        try:
            async with aiohttp.ClientSession() as session:
                # Test de latence
                latencies = []
                for _ in range(5):
                    start = time.time()
                    async with session.get(f"{self.base_url}/health") as _:
                        latencies.append((time.time() - start) * 1000)
                    await asyncio.sleep(0.1)
                
                avg_latency = sum(latencies) / len(latencies)
                
                # Test de charge (simplifi√©)
                start = time.time()
                tasks = []
                for _ in range(10):
                    task = session.get(f"{self.base_url}/health")
                    tasks.append(task)
                
                responses = await asyncio.gather(*tasks, return_exceptions=True)
                load_time = (time.time() - start) * 1000
                
                self.results['performance'] = {
                    'avg_latency_ms': round(avg_latency, 2),
                    'load_test_10req_ms': round(load_time, 2),
                    'recommended_max_latency': '300ms',
                    'status': '‚úÖ OK' if avg_latency < 300 else '‚ö†Ô∏è  LENT'
                }
                
                logger.info(f"   üìà Latence moyenne: {avg_latency:.2f}ms")
                logger.info(f"   üìä Test de charge (10 req): {load_time:.2f}ms")
                
        except Exception as e:
            logger.error(f"   ‚ùå Erreur performance: {e}")
            self.results['performance'] = {'error': str(e)}
    
    def _generate_report(self):
        """G√©n√®re un rapport d√©taill√©"""
        print("\n" + "=" * 60)
        print("üìã RAPPORT DE COMPATIBILIT√â BACKEND")
        print("=" * 60)
        
        # R√©sum√©
        total_tests = (
            (1 if self.results['environment'] else 0) +
            (1 if self.results['database'] else 0) +
            (self.results['api_endpoints'].get('tested', 0)) +
            (len(self.results.get('data_models', {}))) +
            (len(self.results.get('security', {}))) +
            (1 if self.results.get('performance') else 0)
        )
        
        successful = (
            (1 if not self.results['issues'] else 0) +
            self.results['api_endpoints'].get('successful', 0)
        )
        
        print(f"\nüìä STATISTIQUES:")
        print(f"   ‚Ä¢ Tests ex√©cut√©s: {total_tests}")
        print(f"   ‚Ä¢ Endpoints test√©s: {self.results['api_endpoints'].get('tested', 0)}")
        print(f"   ‚Ä¢ Endpoints OK: {self.results['api_endpoints'].get('successful', 0)}")
        print(f"   ‚Ä¢ Mod√®les valid√©s: {len(self.results.get('data_models', {}))}")
        
        print(f"\nüîß ENVIRONNEMENT:")
        for key, value in self.results['environment'].items():
            print(f"   ‚Ä¢ {key}: {value}")
        
        print(f"\nüóÑÔ∏è  BASE DE DONN√âES:")
        db = self.results['database']
        if 'error' not in db:
            print(f"   ‚Ä¢ Connexion: {db.get('connection', 'N/A')}")
            print(f"   ‚Ä¢ Latence: {db.get('latency_ms', 0)}ms")
            print(f"   ‚Ä¢ Tables critiques: {db.get('critical_tables_found', 0)}/6")
            if db.get('missing_tables'):
                print(f"   ‚Ä¢ Tables manquantes: {', '.join(db['missing_tables'])}")
        
        print(f"\nüö® PROBL√àMES IDENTIFI√âS ({len(self.results['issues'])}):")
        for issue in self.results['issues']:
            print(f"   ‚Ä¢ {issue}")
        
        print(f"\nüí° RECOMMANDATIONS:")
        recommendations = [
            "‚úÖ Garder les cl√©s JWT en variables d'environnement",
            "‚úÖ Activer CORS pour le frontend Flutter",
            "‚úÖ Configurer les index de base de donn√©es",
            "‚úÖ Mettre en place le logging structur√©",
            "‚úÖ Tester avec des donn√©es r√©elles",
        ]
        
        for rec in recommendations:
            print(f"   {rec}")
        
        # Sauvegarder le rapport JSON
        report_file = f"backend_compatibility_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w') as f:
            json.dump(self.results, f, indent=2, default=str)
        
        print(f"\nüìÑ Rapport JSON sauvegard√©: {report_file}")
        print("=" * 60)

async def main():
    """Point d'entr√©e principal"""
    print("üöÄ D√âMARRAGE DES TESTS DE COMPATIBILIT√â BACKEND")
    print("=" * 60)
    
    checker = BackendCompatibilityChecker()
    results = await checker.run_comprehensive_check()
    
    # √âvaluation finale
    critical_issues = [
        issue for issue in results['issues'] 
        if any(keyword in issue.lower() for keyword in ['‚ùå', 'erreur', 'manquant'])
    ]
    
    if critical_issues:
        print("\n‚ö†Ô∏è  ATTENTION: Probl√®mes critiques d√©tect√©s!")
        print("   Le backend n√©cessite des corrections avant d√©ploiement.")
        return 1
    else:
        print("\n‚úÖ Backend pr√™t pour l'int√©gration avec Flutter!")
        print("   Tous les tests de compatibilit√© sont pass√©s.")
        return 0

if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n‚ùå Tests interrompus par l'utilisateur")
        sys.exit(1)-e 

-e 
================================================================================
üìÑ FICHIER : backend/test.py
================================================================================
import requests
import sys
import time
import json

# Configuration
BASE_URL = "http://localhost:8000"
# G√©n√©ration d'identifiants uniques pour le test
TIMESTAMP = int(time.time())
USERNAME = f"ci_bot_{TIMESTAMP}"
PASSWORD = "TestPassword123!"
EMAIL = f"ci_{TIMESTAMP}@test.com"

def run_test():
    print(f"üöÄ D√©marrage du test de validation FIX-500 sur {BASE_URL}")

    # 1. INSCRIPTION
    print("üîπ √âtape 1 : Inscription...")
    signup_payload = {"username": USERNAME, "email": EMAIL, "password": PASSWORD}
    try:
        r = requests.post(f"{BASE_URL}/auth/signup", json=signup_payload)
        if r.status_code not in [200, 201]:
            print(f"‚ùå √âchec Inscription: {r.text}")
            sys.exit(1)
    except Exception as e:
        print(f"‚ùå Le serveur semble √©teint : {e}")
        sys.exit(1)

    # 2. CONNEXION (TOKEN)
    print("üîπ √âtape 2 : Connexion...")
    login_data = {"username": USERNAME, "password": PASSWORD}
    r = requests.post(f"{BASE_URL}/auth/token", data=login_data)
    if r.status_code != 200:
        print(f"‚ùå √âchec Connexion: {r.text}")
        sys.exit(1)
    
    token = r.json().get("access_token")
    headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}

    # 3. TEST SAUVEGARDE PROFIL (LE COEUR DU BUG)
    print("üîπ √âtape 3 : Sauvegarde Profil (Test de r√©gression)...")
    
    # Payload complexe (Dictionnaire imbriqu√©) pour provoquer l'erreur 500
    # si le backend ne fait pas le json.dumps()
    profile_payload = {
        "profile_data": {
            "basic_info": {
                "pseudo": USERNAME,
                "email": EMAIL,
                "biography": "Test CI/CD avec caract√®res sp√©ciaux √©√†√π"
            },
            "sport_context": {
                "sport": "Crossfit",
                "stats": {"max_pullups": 20, "run_5k": "20:00"}
            },
            "goals": {
                "primary": "Survivre au d√©ploiement"
            }
        }
    }

    r = requests.post(f"{BASE_URL}/api/v1/profiles/complete", json=profile_payload, headers=headers)

    # 4. VERIFICATION
    if r.status_code == 200:
        print("‚úÖ SUCC√àS : Le profil a √©t√© sauvegard√© sans erreur 500.")
        print("   Le correctif `json.dumps` est actif.")
        
        # V√©rification optionnelle du retour
        data = r.json()
        if isinstance(data.get("profile_data"), dict):
             print("‚úÖ Le backend a bien retourn√© un JSON (Dict) propre.")
        else:
             print("‚ö†Ô∏è Warning: Le backend a retourn√© une String au lieu d'un Dict (Pydantic parsing warning).")
             
        sys.exit(0)
    elif r.status_code == 500:
        print("üî• √âCHEC CRITIQUE : Erreur 500 d√©tect√©e.")
        print("   Cause probable : Le dictionnaire Python est pass√© directement √† SQLAlchemy sans s√©rialisation.")
        print(f"   R√©ponse : {r.text}")
        sys.exit(1)
    else:
        print(f"‚ùå √âchec inattendu (Code {r.status_code}): {r.text}")
        sys.exit(1)

if __name__ == "__main__":
    run_test()-e 

-e 
================================================================================
üìÑ FICHIER : backend/visualisation_db.py
================================================================================
import streamlit as st
import pandas as pd
from sqlalchemy import create_engine, inspect, text

# --- 1. CONFIGURATION ---
# Votre URL est int√©gr√©e ici :
DB_URL = "postgresql://titanflow_prod_db_user:1VRDWljUne5YD0lczDfcY3gLglcgS3VU@dpg-d5ec3fruibrs738a76a0-a.frankfurt-postgres.render.com/titanflow_prod_db"

st.set_page_config(
    page_title="TitanFlow DB Admin", 
    layout="wide",  # Mode "Large" pour voir toutes les colonnes
    page_icon="üëÅÔ∏è"
)

# CSS pour maximiser l'espace
st.markdown("""
<style>
    .block-container { padding-top: 2rem; padding-bottom: 2rem; }
    div[data-testid="stDataFrame"] { width: 100%; }
</style>
""", unsafe_allow_html=True)

st.title("üëÅÔ∏è TitanFlow - Inspecteur de Base de Donn√©es")

# --- 2. CONNEXION ---
try:
    # Petit nettoyage au cas o√π (Render donne parfois postgres:// au lieu de postgresql://)
    if DB_URL.startswith("postgres://"):
        real_url = DB_URL.replace("postgres://", "postgresql://", 1)
    else:
        real_url = DB_URL

    engine = create_engine(real_url)
    inspector = inspect(engine)
    
    # Test de connexion et r√©cup√©ration des tables
    all_tables = inspector.get_table_names()

    if not all_tables:
        st.warning("‚ö†Ô∏è Connexion r√©ussie, mais aucune table trouv√©e dans la base.")
    else:
        # --- 3. SIDEBAR (Navigation) ---
        st.sidebar.header("üìÇ Tables disponibles")
        
        # Tri : on met les tables importantes en haut
        priority = ['users', 'athlete_profiles', 'workout_sessions', 'coach_memories']
        sorted_tables = sorted(all_tables, key=lambda x: (0 if x in priority else 1, x))
        
        selected_table = st.sidebar.radio("S√©lectionnez une table :", sorted_tables)

        st.divider()
        st.header(f"Table : `{selected_table}`")

        # --- 4. INSPECTION DE LA STRUCTURE (Colonnes) ---
        # C'est ici qu'on v√©rifie si les colonnes existent vraiment
        columns_info = inspector.get_columns(selected_table)
        col_names = [col['name'] for col in columns_info]
        
        st.info(f"üìä La table contient **{len(col_names)} colonnes**.")
        
        # Liste d√©roulante pour v√©rifier les noms exacts
        with st.expander("üîé Cliquez ici pour voir la liste exacte des colonnes (Sch√©ma)"):
            schema_df = pd.DataFrame([
                {"Nom": c['name'], "Type": str(c['type']), "Nullable": c['nullable']} 
                for c in columns_info
            ])
            st.table(schema_df)

        # --- 5. AFFICHAGE DES DONN√âES ---
        st.subheader("Donn√©es enregistr√©es")
        
        with engine.connect() as conn:
            # On r√©cup√®re tout le contenu
            query = text(f"SELECT * FROM {selected_table}")
            df = pd.read_sql(query, conn)

        if df.empty:
            st.warning("Cette table est vide (0 ligne).")
        else:
            # Affichage du tableau interactif
            st.dataframe(
                df, 
                use_container_width=True, 
                height=600  # Grande hauteur pour le confort
            )

except Exception as e:
    st.error("‚ùå Erreur de connexion")
    st.error(f"D√©tails : {e}")
    st.info("V√©rifiez votre connexion internet ou si l'URL a chang√©.")-e 

-e 
================================================================================
üìÑ FICHIER : frontend/app.py
================================================================================
import streamlit as st
import requests
import pandas as pd
from datetime import datetime

# Configuration de la page
st.set_page_config(page_title="TitanFlow Pro", page_icon="‚ö°", layout="wide")

# L'URL de ton API (Backend)
API_URL = "http://127.0.0.1:8000"

# --- GESTION DE LA SESSION (Token) ---
if "token" not in st.session_state:
    st.session_state.token = None

def login():
    st.sidebar.header("üîê Connexion")
    username = st.sidebar.text_input("Pseudo")
    password = st.sidebar.text_input("Mot de passe", type="password")
    
    if st.sidebar.button("Se connecter"):
        try:
            # Appel √† l'API pour r√©cup√©rer le token
            response = requests.post(
                f"{API_URL}/auth/token",
                data={"username": username, "password": password}
            )
            if response.status_code == 200:
                st.session_state.token = response.json()["access_token"]
                st.sidebar.success("Connect√© !")
                st.rerun()
            else:
                st.sidebar.error("Erreur de connexion")
        except Exception as e:
            st.sidebar.error(f"API introuvable : {e}")

def logout():
    if st.sidebar.button("Se d√©connecter"):
        st.session_state.token = None
        st.rerun()

# --- INTERFACE PRINCIPALE ---
st.title("‚ö° TitanFlow : Monitoring Athl√©tique")

# V√©rification de l'√©tat de l'API
try:
    health = requests.get(f"{API_URL}/health").json()
    st.success(f"Backend connect√© v{health['version']}")
except:
    st.error("üö® Le Backend semble √©teint. V√©rifie que le Terminal 1 tourne bien !")

# Gestion Login/Logout
if not st.session_state.token:
    st.info("Veuillez vous connecter dans la barre lat√©rale pour acc√©der aux donn√©es.")
    login()
else:
    logout()
    st.write("---")
    
    # Onglets de l'application
    tab1, tab2 = st.tabs(["üèãÔ∏è‚Äç‚ôÇÔ∏è Historique", "‚ûï Nouvelle S√©ance"])
    
    # --- ONGLET 1 : HISTORIQUE ---
    with tab1:
        st.subheader("Vos s√©ances enregistr√©es")
        headers = {"Authorization": f"Bearer {st.session_state.token}"}
        
        try:
            res = requests.get(f"{API_URL}/workouts/", headers=headers)
            if res.status_code == 200:
                workouts = res.json()
                if workouts:
                    df = pd.DataFrame(workouts)
                    st.dataframe(df, use_container_width=True)
                else:
                    st.info("Aucune s√©ance trouv√©e.")
            else:
                st.error("Erreur chargement donn√©es")
        except Exception as e:
            st.error(f"Erreur : {e}")

    # --- ONGLET 2 : AJOUTER S√âANCE ---
    with tab2:
        st.subheader("Enregistrer un entra√Ænement")
        with st.form("new_workout"):
            col1, col2 = st.columns(2)
            date = col1.date_input("Date")
            duration = col2.number_input("Dur√©e (min)", min_value=0, value=60)
            rpe = st.slider("Intensit√© (RPE)", 0, 10, 5)
            
            submitted = st.form_submit_button("Sauvegarder")
            
            if submitted:
                # Pr√©paration du JSON
                payload = {
                    "date": str(date),
                    "duration": duration,
                    "rpe": rpe
                }
                # Envoi √† l'API
                headers = {"Authorization": f"Bearer {st.session_state.token}"}
                res = requests.post(f"{API_URL}/workouts/", json=payload, headers=headers)
                
                if res.status_code == 200:
                    st.success("S√©ance enregistr√©e ! üéâ")
                    # Petit hack pour rafra√Æchir l'historique
                    st.rerun()
                else:
                    st.error(f"Erreur : {res.text}")
-e 

